{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-11-04 03:27:44.133306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-04 03:27:44.602055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-04 03:27:44.602096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-04 03:27:44.602100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_734991/230764483.py:29: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from local_transformers.src.transformers import TrainingArguments\n",
    "from local_transformers.src.transformers.models.biogpt.tokenization_biogpt import BioGptTokenizer # reads the local_transformers folder instead of the actual transformers package\n",
    "from local_transformers.src.transformers.models.CustomBioGPT import CustomBioGptForCausalLM # reads the local_transformers folder instead of the actual transformers package\n",
    "from local_transformers.src.transformers.CustomComputeLoss import CustomTrainer # reads the local_transformers folder instead of the actual transformers package\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import ConcatDataset\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "if tf.test.is_gpu_available():\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is not available, running on CPU')\n",
    "\n",
    "# Reading data\n",
    "df=pd.read_csv(\"df.csv\")\n",
    "df[\"death_in_30\"] = df[\"death_in_30\"].astype(int)\n",
    "df[\"DVT\"] = df[\"DVT\"].astype(int)\n",
    "df[\"PE\"] = df[\"PE\"].astype(int)\n",
    "df[\"post_aki_status\"] = df[\"post_aki_status\"].astype(int)\n",
    "df[\"PNA\"] = df[\"PNA\"].astype(int)\n",
    "\n",
    "\n",
    "# VERY IMPORTANT: MAKE SURE TO USE CustomBioGptForCausalLM SO WE CAN ACCEPT THE LABELS AS PART OF OUR FINE-TUNNING \n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "# preparing the clinical notes for training and fine-tuning \n",
    "# this function here helps set up and prepare the data for fine-tuning, including those of the additional labels. \n",
    "class preparing(torch.utils.data.Dataset):\n",
    "    def __init__(self, notes, additional_labels, tokenizer, task_ids, max_length=188):\n",
    "        self.notes = notes\n",
    "        self.additional_labels = additional_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.task_ids=task_ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        note = self.notes[idx]\n",
    "        additional_label = self.additional_labels[idx]\n",
    "        task_id = self.task_ids[idx]\n",
    "\n",
    "        # Tokenize the input note\n",
    "        encoding = self.tokenizer(note, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        # Split the input sequence into input and label sequences\n",
    "        input_ids = encoding['input_ids'][0][:-1]\n",
    "        label_ids = encoding['input_ids'][0][1:]\n",
    "\n",
    "        # Return the input and label sequences along with the additional_label\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': encoding['attention_mask'][0][:-1],\n",
    "            'labels': label_ids,\n",
    "            'additional_labels': additional_label, # HERE WE INCLUDE THE ADDITIONAL_LABELS TO BE CONSIDERED AS PART OF OUR TRAINING\n",
    "            'task_ids': task_id # Include the task_ids to differentiate tasks\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notes)\n",
    "\n",
    "\n",
    "# By default Trainer actually shuffles the order of the data, but we can use this as well if we wish to\n",
    "# class ShuffledDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "#         indices = torch.randperm(len(dataset))\n",
    "#         self.shuffled_data = [dataset[i] for i in indices]\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.shuffled_data[idx]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "\n",
    "# stacking the data of different labels on top of one another so we can perform MTL fine-tuning\n",
    "def stack_data(df,tasks):\n",
    "    tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "    datasets = []\n",
    "    # print(enumerate(tasks))\n",
    "    for i, task in enumerate(tasks):\n",
    "        df_now = df.dropna(subset=[task]).reset_index(drop=True)\n",
    "        dataset = preparing(df_now[\"AN_PROC_NAME\"], df_now[task], tokenizer, torch.tensor([i] * len(df_now)))\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    combined_dataset = ConcatDataset(datasets)\n",
    "    return(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84875"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finetunes our model\n",
    "def get_model(name, train_dataset,val_dataset):\n",
    "    model = CustomBioGptForCausalLM.from_pretrained(\"microsoft/biogpt\", output_hidden_states=True, lambda_constant=10, num_tasks=6)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=3,      # total number of training epochs\n",
    "        per_device_train_batch_size=48,  # batch size per device during training\n",
    "        per_device_eval_batch_size=48,   # batch size for evaluation\n",
    "        warmup_steps=1000,          # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.001,          # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=1000,  # Add this line\n",
    "        save_strategy=\"steps\",\n",
    "        learning_rate=0.000005)       \n",
    "    # Create the Trainer object\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        lambda_constant=10)\n",
    "\n",
    "    # Fine-tune BioGPT on the training dataset\n",
    "    trainer.train()\n",
    "    #trainer.evaluate(eval_dataset=val_dataset)\n",
    "    # saving the newly pre-trained model. \n",
    "    trainer.model.save_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the text representation from the updated specified model\n",
    "def get_biogpt_updated(texts, name):\n",
    "    batch_size=64\n",
    "    max_length=144\n",
    "    texts = list(texts)\n",
    "\n",
    "    model = CustomBioGptForCausalLM.from_pretrained(name, output_hidden_states=True, lambda_constant=10, num_tasks=6) \n",
    "    tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "\n",
    "    # Move the model to the GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "    # tokenize the input text in batches\n",
    "    all_embeddings = []\n",
    "    for i in (range(0, len(texts), batch_size)):\n",
    "        print(\"Progress\", (i/len(texts))*100)\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_encoded = tokenizer(batch_texts, padding='max_length', truncation=True, return_tensors=\"pt\",\n",
    "                                  max_length=max_length)\n",
    "        input_ids = batch_encoded[\"input_ids\"]\n",
    "        attention_mask = batch_encoded[\"attention_mask\"]\n",
    "\n",
    "        # Move the tensors to the GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.to(\"cuda\")\n",
    "            attention_mask = attention_mask.to(\"cuda\")\n",
    "\n",
    "        # process each batch separately\n",
    "        batch_embeddings = []\n",
    "        for j in (range(input_ids.shape[0])):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids[j:j + 1], attention_mask=attention_mask[j:j + 1])\n",
    "                last_hidden_state = outputs.hidden_states[-1]\n",
    "                masked_hidden_state = last_hidden_state * attention_mask[j:j + 1].unsqueeze(-1)\n",
    "                embedding = torch.mean(masked_hidden_state, dim=1)\n",
    "                embedding = F.normalize(embedding, p=2, dim=1)\n",
    "            \n",
    "            # If you used GPU, move the embeddings back to CPU for further operations (like converting to numpy array)\n",
    "            if torch.cuda.is_available():\n",
    "                embedding = embedding.to(\"cpu\")\n",
    "            batch_embeddings.append(embedding)\n",
    "\n",
    "        # concatenate the embeddings from all examples in the batch\n",
    "        embeddings = torch.cat(batch_embeddings, dim=0)\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "    # concatenate the embeddings from all batches\n",
    "    embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    # convert the embeddings to a numpy array\n",
    "    X = embeddings.detach().numpy()\n",
    "\n",
    "    return (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs the 5-fold for XGBoost (default model)\n",
    "def rounding(take_mean, take_std):\n",
    "    return(round(take_mean, 2), round(take_std,2))\n",
    "\n",
    "\n",
    "def K_fold_val(outcome_col, df):\n",
    "    # Initialize the StratifiedKFold class\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Initialize lists to hold scores\n",
    "    auroc_scores, auprc_scores,accuracy_scores, recall_scores,precision_scores, specificity_scores,f_scores = [],[],[],[],[],[],[]\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.1,0.15,0.3],\n",
    "        'max_depth': [4,5,6,7,8],\n",
    "        'min_child_weight':[1,2,4]\n",
    "        }\n",
    "    i=1\n",
    "    # Perform 5-fold cross validation\n",
    "    for train_index, test_index in tqdm(skf.split(df, df[\"PE\"])):\n",
    "        # Split the data into train/test sets\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        name=f\"fold_{i}\"\n",
    "        i=i+1\n",
    "        if os.path.isdir(name):\n",
    "            print(\"passed\")\n",
    "        else:\n",
    "            # train val split\n",
    "            train_new=((train.sample(frac=7/8,random_state=42)))\n",
    "            val_new = train[~train.index.isin(train_new.index)]\n",
    "            train_notes=(train_new.reset_index(drop=True))\n",
    "            val_notes=(val_new.reset_index(drop=True))\n",
    "            tasks=[\"death_in_30\",\"DVT\",\"PE\",\"PNA\",\"post_aki_status\",\"postop_del\"]\n",
    "            train_dataset=stack_data(train_notes,tasks)\n",
    "            val_dataset=stack_data(val_notes,tasks)\n",
    "            get_model(name, train_dataset,val_dataset)\n",
    "        if os.path.isfile(f'{name}.pickle'):\n",
    "            with open(f'{name}.pickle', 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                X_train=data[0]\n",
    "                X_test=data[1]\n",
    "        else:\n",
    "            X_train=get_biogpt_updated(train[\"AN_PROC_NAME\"], name)\n",
    "            X_test = get_biogpt_updated(test[\"AN_PROC_NAME\"], name)\n",
    "            with open(f\"{name}.pickle\", 'wb') as f:\n",
    "                    pickle.dump([X_train,X_test], f)  \n",
    "\n",
    "        # Prepare training and testing data\n",
    "        y_train = train[outcome_col]\n",
    "        y_test = test[outcome_col]\n",
    "\n",
    "         # removing rows with potential NAs in them\n",
    "        if y_train.isna().any() or y_test.isna().any(): \n",
    "            na_indices = y_train.isna()  \n",
    "            X_train = (X_train[~na_indices])\n",
    "            y_train = (((y_train.dropna())).astype(int)).reset_index(drop=True)\n",
    "            na_indices = y_test.isna()  \n",
    "            X_test = X_test[~na_indices]  \n",
    "            y_test = ((y_test.dropna()).astype(int)).reset_index(drop=True)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # performing the XGboost classification\n",
    "        model = xgb.XGBClassifier(random_state=42,tree_method='gpu_hist')\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='average_precision',verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_class = best_model.predict(X_test)\n",
    "\n",
    "        # Compute the metrics\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        auprc = average_precision_score(y_test, y_pred)\n",
    "        accuracy=accuracy_score(y_test, y_pred_class)\n",
    "        recall = recall_score(y_test, y_pred_class)\n",
    "        precision = precision_score(y_test, y_pred_class)\n",
    "        # For specificity (True Negative Rate)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        f_score=f1_score(y_test, y_pred_class)\n",
    "\n",
    "        # Save the scores\n",
    "        auroc_scores.append(auroc)\n",
    "        auprc_scores.append(auprc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        recall_scores.append(recall)\n",
    "        precision_scores.append(precision)\n",
    "        specificity_scores.append(specificity)\n",
    "        f_scores.append(f_score)\n",
    "\n",
    "        with open(f\"update_{outcome_col}.pickle\", 'wb') as f:\n",
    "            pickle.dump({\"auprc\":auprc_scores, \"auroc\":auroc_scores,\"accuracy\":accuracy_scores,\n",
    "                         \"precision\":precision_scores,\"recall\":recall_scores, \n",
    "                         \"specificity\":specificity_scores,\n",
    "                         \"f1\":f_scores},f)\n",
    "\n",
    "    \n",
    "    # Now you can calculate the mean and standard deviation\n",
    "    mean_auroc,std_auroc = rounding(np.mean(auroc_scores), np.std(auroc_scores))\n",
    "    mean_auprc, std_auprc = rounding(np.mean(auprc_scores), np.std(auprc_scores))\n",
    "    mean_accuracy, std_accuracy=rounding(np.mean(accuracy_scores), np.std(accuracy_scores))\n",
    "    mean_precision, std_precision=rounding(np.mean(precision_scores), np.std(precision_scores))\n",
    "    mean_recall, std_recall=rounding(np.mean(recall_scores), np.std(recall_scores))\n",
    "    mean_specificity, std_specificity=rounding(np.mean(specificity_scores), np.std(specificity_scores))\n",
    "    mean_f1,std_f1=rounding(np.mean(f_scores), np.std(f_scores))  \n",
    "    \n",
    "    print_statement=f'''\n",
    "    metrics: Mean AUROC: {mean_auroc}, SD AUROC: {std_auroc}, \n",
    "    \\n Mean AUPRC: {mean_auprc}, SD AUPRC: {std_auprc}, \n",
    "    \\n Mean ACC:{mean_accuracy}, SD ACC:{std_accuracy}, \n",
    "    \\n Mean precision:{mean_precision}, std precision:{std_precision}, \n",
    "    \\n mean recall:{mean_recall}, std_recall:{std_recall},\n",
    "    \\n mean specificity:{mean_specificity}, std specificity:{std_specificity}, \n",
    "    \\n mean f1:{mean_f1}, std f1:{std_f1} \n",
    "    '''\n",
    "    return(print_statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs the 5-fold for Logistic Regression\n",
    "def K_fold_val_log_reg(outcome_col, df):\n",
    "    # Initialize the StratifiedKFold class\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to hold scores\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "\n",
    "    # changed parameters here because initial parameters gave underwhelming results\n",
    "    # so i explored alternative hyperparameters to see if model improves\n",
    "    param_grid = {\n",
    "    'C': [0.01, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['lbfgs', 'newton-cholesky']\n",
    "    }\n",
    "    i=1\n",
    "    # Perform 5-fold cross validation\n",
    "    for train_index, test_index in tqdm(skf.split(df, df[\"PE\"])):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        name=f\"fold_{i}\"            \n",
    "        i=i+1\n",
    "        if os.path.isdir(name):\n",
    "            print(\"passed\")\n",
    "        else:\n",
    "            train_new=((train.sample(frac=7/8,random_state=42)))\n",
    "            val_new = train[~train.index.isin(train_new.index)]\n",
    "            train_new=(train_new.reset_index(drop=True))\n",
    "            val_new=(val_new.reset_index(drop=True))\n",
    "            tasks=[\"death_in_30\",\"DVT\",\"PE\",\"PNA\",\"post_aki_status\",\"postop_del\"]\n",
    "            train_new=stack_data(train_new, tasks)\n",
    "            val_new=stack_data(val_new, tasks)\n",
    "            get_model(name, train_new,val_new)\n",
    "        if os.path.isfile(f\"{name}.pickle\"):\n",
    "            with open(f\"{name}.pickle\", 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                X_train=data[0]\n",
    "                X_test=data[1]\n",
    "        else:\n",
    "            X_train=get_biogpt_updated(train[\"AN_PROC_NAME\"], name)\n",
    "            X_test = get_biogpt_updated(test[\"AN_PROC_NAME\"], name)\n",
    "                    \n",
    "            with open(f\"{name}.pickle\", 'wb') as f:\n",
    "                pickle.dump([X_train,X_test], f)\n",
    "        # Prepare training and testing data\n",
    "\n",
    "        y_train = train[outcome_col]\n",
    "        y_test = test[outcome_col]\n",
    "\n",
    "        if y_train.isna().any() or y_test.isna().any(): \n",
    "            na_indices = y_train.isna()  \n",
    "            X_train = (X_train[~na_indices])\n",
    "            y_train = (((y_train.dropna())).astype(int)).reset_index(drop=True)\n",
    "            na_indices = y_test.isna()  \n",
    "            X_test = X_test[~na_indices]  \n",
    "            y_test = ((y_test.dropna()).astype(int)).reset_index(drop=True)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        model = LogisticRegression(random_state=42,max_iter=10000)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='average_precision',verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute the AUROC and AUPRC\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "        # Save the scores\n",
    "        auroc_scores.append(auroc)\n",
    "        auprc_scores.append(auprc)\n",
    "        with open(f\"update_{outcome_col}_logreg.pickle\", 'wb') as f:\n",
    "            pickle.dump({\"auprc\":auprc_scores, \"auroc\":auroc_scores}, f)\n",
    "\n",
    "    # Now you can calculate the mean and standard deviation\n",
    "    mean_auroc = np.mean(auroc_scores)\n",
    "    std_auroc = np.std(auroc_scores)\n",
    "    mean_auprc = np.mean(auprc_scores)\n",
    "    std_auprc = np.std(auprc_scores)\n",
    "    \n",
    "    return(f\"metrics: Mean AUROC: {mean_auroc}, SD AUROC: {std_auroc}, Mean AUPRC: {mean_auprc}, SD AUPRC: {std_auprc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # performs the 5-fold for Random Forest\n",
    "def K_fold_val_rf(outcome_col, df):\n",
    "    # Initialize the StratifiedKFold class\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to hold scores\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "\n",
    "    # changed parameters here because initial parameters gave underwhelming results\n",
    "    # so i explored alternative hyperparameters to see if model improves\n",
    "    param_grid = {\n",
    "        'max_depth': [4, None],  # maximum depth of the tree\n",
    "        'min_samples_split': [2, 5],  # minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 3],  # minimum number of samples required to be at a leaf node\n",
    "        }\n",
    "    i=1\n",
    "    # Perform 5-fold cross validation\n",
    "    for train_index, test_index in tqdm(skf.split(df, df[\"PE\"])):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        name=f\"fold_{i}\"            \n",
    "        i=i+1\n",
    "        if os.path.isdir(name):\n",
    "            print(\"passed\")\n",
    "        else:\n",
    "            train_new=((train.sample(frac=7/8,random_state=42)))\n",
    "            val_new = train[~train.index.isin(train_new.index)]\n",
    "            train_new=(train_new.reset_index(drop=True))\n",
    "            val_new=(val_new.reset_index(drop=True))\n",
    "            tasks=[\"death_in_30\",\"DVT\",\"PE\",\"PNA\",\"post_aki_status\",\"postop_del\"]\n",
    "            train_new=stack_data(train_new, tasks)\n",
    "            val_new=stack_data(val_new, tasks)\n",
    "            get_model(name, train_new,val_new)\n",
    "        if os.path.isfile(f\"{name}.pickle\"):\n",
    "            with open(f\"{name}.pickle\", 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "                X_train=data[0]\n",
    "                X_test=data[1]\n",
    "        else:\n",
    "            X_train=get_biogpt_updated(train[\"AN_PROC_NAME\"], name)\n",
    "            X_test = get_biogpt_updated(test[\"AN_PROC_NAME\"], name)\n",
    "                    \n",
    "            with open(f\"{name}.pickle\", 'wb') as f:\n",
    "                pickle.dump([X_train,X_test], f)\n",
    "        # Prepare training and testing data\n",
    "\n",
    "        y_train = train[outcome_col]\n",
    "        y_test = test[outcome_col]\n",
    "\n",
    "        if y_train.isna().any() or y_test.isna().any(): \n",
    "            na_indices = y_train.isna()  \n",
    "            X_train = (X_train[~na_indices])\n",
    "            y_train = (((y_train.dropna())).astype(int)).reset_index(drop=True)\n",
    "            na_indices = y_test.isna()  \n",
    "            X_test = X_test[~na_indices]  \n",
    "            y_test = ((y_test.dropna()).astype(int)).reset_index(drop=True)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='average_precision',verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute the AUROC and AUPRC\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "        # Save the scores\n",
    "        auroc_scores.append(auroc)\n",
    "        auprc_scores.append(auprc)\n",
    "        with open(f\"update_{outcome_col}_rf.pickle\", 'wb') as f:\n",
    "            pickle.dump({\"auprc\":auprc_scores, \"auroc\":auroc_scores}, f)\n",
    "\n",
    "    # Now you can calculate the mean and standard deviation\n",
    "    mean_auroc = np.mean(auroc_scores)\n",
    "    std_auroc = np.std(auroc_scores)\n",
    "    mean_auprc = np.mean(auprc_scores)\n",
    "    std_auprc = np.std(auprc_scores)\n",
    "    \n",
    "    return(f\"metrics: Mean AUROC: {mean_auroc}, SD AUROC: {std_auroc}, Mean AUPRC: {mean_auprc}, SD AUPRC: {std_auprc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [05:29, 329.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [11:01, 330.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [16:29, 329.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [21:58, 329.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [27:28, 329.71s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"death_in_30\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Progress 0.0\n",
      "Progress 0.09425625920471281\n",
      "Progress 0.18851251840942562\n",
      "Progress 0.28276877761413843\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.47128129602356406\n",
      "Progress 0.5655375552282769\n",
      "Progress 0.6597938144329897\n",
      "Progress 0.7540500736377025\n",
      "Progress 0.8483063328424153\n",
      "Progress 0.9425625920471281\n",
      "Progress 1.036818851251841\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.2253313696612664\n",
      "Progress 1.3195876288659794\n",
      "Progress 1.4138438880706923\n",
      "Progress 1.508100147275405\n",
      "Progress 1.602356406480118\n",
      "Progress 1.6966126656848306\n",
      "Progress 1.7908689248895433\n",
      "Progress 1.8851251840942562\n",
      "Progress 1.979381443298969\n",
      "Progress 2.073637702503682\n",
      "Progress 2.167893961708395\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.3564064801178204\n",
      "Progress 2.450662739322533\n",
      "Progress 2.544918998527246\n",
      "Progress 2.6391752577319587\n",
      "Progress 2.7334315169366716\n",
      "Progress 2.8276877761413846\n",
      "Progress 2.921944035346097\n",
      "Progress 3.01620029455081\n",
      "Progress 3.110456553755523\n",
      "Progress 3.204712812960236\n",
      "Progress 3.2989690721649487\n",
      "Progress 3.393225331369661\n",
      "Progress 3.487481590574374\n",
      "Progress 3.5817378497790866\n",
      "Progress 3.6759941089837995\n",
      "Progress 3.7702503681885124\n",
      "Progress 3.864506627393225\n",
      "Progress 3.958762886597938\n",
      "Progress 4.053019145802652\n",
      "Progress 4.147275405007364\n",
      "Progress 4.241531664212077\n",
      "Progress 4.33578792341679\n",
      "Progress 4.4300441826215025\n",
      "Progress 4.524300441826215\n",
      "Progress 4.618556701030927\n",
      "Progress 4.712812960235641\n",
      "Progress 4.807069219440353\n",
      "Progress 4.901325478645066\n",
      "Progress 4.995581737849779\n",
      "Progress 5.089837997054492\n",
      "Progress 5.184094256259205\n",
      "Progress 5.278350515463917\n",
      "Progress 5.372606774668631\n",
      "Progress 5.466863033873343\n",
      "Progress 5.561119293078056\n",
      "Progress 5.655375552282769\n",
      "Progress 5.749631811487482\n",
      "Progress 5.843888070692194\n",
      "Progress 5.938144329896907\n",
      "Progress 6.03240058910162\n",
      "Progress 6.126656848306332\n",
      "Progress 6.220913107511046\n",
      "Progress 6.315169366715759\n",
      "Progress 6.409425625920472\n",
      "Progress 6.503681885125184\n",
      "Progress 6.5979381443298974\n",
      "Progress 6.69219440353461\n",
      "Progress 6.786450662739322\n",
      "Progress 6.880706921944036\n",
      "Progress 6.974963181148748\n",
      "Progress 7.069219440353461\n",
      "Progress 7.163475699558173\n",
      "Progress 7.257731958762887\n",
      "Progress 7.351988217967599\n",
      "Progress 7.4462444771723115\n",
      "Progress 7.540500736377025\n",
      "Progress 7.634756995581737\n",
      "Progress 7.72901325478645\n",
      "Progress 7.823269513991163\n",
      "Progress 7.917525773195876\n",
      "Progress 8.011782032400589\n",
      "Progress 8.106038291605303\n",
      "Progress 8.200294550810016\n",
      "Progress 8.294550810014728\n",
      "Progress 8.38880706921944\n",
      "Progress 8.483063328424153\n",
      "Progress 8.577319587628866\n",
      "Progress 8.67157584683358\n",
      "Progress 8.765832106038292\n",
      "Progress 8.860088365243005\n",
      "Progress 8.954344624447717\n",
      "Progress 9.04860088365243\n",
      "Progress 9.142857142857142\n",
      "Progress 9.237113402061855\n",
      "Progress 9.331369661266569\n",
      "Progress 9.425625920471282\n",
      "Progress 9.519882179675994\n",
      "Progress 9.614138438880707\n",
      "Progress 9.708394698085419\n",
      "Progress 9.802650957290131\n",
      "Progress 9.896907216494846\n",
      "Progress 9.991163475699558\n",
      "Progress 10.08541973490427\n",
      "Progress 10.179675994108983\n",
      "Progress 10.273932253313697\n",
      "Progress 10.36818851251841\n",
      "Progress 10.462444771723122\n",
      "Progress 10.556701030927835\n",
      "Progress 10.650957290132549\n",
      "Progress 10.745213549337262\n",
      "Progress 10.839469808541974\n",
      "Progress 10.933726067746687\n",
      "Progress 11.027982326951399\n",
      "Progress 11.122238586156111\n",
      "Progress 11.216494845360824\n",
      "Progress 11.310751104565538\n",
      "Progress 11.40500736377025\n",
      "Progress 11.499263622974963\n",
      "Progress 11.593519882179676\n",
      "Progress 11.687776141384388\n",
      "Progress 11.7820324005891\n",
      "Progress 11.876288659793815\n",
      "Progress 11.970544918998527\n",
      "Progress 12.06480117820324\n",
      "Progress 12.159057437407952\n",
      "Progress 12.253313696612665\n",
      "Progress 12.347569955817377\n",
      "Progress 12.441826215022092\n",
      "Progress 12.536082474226804\n",
      "Progress 12.630338733431518\n",
      "Progress 12.724594992636229\n",
      "Progress 12.818851251840943\n",
      "Progress 12.913107511045654\n",
      "Progress 13.007363770250368\n",
      "Progress 13.10162002945508\n",
      "Progress 13.195876288659795\n",
      "Progress 13.290132547864506\n",
      "Progress 13.38438880706922\n",
      "Progress 13.47864506627393\n",
      "Progress 13.572901325478645\n",
      "Progress 13.667157584683357\n",
      "Progress 13.761413843888072\n",
      "Progress 13.855670103092784\n",
      "Progress 13.949926362297496\n",
      "Progress 14.04418262150221\n",
      "Progress 14.138438880706921\n",
      "Progress 14.232695139911636\n",
      "Progress 14.326951399116346\n",
      "Progress 14.42120765832106\n",
      "Progress 14.515463917525773\n",
      "Progress 14.609720176730487\n",
      "Progress 14.703976435935198\n",
      "Progress 14.798232695139912\n",
      "Progress 14.892488954344623\n",
      "Progress 14.986745213549337\n",
      "Progress 15.08100147275405\n",
      "Progress 15.175257731958764\n",
      "Progress 15.269513991163475\n",
      "Progress 15.363770250368189\n",
      "Progress 15.4580265095729\n",
      "Progress 15.552282768777614\n",
      "Progress 15.646539027982326\n",
      "Progress 15.74079528718704\n",
      "Progress 15.835051546391751\n",
      "Progress 15.929307805596466\n",
      "Progress 16.023564064801178\n",
      "Progress 16.11782032400589\n",
      "Progress 16.212076583210607\n",
      "Progress 16.306332842415316\n",
      "Progress 16.40058910162003\n",
      "Progress 16.49484536082474\n",
      "Progress 16.589101620029457\n",
      "Progress 16.68335787923417\n",
      "Progress 16.77761413843888\n",
      "Progress 16.871870397643594\n",
      "Progress 16.966126656848306\n",
      "Progress 17.06038291605302\n",
      "Progress 17.15463917525773\n",
      "Progress 17.248895434462444\n",
      "Progress 17.34315169366716\n",
      "Progress 17.43740795287187\n",
      "Progress 17.531664212076585\n",
      "Progress 17.625920471281294\n",
      "Progress 17.72017673048601\n",
      "Progress 17.814432989690722\n",
      "Progress 17.908689248895435\n",
      "Progress 18.002945508100147\n",
      "Progress 18.09720176730486\n",
      "Progress 18.191458026509572\n",
      "Progress 18.285714285714285\n",
      "Progress 18.379970544919\n",
      "Progress 18.47422680412371\n",
      "Progress 18.568483063328426\n",
      "Progress 18.662739322533138\n",
      "Progress 18.75699558173785\n",
      "Progress 18.851251840942563\n",
      "Progress 18.945508100147276\n",
      "Progress 19.039764359351988\n",
      "Progress 19.1340206185567\n",
      "Progress 19.228276877761413\n",
      "Progress 19.32253313696613\n",
      "Progress 19.416789396170838\n",
      "Progress 19.511045655375554\n",
      "Progress 19.605301914580263\n",
      "Progress 19.69955817378498\n",
      "Progress 19.79381443298969\n",
      "Progress 19.888070692194404\n",
      "Progress 19.982326951399116\n",
      "Progress 20.07658321060383\n",
      "Progress 20.17083946980854\n",
      "Progress 20.265095729013254\n",
      "Progress 20.359351988217966\n",
      "Progress 20.45360824742268\n",
      "Progress 20.547864506627395\n",
      "Progress 20.642120765832107\n",
      "Progress 20.73637702503682\n",
      "Progress 20.830633284241532\n",
      "Progress 20.924889543446245\n",
      "Progress 21.019145802650957\n",
      "Progress 21.11340206185567\n",
      "Progress 21.207658321060382\n",
      "Progress 21.301914580265098\n",
      "Progress 21.396170839469807\n",
      "Progress 21.490427098674523\n",
      "Progress 21.584683357879232\n",
      "Progress 21.678939617083948\n",
      "Progress 21.77319587628866\n",
      "Progress 21.867452135493373\n",
      "Progress 21.961708394698086\n",
      "Progress 22.055964653902798\n",
      "Progress 22.15022091310751\n",
      "Progress 22.244477172312223\n",
      "Progress 22.338733431516935\n",
      "Progress 22.432989690721648\n",
      "Progress 22.52724594992636\n",
      "Progress 22.621502209131076\n",
      "Progress 22.715758468335785\n",
      "Progress 22.8100147275405\n",
      "Progress 22.904270986745214\n",
      "Progress 22.998527245949926\n",
      "Progress 23.09278350515464\n",
      "Progress 23.18703976435935\n",
      "Progress 23.281296023564067\n",
      "Progress 23.375552282768776\n",
      "Progress 23.469808541973492\n",
      "Progress 23.5640648011782\n",
      "Progress 23.658321060382917\n",
      "Progress 23.75257731958763\n",
      "Progress 23.846833578792342\n",
      "Progress 23.941089837997055\n",
      "Progress 24.035346097201767\n",
      "Progress 24.12960235640648\n",
      "Progress 24.223858615611192\n",
      "Progress 24.318114874815905\n",
      "Progress 24.41237113402062\n",
      "Progress 24.50662739322533\n",
      "Progress 24.600883652430046\n",
      "Progress 24.695139911634755\n",
      "Progress 24.78939617083947\n",
      "Progress 24.883652430044183\n",
      "Progress 24.977908689248896\n",
      "Progress 25.072164948453608\n",
      "Progress 25.166421207658324\n",
      "Progress 25.260677466863036\n",
      "Progress 25.354933726067745\n",
      "Progress 25.449189985272458\n",
      "Progress 25.543446244477174\n",
      "Progress 25.637702503681886\n",
      "Progress 25.7319587628866\n",
      "Progress 25.826215022091308\n",
      "Progress 25.920471281296027\n",
      "Progress 26.014727540500736\n",
      "Progress 26.10898379970545\n",
      "Progress 26.20324005891016\n",
      "Progress 26.297496318114877\n",
      "Progress 26.39175257731959\n",
      "Progress 26.4860088365243\n",
      "Progress 26.58026509572901\n",
      "Progress 26.674521354933727\n",
      "Progress 26.76877761413844\n",
      "Progress 26.863033873343152\n",
      "Progress 26.95729013254786\n",
      "Progress 27.05154639175258\n",
      "Progress 27.14580265095729\n",
      "Progress 27.240058910162002\n",
      "Progress 27.334315169366715\n",
      "Progress 27.42857142857143\n",
      "Progress 27.522827687776143\n",
      "Progress 27.617083946980852\n",
      "Progress 27.711340206185568\n",
      "Progress 27.80559646539028\n",
      "Progress 27.899852724594993\n",
      "Progress 27.994108983799705\n",
      "Progress 28.08836524300442\n",
      "Progress 28.18262150220913\n",
      "Progress 28.276877761413843\n",
      "Progress 28.371134020618555\n",
      "Progress 28.46539027982327\n",
      "Progress 28.559646539027984\n",
      "Progress 28.653902798232693\n",
      "Progress 28.748159057437405\n",
      "Progress 28.84241531664212\n",
      "Progress 28.936671575846834\n",
      "Progress 29.030927835051546\n",
      "Progress 29.125184094256255\n",
      "Progress 29.219440353460975\n",
      "Progress 29.313696612665684\n",
      "Progress 29.407952871870396\n",
      "Progress 29.50220913107511\n",
      "Progress 29.596465390279825\n",
      "Progress 29.690721649484537\n",
      "Progress 29.784977908689246\n",
      "Progress 29.879234167893966\n",
      "Progress 29.973490427098675\n",
      "Progress 30.067746686303387\n",
      "Progress 30.1620029455081\n",
      "Progress 30.256259204712816\n",
      "Progress 30.350515463917528\n",
      "Progress 30.444771723122237\n",
      "Progress 30.53902798232695\n",
      "Progress 30.633284241531666\n",
      "Progress 30.727540500736378\n",
      "Progress 30.82179675994109\n",
      "Progress 30.9160530191458\n",
      "Progress 31.01030927835052\n",
      "Progress 31.104565537555228\n",
      "Progress 31.19882179675994\n",
      "Progress 31.293078055964653\n",
      "Progress 31.38733431516937\n",
      "Progress 31.48159057437408\n",
      "Progress 31.57584683357879\n",
      "Progress 31.670103092783503\n",
      "Progress 31.76435935198822\n",
      "Progress 31.85861561119293\n",
      "Progress 31.952871870397644\n",
      "Progress 32.047128129602356\n",
      "Progress 32.14138438880707\n",
      "Progress 32.23564064801178\n",
      "Progress 32.329896907216494\n",
      "Progress 32.42415316642121\n",
      "Progress 32.51840942562592\n",
      "Progress 32.61266568483063\n",
      "Progress 32.706921944035344\n",
      "Progress 32.80117820324006\n",
      "Progress 32.895434462444776\n",
      "Progress 32.98969072164948\n",
      "Progress 33.08394698085419\n",
      "Progress 33.17820324005891\n",
      "Progress 33.272459499263626\n",
      "Progress 33.36671575846834\n",
      "Progress 33.46097201767304\n",
      "Progress 33.55522827687776\n",
      "Progress 33.649484536082475\n",
      "Progress 33.74374079528719\n",
      "Progress 33.8379970544919\n",
      "Progress 33.93225331369661\n",
      "Progress 34.026509572901325\n",
      "Progress 34.12076583210604\n",
      "Progress 34.21502209131075\n",
      "Progress 34.30927835051546\n",
      "Progress 34.403534609720175\n",
      "Progress 34.49779086892489\n",
      "Progress 34.59204712812961\n",
      "Progress 34.68630338733432\n",
      "Progress 34.780559646539025\n",
      "Progress 34.87481590574374\n",
      "Progress 34.96907216494846\n",
      "Progress 35.06332842415317\n",
      "Progress 35.15758468335788\n",
      "Progress 35.25184094256259\n",
      "Progress 35.34609720176731\n",
      "Progress 35.44035346097202\n",
      "Progress 35.53460972017673\n",
      "Progress 35.628865979381445\n",
      "Progress 35.72312223858616\n",
      "Progress 35.81737849779087\n",
      "Progress 35.91163475699558\n",
      "Progress 36.005891016200295\n",
      "Progress 36.10014727540501\n",
      "Progress 36.19440353460972\n",
      "Progress 36.28865979381443\n",
      "Progress 36.382916053019144\n",
      "Progress 36.47717231222386\n",
      "Progress 36.57142857142857\n",
      "Progress 36.66568483063328\n",
      "Progress 36.759941089838\n",
      "Progress 36.854197349042714\n",
      "Progress 36.94845360824742\n",
      "Progress 37.04270986745213\n",
      "Progress 37.13696612665685\n",
      "Progress 37.231222385861564\n",
      "Progress 37.325478645066276\n",
      "Progress 37.41973490427098\n",
      "Progress 37.5139911634757\n",
      "Progress 37.608247422680414\n",
      "Progress 37.702503681885126\n",
      "Progress 37.79675994108984\n",
      "Progress 37.89101620029455\n",
      "Progress 37.985272459499264\n",
      "Progress 38.079528718703976\n",
      "Progress 38.17378497790869\n",
      "Progress 38.2680412371134\n",
      "Progress 38.362297496318114\n",
      "Progress 38.456553755522826\n",
      "Progress 38.55081001472754\n",
      "Progress 38.64506627393226\n",
      "Progress 38.73932253313696\n",
      "Progress 38.833578792341676\n",
      "Progress 38.927835051546396\n",
      "Progress 39.02209131075111\n",
      "Progress 39.11634756995582\n",
      "Progress 39.210603829160526\n",
      "Progress 39.304860088365245\n",
      "Progress 39.39911634756996\n",
      "Progress 39.49337260677467\n",
      "Progress 39.58762886597938\n",
      "Progress 39.681885125184095\n",
      "Progress 39.77614138438881\n",
      "Progress 39.87039764359352\n",
      "Progress 39.96465390279823\n",
      "Progress 40.058910162002945\n",
      "Progress 40.15316642120766\n",
      "Progress 40.24742268041237\n",
      "Progress 40.34167893961708\n",
      "Progress 40.435935198821795\n",
      "Progress 40.53019145802651\n",
      "Progress 40.62444771723122\n",
      "Progress 40.71870397643593\n",
      "Progress 40.81296023564065\n",
      "Progress 40.90721649484536\n",
      "Progress 41.00147275405007\n",
      "Progress 41.09572901325479\n",
      "Progress 41.1899852724595\n",
      "Progress 41.284241531664215\n",
      "Progress 41.37849779086892\n",
      "Progress 41.47275405007364\n",
      "Progress 41.56701030927835\n",
      "Progress 41.661266568483065\n",
      "Progress 41.75552282768778\n",
      "Progress 41.84977908689249\n",
      "Progress 41.9440353460972\n",
      "Progress 42.038291605301914\n",
      "Progress 42.13254786450663\n",
      "Progress 42.22680412371134\n",
      "Progress 42.32106038291605\n",
      "Progress 42.415316642120764\n",
      "Progress 42.50957290132548\n",
      "Progress 42.603829160530196\n",
      "Progress 42.6980854197349\n",
      "Progress 42.792341678939614\n",
      "Progress 42.88659793814433\n",
      "Progress 42.980854197349046\n",
      "Progress 43.07511045655376\n",
      "Progress 43.169366715758464\n",
      "Progress 43.26362297496318\n",
      "Progress 43.357879234167896\n",
      "Progress 43.45213549337261\n",
      "Progress 43.54639175257732\n",
      "Progress 43.640648011782034\n",
      "Progress 43.734904270986746\n",
      "Progress 43.82916053019146\n",
      "Progress 43.92341678939617\n",
      "Progress 44.017673048600884\n",
      "Progress 44.111929307805596\n",
      "Progress 44.20618556701031\n",
      "Progress 44.30044182621502\n",
      "Progress 44.39469808541973\n",
      "Progress 44.488954344624446\n",
      "Progress 44.58321060382916\n",
      "Progress 44.67746686303387\n",
      "Progress 44.77172312223859\n",
      "Progress 44.865979381443296\n",
      "Progress 44.96023564064801\n",
      "Progress 45.05449189985272\n",
      "Progress 45.14874815905744\n",
      "Progress 45.24300441826215\n",
      "Progress 45.33726067746686\n",
      "Progress 45.43151693667157\n",
      "Progress 45.52577319587629\n",
      "Progress 45.620029455081\n",
      "Progress 45.714285714285715\n",
      "Progress 45.80854197349043\n",
      "Progress 45.90279823269514\n",
      "Progress 45.99705449189985\n",
      "Progress 46.091310751104565\n",
      "Progress 46.18556701030928\n",
      "Progress 46.27982326951399\n",
      "Progress 46.3740795287187\n",
      "Progress 46.468335787923415\n",
      "Progress 46.562592047128135\n",
      "Progress 46.65684830633284\n",
      "Progress 46.75110456553755\n",
      "Progress 46.845360824742265\n",
      "Progress 46.939617083946985\n",
      "Progress 47.0338733431517\n",
      "Progress 47.1281296023564\n",
      "Progress 47.222385861561115\n",
      "Progress 47.316642120765835\n",
      "Progress 47.41089837997055\n",
      "Progress 47.50515463917526\n",
      "Progress 47.599410898379965\n",
      "Progress 47.693667157584684\n",
      "Progress 47.7879234167894\n",
      "Progress 47.88217967599411\n",
      "Progress 47.97643593519882\n",
      "Progress 48.070692194403534\n",
      "Progress 48.16494845360825\n",
      "Progress 48.25920471281296\n",
      "Progress 48.35346097201768\n",
      "Progress 48.447717231222384\n",
      "Progress 48.5419734904271\n",
      "Progress 48.63622974963181\n",
      "Progress 48.73048600883653\n",
      "Progress 48.82474226804124\n",
      "Progress 48.91899852724595\n",
      "Progress 49.01325478645066\n",
      "Progress 49.10751104565538\n",
      "Progress 49.20176730486009\n",
      "Progress 49.296023564064804\n",
      "Progress 49.39027982326951\n",
      "Progress 49.48453608247423\n",
      "Progress 49.57879234167894\n",
      "Progress 49.673048600883654\n",
      "Progress 49.767304860088366\n",
      "Progress 49.86156111929308\n",
      "Progress 49.95581737849779\n",
      "Progress 50.05007363770251\n",
      "Progress 50.144329896907216\n",
      "Progress 50.23858615611193\n",
      "Progress 50.33284241531665\n",
      "Progress 50.42709867452135\n",
      "Progress 50.52135493372607\n",
      "Progress 50.61561119293078\n",
      "Progress 50.70986745213549\n",
      "Progress 50.80412371134021\n",
      "Progress 50.898379970544916\n",
      "Progress 50.992636229749635\n",
      "Progress 51.08689248895435\n",
      "Progress 51.18114874815905\n",
      "Progress 51.27540500736377\n",
      "Progress 51.36966126656848\n",
      "Progress 51.4639175257732\n",
      "Progress 51.55817378497791\n",
      "Progress 51.652430044182616\n",
      "Progress 51.746686303387335\n",
      "Progress 51.840942562592055\n",
      "Progress 51.93519882179676\n",
      "Progress 52.02945508100147\n",
      "Progress 52.12371134020618\n",
      "Progress 52.2179675994109\n",
      "Progress 52.31222385861562\n",
      "Progress 52.40648011782032\n",
      "Progress 52.500736377025035\n",
      "Progress 52.594992636229755\n",
      "Progress 52.68924889543446\n",
      "Progress 52.78350515463918\n",
      "Progress 52.87776141384389\n",
      "Progress 52.9720176730486\n",
      "Progress 53.06627393225332\n",
      "Progress 53.16053019145802\n",
      "Progress 53.25478645066274\n",
      "Progress 53.349042709867454\n",
      "Progress 53.44329896907216\n",
      "Progress 53.53755522827688\n",
      "Progress 53.6318114874816\n",
      "Progress 53.726067746686304\n",
      "Progress 53.82032400589102\n",
      "Progress 53.91458026509572\n",
      "Progress 54.00883652430044\n",
      "Progress 54.10309278350516\n",
      "Progress 54.19734904270987\n",
      "Progress 54.29160530191458\n",
      "Progress 54.3858615611193\n",
      "Progress 54.480117820324004\n",
      "Progress 54.574374079528724\n",
      "Progress 54.66863033873343\n",
      "Progress 54.76288659793814\n",
      "Progress 54.85714285714286\n",
      "Progress 54.95139911634757\n",
      "Progress 55.045655375552286\n",
      "Progress 55.139911634757\n",
      "Progress 55.234167893961704\n",
      "Progress 55.328424153166424\n",
      "Progress 55.422680412371136\n",
      "Progress 55.51693667157585\n",
      "Progress 55.61119293078056\n",
      "Progress 55.705449189985266\n",
      "Progress 55.799705449189986\n",
      "Progress 55.8939617083947\n",
      "Progress 55.98821796759941\n",
      "Progress 56.08247422680412\n",
      "Progress 56.17673048600884\n",
      "Progress 56.27098674521355\n",
      "Progress 56.36524300441826\n",
      "Progress 56.45949926362297\n",
      "Progress 56.553755522827686\n",
      "Progress 56.648011782032405\n",
      "Progress 56.74226804123711\n",
      "Progress 56.83652430044182\n",
      "Progress 56.93078055964654\n",
      "Progress 57.02503681885125\n",
      "Progress 57.11929307805597\n",
      "Progress 57.21354933726068\n",
      "Progress 57.307805596465386\n",
      "Progress 57.402061855670105\n",
      "Progress 57.49631811487481\n",
      "Progress 57.59057437407953\n",
      "Progress 57.68483063328424\n",
      "Progress 57.77908689248895\n",
      "Progress 57.87334315169367\n",
      "Progress 57.96759941089839\n",
      "Progress 58.06185567010309\n",
      "Progress 58.156111929307805\n",
      "Progress 58.25036818851251\n",
      "Progress 58.34462444771723\n",
      "Progress 58.43888070692195\n",
      "Progress 58.533136966126655\n",
      "Progress 58.62739322533137\n",
      "Progress 58.72164948453609\n",
      "Progress 58.81590574374079\n",
      "Progress 58.91016200294551\n",
      "Progress 59.00441826215022\n",
      "Progress 59.09867452135493\n",
      "Progress 59.19293078055965\n",
      "Progress 59.287187039764355\n",
      "Progress 59.381443298969074\n",
      "Progress 59.47569955817379\n",
      "Progress 59.56995581737849\n",
      "Progress 59.66421207658321\n",
      "Progress 59.75846833578793\n",
      "Progress 59.85272459499264\n",
      "Progress 59.94698085419735\n",
      "Progress 60.041237113402055\n",
      "Progress 60.135493372606774\n",
      "Progress 60.229749631811494\n",
      "Progress 60.3240058910162\n",
      "Progress 60.41826215022091\n",
      "Progress 60.51251840942563\n",
      "Progress 60.60677466863034\n",
      "Progress 60.701030927835056\n",
      "Progress 60.79528718703976\n",
      "Progress 60.889543446244474\n",
      "Progress 60.983799705449194\n",
      "Progress 61.0780559646539\n",
      "Progress 61.17231222385862\n",
      "Progress 61.26656848306333\n",
      "Progress 61.360824742268036\n",
      "Progress 61.455081001472756\n",
      "Progress 61.54933726067746\n",
      "Progress 61.64359351988218\n",
      "Progress 61.73784977908689\n",
      "Progress 61.8321060382916\n",
      "Progress 61.92636229749632\n",
      "Progress 62.02061855670104\n",
      "Progress 62.11487481590574\n",
      "Progress 62.209131075110456\n",
      "Progress 62.303387334315175\n",
      "Progress 62.39764359351988\n",
      "Progress 62.4918998527246\n",
      "Progress 62.586156111929306\n",
      "Progress 62.68041237113402\n",
      "Progress 62.77466863033874\n",
      "Progress 62.86892488954344\n",
      "Progress 62.96318114874816\n",
      "Progress 63.057437407952875\n",
      "Progress 63.15169366715758\n",
      "Progress 63.2459499263623\n",
      "Progress 63.340206185567006\n",
      "Progress 63.434462444771725\n",
      "Progress 63.52871870397644\n",
      "Progress 63.62297496318114\n",
      "Progress 63.71723122238586\n",
      "Progress 63.811487481590575\n",
      "Progress 63.90574374079529\n",
      "Progress 64.0\n",
      "Progress 64.09425625920471\n",
      "Progress 64.18851251840942\n",
      "Progress 64.28276877761414\n",
      "Progress 64.37702503681885\n",
      "Progress 64.47128129602356\n",
      "Progress 64.56553755522827\n",
      "Progress 64.65979381443299\n",
      "Progress 64.7540500736377\n",
      "Progress 64.84830633284243\n",
      "Progress 64.94256259204712\n",
      "Progress 65.03681885125184\n",
      "Progress 65.13107511045655\n",
      "Progress 65.22533136966126\n",
      "Progress 65.31958762886599\n",
      "Progress 65.41384388807069\n",
      "Progress 65.5081001472754\n",
      "Progress 65.60235640648013\n",
      "Progress 65.69661266568482\n",
      "Progress 65.79086892488955\n",
      "Progress 65.88512518409425\n",
      "Progress 65.97938144329896\n",
      "Progress 66.07363770250369\n",
      "Progress 66.16789396170839\n",
      "Progress 66.26215022091311\n",
      "Progress 66.35640648011783\n",
      "Progress 66.45066273932252\n",
      "Progress 66.54491899852725\n",
      "Progress 66.63917525773196\n",
      "Progress 66.73343151693668\n",
      "Progress 66.82768777614139\n",
      "Progress 66.92194403534609\n",
      "Progress 67.01620029455081\n",
      "Progress 67.11045655375553\n",
      "Progress 67.20471281296024\n",
      "Progress 67.29896907216495\n",
      "Progress 67.39322533136966\n",
      "Progress 67.48748159057438\n",
      "Progress 67.58173784977909\n",
      "Progress 67.6759941089838\n",
      "Progress 67.77025036818851\n",
      "Progress 67.86450662739323\n",
      "Progress 67.95876288659794\n",
      "Progress 68.05301914580265\n",
      "Progress 68.14727540500736\n",
      "Progress 68.24153166421208\n",
      "Progress 68.33578792341679\n",
      "Progress 68.4300441826215\n",
      "Progress 68.52430044182621\n",
      "Progress 68.61855670103093\n",
      "Progress 68.71281296023564\n",
      "Progress 68.80706921944035\n",
      "Progress 68.90132547864508\n",
      "Progress 68.99558173784978\n",
      "Progress 69.08983799705449\n",
      "Progress 69.18409425625921\n",
      "Progress 69.27835051546391\n",
      "Progress 69.37260677466864\n",
      "Progress 69.46686303387334\n",
      "Progress 69.56111929307805\n",
      "Progress 69.65537555228278\n",
      "Progress 69.74963181148748\n",
      "Progress 69.8438880706922\n",
      "Progress 69.93814432989691\n",
      "Progress 70.03240058910161\n",
      "Progress 70.12665684830634\n",
      "Progress 70.22091310751104\n",
      "Progress 70.31516936671576\n",
      "Progress 70.40942562592048\n",
      "Progress 70.50368188512518\n",
      "Progress 70.5979381443299\n",
      "Progress 70.69219440353461\n",
      "Progress 70.78645066273933\n",
      "Progress 70.88070692194404\n",
      "Progress 70.97496318114875\n",
      "Progress 71.06921944035346\n",
      "Progress 71.16347569955818\n",
      "Progress 71.25773195876289\n",
      "Progress 71.3519882179676\n",
      "Progress 71.44624447717231\n",
      "Progress 71.54050073637703\n",
      "Progress 71.63475699558174\n",
      "Progress 71.72901325478645\n",
      "Progress 71.82326951399116\n",
      "Progress 71.91752577319588\n",
      "Progress 72.01178203240059\n",
      "Progress 72.1060382916053\n",
      "Progress 72.20029455081001\n",
      "Progress 72.29455081001473\n",
      "Progress 72.38880706921944\n",
      "Progress 72.48306332842415\n",
      "Progress 72.57731958762886\n",
      "Progress 72.67157584683358\n",
      "Progress 72.76583210603829\n",
      "Progress 72.860088365243\n",
      "Progress 72.95434462444771\n",
      "Progress 73.04860088365243\n",
      "Progress 73.14285714285714\n",
      "Progress 73.23711340206187\n",
      "Progress 73.33136966126656\n",
      "Progress 73.42562592047128\n",
      "Progress 73.519882179676\n",
      "Progress 73.6141384388807\n",
      "Progress 73.70839469808543\n",
      "Progress 73.80265095729013\n",
      "Progress 73.89690721649484\n",
      "Progress 73.99116347569957\n",
      "Progress 74.08541973490426\n",
      "Progress 74.17967599410899\n",
      "Progress 74.2739322533137\n",
      "Progress 74.3681885125184\n",
      "Progress 74.46244477172313\n",
      "Progress 74.55670103092783\n",
      "Progress 74.65095729013255\n",
      "Progress 74.74521354933727\n",
      "Progress 74.83946980854196\n",
      "Progress 74.93372606774669\n",
      "Progress 75.0279823269514\n",
      "Progress 75.12223858615612\n",
      "Progress 75.21649484536083\n",
      "Progress 75.31075110456553\n",
      "Progress 75.40500736377025\n",
      "Progress 75.49926362297496\n",
      "Progress 75.59351988217968\n",
      "Progress 75.68777614138439\n",
      "Progress 75.7820324005891\n",
      "Progress 75.87628865979381\n",
      "Progress 75.97054491899853\n",
      "Progress 76.06480117820324\n",
      "Progress 76.15905743740795\n",
      "Progress 76.25331369661266\n",
      "Progress 76.34756995581738\n",
      "Progress 76.44182621502209\n",
      "Progress 76.5360824742268\n",
      "Progress 76.63033873343151\n",
      "Progress 76.72459499263623\n",
      "Progress 76.81885125184095\n",
      "Progress 76.91310751104565\n",
      "Progress 77.00736377025036\n",
      "Progress 77.10162002945508\n",
      "Progress 77.19587628865979\n",
      "Progress 77.29013254786452\n",
      "Progress 77.38438880706921\n",
      "Progress 77.47864506627393\n",
      "Progress 77.57290132547865\n",
      "Progress 77.66715758468335\n",
      "Progress 77.76141384388808\n",
      "Progress 77.85567010309279\n",
      "Progress 77.94992636229749\n",
      "Progress 78.04418262150222\n",
      "Progress 78.13843888070691\n",
      "Progress 78.23269513991164\n",
      "Progress 78.32695139911635\n",
      "Progress 78.42120765832105\n",
      "Progress 78.51546391752578\n",
      "Progress 78.60972017673049\n",
      "Progress 78.7039764359352\n",
      "Progress 78.79823269513992\n",
      "Progress 78.89248895434461\n",
      "Progress 78.98674521354934\n",
      "Progress 79.08100147275405\n",
      "Progress 79.17525773195877\n",
      "Progress 79.26951399116348\n",
      "Progress 79.36377025036819\n",
      "Progress 79.4580265095729\n",
      "Progress 79.55228276877762\n",
      "Progress 79.64653902798233\n",
      "Progress 79.74079528718704\n",
      "Progress 79.83505154639175\n",
      "Progress 79.92930780559647\n",
      "Progress 80.02356406480118\n",
      "Progress 80.11782032400589\n",
      "Progress 80.2120765832106\n",
      "Progress 80.30633284241532\n",
      "Progress 80.40058910162003\n",
      "Progress 80.49484536082474\n",
      "Progress 80.58910162002945\n",
      "Progress 80.68335787923417\n",
      "Progress 80.77761413843888\n",
      "Progress 80.87187039764359\n",
      "Progress 80.9661266568483\n",
      "Progress 81.06038291605302\n",
      "Progress 81.15463917525774\n",
      "Progress 81.24889543446244\n",
      "Progress 81.34315169366715\n",
      "Progress 81.43740795287187\n",
      "Progress 81.53166421207658\n",
      "Progress 81.6259204712813\n",
      "Progress 81.720176730486\n",
      "Progress 81.81443298969072\n",
      "Progress 81.90868924889544\n",
      "Progress 82.00294550810014\n",
      "Progress 82.09720176730487\n",
      "Progress 82.19145802650958\n",
      "Progress 82.28571428571428\n",
      "Progress 82.379970544919\n",
      "Progress 82.4742268041237\n",
      "Progress 82.56848306332843\n",
      "Progress 82.66273932253314\n",
      "Progress 82.75699558173784\n",
      "Progress 82.85125184094257\n",
      "Progress 82.94550810014728\n",
      "Progress 83.03976435935199\n",
      "Progress 83.1340206185567\n",
      "Progress 83.2282768777614\n",
      "Progress 83.32253313696613\n",
      "Progress 83.41678939617084\n",
      "Progress 83.51104565537555\n",
      "Progress 83.60530191458027\n",
      "Progress 83.69955817378498\n",
      "Progress 83.79381443298969\n",
      "Progress 83.8880706921944\n",
      "Progress 83.98232695139912\n",
      "Progress 84.07658321060383\n",
      "Progress 84.17083946980854\n",
      "Progress 84.26509572901325\n",
      "Progress 84.35935198821797\n",
      "Progress 84.45360824742268\n",
      "Progress 84.54786450662739\n",
      "Progress 84.6421207658321\n",
      "Progress 84.73637702503683\n",
      "Progress 84.83063328424153\n",
      "Progress 84.92488954344624\n",
      "Progress 85.01914580265095\n",
      "Progress 85.11340206185567\n",
      "Progress 85.20765832106039\n",
      "Progress 85.30191458026509\n",
      "Progress 85.3961708394698\n",
      "Progress 85.49042709867453\n",
      "Progress 85.58468335787923\n",
      "Progress 85.67893961708396\n",
      "Progress 85.77319587628865\n",
      "Progress 85.86745213549337\n",
      "Progress 85.96170839469809\n",
      "Progress 86.05596465390279\n",
      "Progress 86.15022091310752\n",
      "Progress 86.24447717231223\n",
      "Progress 86.33873343151693\n",
      "Progress 86.43298969072166\n",
      "Progress 86.52724594992635\n",
      "Progress 86.62150220913108\n",
      "Progress 86.71575846833579\n",
      "Progress 86.81001472754049\n",
      "Progress 86.90427098674522\n",
      "Progress 86.99852724594993\n",
      "Progress 87.09278350515464\n",
      "Progress 87.18703976435935\n",
      "Progress 87.28129602356407\n",
      "Progress 87.37555228276878\n",
      "Progress 87.46980854197349\n",
      "Progress 87.5640648011782\n",
      "Progress 87.65832106038292\n",
      "Progress 87.75257731958763\n",
      "Progress 87.84683357879234\n",
      "Progress 87.94108983799705\n",
      "Progress 88.03534609720177\n",
      "Progress 88.12960235640648\n",
      "Progress 88.22385861561119\n",
      "Progress 88.3181148748159\n",
      "Progress 88.41237113402062\n",
      "Progress 88.50662739322533\n",
      "Progress 88.60088365243004\n",
      "Progress 88.69513991163475\n",
      "Progress 88.78939617083947\n",
      "Progress 88.88365243004418\n",
      "Progress 88.97790868924889\n",
      "Progress 89.07216494845362\n",
      "Progress 89.16642120765832\n",
      "Progress 89.26067746686303\n",
      "Progress 89.35493372606774\n",
      "Progress 89.44918998527245\n",
      "Progress 89.54344624447718\n",
      "Progress 89.63770250368188\n",
      "Progress 89.73195876288659\n",
      "Progress 89.82621502209132\n",
      "Progress 89.92047128129602\n",
      "Progress 90.01472754050074\n",
      "Progress 90.10898379970544\n",
      "Progress 90.20324005891015\n",
      "Progress 90.29749631811488\n",
      "Progress 90.39175257731958\n",
      "Progress 90.4860088365243\n",
      "Progress 90.58026509572902\n",
      "Progress 90.67452135493372\n",
      "Progress 90.76877761413844\n",
      "Progress 90.86303387334314\n",
      "Progress 90.95729013254787\n",
      "Progress 91.05154639175258\n",
      "Progress 91.14580265095728\n",
      "Progress 91.240058910162\n",
      "Progress 91.33431516936672\n",
      "Progress 91.42857142857143\n",
      "Progress 91.52282768777614\n",
      "Progress 91.61708394698086\n",
      "Progress 91.71134020618557\n",
      "Progress 91.80559646539028\n",
      "Progress 91.899852724595\n",
      "Progress 91.9941089837997\n",
      "Progress 92.08836524300442\n",
      "Progress 92.18262150220913\n",
      "Progress 92.27687776141384\n",
      "Progress 92.37113402061856\n",
      "Progress 92.46539027982327\n",
      "Progress 92.55964653902798\n",
      "Progress 92.65390279823269\n",
      "Progress 92.7481590574374\n",
      "Progress 92.84241531664212\n",
      "Progress 92.93667157584683\n",
      "Progress 93.03092783505154\n",
      "Progress 93.12518409425627\n",
      "Progress 93.21944035346097\n",
      "Progress 93.31369661266568\n",
      "Progress 93.40795287187039\n",
      "Progress 93.5022091310751\n",
      "Progress 93.59646539027983\n",
      "Progress 93.69072164948453\n",
      "Progress 93.78497790868924\n",
      "Progress 93.87923416789397\n",
      "Progress 93.97349042709867\n",
      "Progress 94.0677466863034\n",
      "Progress 94.1620029455081\n",
      "Progress 94.2562592047128\n",
      "Progress 94.35051546391753\n",
      "Progress 94.44477172312223\n",
      "Progress 94.53902798232696\n",
      "Progress 94.63328424153167\n",
      "Progress 94.72754050073637\n",
      "Progress 94.8217967599411\n",
      "Progress 94.9160530191458\n",
      "Progress 95.01030927835052\n",
      "Progress 95.10456553755523\n",
      "Progress 95.19882179675993\n",
      "Progress 95.29307805596466\n",
      "Progress 95.38733431516937\n",
      "Progress 95.48159057437408\n",
      "Progress 95.5758468335788\n",
      "Progress 95.6701030927835\n",
      "Progress 95.76435935198822\n",
      "Progress 95.85861561119293\n",
      "Progress 95.95287187039764\n",
      "Progress 96.04712812960236\n",
      "Progress 96.14138438880707\n",
      "Progress 96.23564064801178\n",
      "Progress 96.3298969072165\n",
      "Progress 96.4241531664212\n",
      "Progress 96.51840942562592\n",
      "Progress 96.61266568483063\n",
      "Progress 96.70692194403536\n",
      "Progress 96.80117820324006\n",
      "Progress 96.89543446244477\n",
      "Progress 96.98969072164948\n",
      "Progress 97.0839469808542\n",
      "Progress 97.17820324005892\n",
      "Progress 97.27245949926362\n",
      "Progress 97.36671575846833\n",
      "Progress 97.46097201767306\n",
      "Progress 97.55522827687776\n",
      "Progress 97.64948453608248\n",
      "Progress 97.74374079528718\n",
      "Progress 97.8379970544919\n",
      "Progress 97.93225331369662\n",
      "Progress 98.02650957290132\n",
      "Progress 98.12076583210604\n",
      "Progress 98.21502209131076\n",
      "Progress 98.30927835051546\n",
      "Progress 98.40353460972018\n",
      "Progress 98.4977908689249\n",
      "Progress 98.59204712812961\n",
      "Progress 98.68630338733432\n",
      "Progress 98.78055964653902\n",
      "Progress 98.87481590574374\n",
      "Progress 98.96907216494846\n",
      "Progress 99.06332842415317\n",
      "Progress 99.15758468335788\n",
      "Progress 99.2518409425626\n",
      "Progress 99.34609720176731\n",
      "Progress 99.44035346097202\n",
      "Progress 99.53460972017673\n",
      "Progress 99.62886597938144\n",
      "Progress 99.72312223858616\n",
      "Progress 99.81737849779087\n",
      "Progress 99.91163475699558\n",
      "Progress 0.0\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.7540500736377025\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.508100147275405\n",
      "Progress 1.8851251840942562\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.6391752577319587\n",
      "Progress 3.01620029455081\n",
      "Progress 3.393225331369661\n",
      "Progress 3.7702503681885124\n",
      "Progress 4.147275405007364\n",
      "Progress 4.524300441826215\n",
      "Progress 4.901325478645066\n",
      "Progress 5.278350515463917\n",
      "Progress 5.655375552282769\n",
      "Progress 6.03240058910162\n",
      "Progress 6.409425625920472\n",
      "Progress 6.786450662739322\n",
      "Progress 7.163475699558173\n",
      "Progress 7.540500736377025\n",
      "Progress 7.917525773195876\n",
      "Progress 8.294550810014728\n",
      "Progress 8.67157584683358\n",
      "Progress 9.04860088365243\n",
      "Progress 9.425625920471282\n",
      "Progress 9.802650957290131\n",
      "Progress 10.179675994108983\n",
      "Progress 10.556701030927835\n",
      "Progress 10.933726067746687\n",
      "Progress 11.310751104565538\n",
      "Progress 11.687776141384388\n",
      "Progress 12.06480117820324\n",
      "Progress 12.441826215022092\n",
      "Progress 12.818851251840943\n",
      "Progress 13.195876288659795\n",
      "Progress 13.572901325478645\n",
      "Progress 13.949926362297496\n",
      "Progress 14.326951399116346\n",
      "Progress 14.703976435935198\n",
      "Progress 15.08100147275405\n",
      "Progress 15.4580265095729\n",
      "Progress 15.835051546391751\n",
      "Progress 16.212076583210607\n",
      "Progress 16.589101620029457\n",
      "Progress 16.966126656848306\n",
      "Progress 17.34315169366716\n",
      "Progress 17.72017673048601\n",
      "Progress 18.09720176730486\n",
      "Progress 18.47422680412371\n",
      "Progress 18.851251840942563\n",
      "Progress 19.228276877761413\n",
      "Progress 19.605301914580263\n",
      "Progress 19.982326951399116\n",
      "Progress 20.359351988217966\n",
      "Progress 20.73637702503682\n",
      "Progress 21.11340206185567\n",
      "Progress 21.490427098674523\n",
      "Progress 21.867452135493373\n",
      "Progress 22.244477172312223\n",
      "Progress 22.621502209131076\n",
      "Progress 22.998527245949926\n",
      "Progress 23.375552282768776\n",
      "Progress 23.75257731958763\n",
      "Progress 24.12960235640648\n",
      "Progress 24.50662739322533\n",
      "Progress 24.883652430044183\n",
      "Progress 25.260677466863036\n",
      "Progress 25.637702503681886\n",
      "Progress 26.014727540500736\n",
      "Progress 26.39175257731959\n",
      "Progress 26.76877761413844\n",
      "Progress 27.14580265095729\n",
      "Progress 27.522827687776143\n",
      "Progress 27.899852724594993\n",
      "Progress 28.276877761413843\n",
      "Progress 28.653902798232693\n",
      "Progress 29.030927835051546\n",
      "Progress 29.407952871870396\n",
      "Progress 29.784977908689246\n",
      "Progress 30.1620029455081\n",
      "Progress 30.53902798232695\n",
      "Progress 30.9160530191458\n",
      "Progress 31.293078055964653\n",
      "Progress 31.670103092783503\n",
      "Progress 32.047128129602356\n",
      "Progress 32.42415316642121\n",
      "Progress 32.80117820324006\n",
      "Progress 33.17820324005891\n",
      "Progress 33.55522827687776\n",
      "Progress 33.93225331369661\n",
      "Progress 34.30927835051546\n",
      "Progress 34.68630338733432\n",
      "Progress 35.06332842415317\n",
      "Progress 35.44035346097202\n",
      "Progress 35.81737849779087\n",
      "Progress 36.19440353460972\n",
      "Progress 36.57142857142857\n",
      "Progress 36.94845360824742\n",
      "Progress 37.325478645066276\n",
      "Progress 37.702503681885126\n",
      "Progress 38.079528718703976\n",
      "Progress 38.456553755522826\n",
      "Progress 38.833578792341676\n",
      "Progress 39.210603829160526\n",
      "Progress 39.58762886597938\n",
      "Progress 39.96465390279823\n",
      "Progress 40.34167893961708\n",
      "Progress 40.71870397643593\n",
      "Progress 41.09572901325479\n",
      "Progress 41.47275405007364\n",
      "Progress 41.84977908689249\n",
      "Progress 42.22680412371134\n",
      "Progress 42.603829160530196\n",
      "Progress 42.980854197349046\n",
      "Progress 43.357879234167896\n",
      "Progress 43.734904270986746\n",
      "Progress 44.111929307805596\n",
      "Progress 44.488954344624446\n",
      "Progress 44.865979381443296\n",
      "Progress 45.24300441826215\n",
      "Progress 45.620029455081\n",
      "Progress 45.99705449189985\n",
      "Progress 46.3740795287187\n",
      "Progress 46.75110456553755\n",
      "Progress 47.1281296023564\n",
      "Progress 47.50515463917526\n",
      "Progress 47.88217967599411\n",
      "Progress 48.25920471281296\n",
      "Progress 48.63622974963181\n",
      "Progress 49.01325478645066\n",
      "Progress 49.39027982326951\n",
      "Progress 49.767304860088366\n",
      "Progress 50.144329896907216\n",
      "Progress 50.52135493372607\n",
      "Progress 50.898379970544916\n",
      "Progress 51.27540500736377\n",
      "Progress 51.652430044182616\n",
      "Progress 52.02945508100147\n",
      "Progress 52.40648011782032\n",
      "Progress 52.78350515463918\n",
      "Progress 53.16053019145802\n",
      "Progress 53.53755522827688\n",
      "Progress 53.91458026509572\n",
      "Progress 54.29160530191458\n",
      "Progress 54.66863033873343\n",
      "Progress 55.045655375552286\n",
      "Progress 55.422680412371136\n",
      "Progress 55.799705449189986\n",
      "Progress 56.17673048600884\n",
      "Progress 56.553755522827686\n",
      "Progress 56.93078055964654\n",
      "Progress 57.307805596465386\n",
      "Progress 57.68483063328424\n",
      "Progress 58.06185567010309\n",
      "Progress 58.43888070692195\n",
      "Progress 58.81590574374079\n",
      "Progress 59.19293078055965\n",
      "Progress 59.56995581737849\n",
      "Progress 59.94698085419735\n",
      "Progress 60.3240058910162\n",
      "Progress 60.701030927835056\n",
      "Progress 61.0780559646539\n",
      "Progress 61.455081001472756\n",
      "Progress 61.8321060382916\n",
      "Progress 62.209131075110456\n",
      "Progress 62.586156111929306\n",
      "Progress 62.96318114874816\n",
      "Progress 63.340206185567006\n",
      "Progress 63.71723122238586\n",
      "Progress 64.09425625920471\n",
      "Progress 64.47128129602356\n",
      "Progress 64.84830633284243\n",
      "Progress 65.22533136966126\n",
      "Progress 65.60235640648013\n",
      "Progress 65.97938144329896\n",
      "Progress 66.35640648011783\n",
      "Progress 66.73343151693668\n",
      "Progress 67.11045655375553\n",
      "Progress 67.48748159057438\n",
      "Progress 67.86450662739323\n",
      "Progress 68.24153166421208\n",
      "Progress 68.61855670103093\n",
      "Progress 68.99558173784978\n",
      "Progress 69.37260677466864\n",
      "Progress 69.74963181148748\n",
      "Progress 70.12665684830634\n",
      "Progress 70.50368188512518\n",
      "Progress 70.88070692194404\n",
      "Progress 71.25773195876289\n",
      "Progress 71.63475699558174\n",
      "Progress 72.01178203240059\n",
      "Progress 72.38880706921944\n",
      "Progress 72.76583210603829\n",
      "Progress 73.14285714285714\n",
      "Progress 73.519882179676\n",
      "Progress 73.89690721649484\n",
      "Progress 74.2739322533137\n",
      "Progress 74.65095729013255\n",
      "Progress 75.0279823269514\n",
      "Progress 75.40500736377025\n",
      "Progress 75.7820324005891\n",
      "Progress 76.15905743740795\n",
      "Progress 76.5360824742268\n",
      "Progress 76.91310751104565\n",
      "Progress 77.29013254786452\n",
      "Progress 77.66715758468335\n",
      "Progress 78.04418262150222\n",
      "Progress 78.42120765832105\n",
      "Progress 78.79823269513992\n",
      "Progress 79.17525773195877\n",
      "Progress 79.55228276877762\n",
      "Progress 79.92930780559647\n",
      "Progress 80.30633284241532\n",
      "Progress 80.68335787923417\n",
      "Progress 81.06038291605302\n",
      "Progress 81.43740795287187\n",
      "Progress 81.81443298969072\n",
      "Progress 82.19145802650958\n",
      "Progress 82.56848306332843\n",
      "Progress 82.94550810014728\n",
      "Progress 83.32253313696613\n",
      "Progress 83.69955817378498\n",
      "Progress 84.07658321060383\n",
      "Progress 84.45360824742268\n",
      "Progress 84.83063328424153\n",
      "Progress 85.20765832106039\n",
      "Progress 85.58468335787923\n",
      "Progress 85.96170839469809\n",
      "Progress 86.33873343151693\n",
      "Progress 86.71575846833579\n",
      "Progress 87.09278350515464\n",
      "Progress 87.46980854197349\n",
      "Progress 87.84683357879234\n",
      "Progress 88.22385861561119\n",
      "Progress 88.60088365243004\n",
      "Progress 88.97790868924889\n",
      "Progress 89.35493372606774\n",
      "Progress 89.73195876288659\n",
      "Progress 90.10898379970544\n",
      "Progress 90.4860088365243\n",
      "Progress 90.86303387334314\n",
      "Progress 91.240058910162\n",
      "Progress 91.61708394698086\n",
      "Progress 91.9941089837997\n",
      "Progress 92.37113402061856\n",
      "Progress 92.7481590574374\n",
      "Progress 93.12518409425627\n",
      "Progress 93.5022091310751\n",
      "Progress 93.87923416789397\n",
      "Progress 94.2562592047128\n",
      "Progress 94.63328424153167\n",
      "Progress 95.01030927835052\n",
      "Progress 95.38733431516937\n",
      "Progress 95.76435935198822\n",
      "Progress 96.14138438880707\n",
      "Progress 96.51840942562592\n",
      "Progress 96.89543446244477\n",
      "Progress 97.27245949926362\n",
      "Progress 97.64948453608248\n",
      "Progress 98.02650957290132\n",
      "Progress 98.40353460972018\n",
      "Progress 98.78055964653902\n",
      "Progress 99.15758468335788\n",
      "Progress 99.53460972017673\n",
      "Progress 99.91163475699558\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   7.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06596e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06167e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06014e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06973e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06934e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.15359469 0.15359515        nan        nan\n",
      " 0.20095624 0.20099716        nan        nan 0.20811396        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [19:20, 1160.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Progress 0.0\n",
      "Progress 0.09425625920471281\n",
      "Progress 0.18851251840942562\n",
      "Progress 0.28276877761413843\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.47128129602356406\n",
      "Progress 0.5655375552282769\n",
      "Progress 0.6597938144329897\n",
      "Progress 0.7540500736377025\n",
      "Progress 0.8483063328424153\n",
      "Progress 0.9425625920471281\n",
      "Progress 1.036818851251841\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.2253313696612664\n",
      "Progress 1.3195876288659794\n",
      "Progress 1.4138438880706923\n",
      "Progress 1.508100147275405\n",
      "Progress 1.602356406480118\n",
      "Progress 1.6966126656848306\n",
      "Progress 1.7908689248895433\n",
      "Progress 1.8851251840942562\n",
      "Progress 1.979381443298969\n",
      "Progress 2.073637702503682\n",
      "Progress 2.167893961708395\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.3564064801178204\n",
      "Progress 2.450662739322533\n",
      "Progress 2.544918998527246\n",
      "Progress 2.6391752577319587\n",
      "Progress 2.7334315169366716\n",
      "Progress 2.8276877761413846\n",
      "Progress 2.921944035346097\n",
      "Progress 3.01620029455081\n",
      "Progress 3.110456553755523\n",
      "Progress 3.204712812960236\n",
      "Progress 3.2989690721649487\n",
      "Progress 3.393225331369661\n",
      "Progress 3.487481590574374\n",
      "Progress 3.5817378497790866\n",
      "Progress 3.6759941089837995\n",
      "Progress 3.7702503681885124\n",
      "Progress 3.864506627393225\n",
      "Progress 3.958762886597938\n",
      "Progress 4.053019145802652\n",
      "Progress 4.147275405007364\n",
      "Progress 4.241531664212077\n",
      "Progress 4.33578792341679\n",
      "Progress 4.4300441826215025\n",
      "Progress 4.524300441826215\n",
      "Progress 4.618556701030927\n",
      "Progress 4.712812960235641\n",
      "Progress 4.807069219440353\n",
      "Progress 4.901325478645066\n",
      "Progress 4.995581737849779\n",
      "Progress 5.089837997054492\n",
      "Progress 5.184094256259205\n",
      "Progress 5.278350515463917\n",
      "Progress 5.372606774668631\n",
      "Progress 5.466863033873343\n",
      "Progress 5.561119293078056\n",
      "Progress 5.655375552282769\n",
      "Progress 5.749631811487482\n",
      "Progress 5.843888070692194\n",
      "Progress 5.938144329896907\n",
      "Progress 6.03240058910162\n",
      "Progress 6.126656848306332\n",
      "Progress 6.220913107511046\n",
      "Progress 6.315169366715759\n",
      "Progress 6.409425625920472\n",
      "Progress 6.503681885125184\n",
      "Progress 6.5979381443298974\n",
      "Progress 6.69219440353461\n",
      "Progress 6.786450662739322\n",
      "Progress 6.880706921944036\n",
      "Progress 6.974963181148748\n",
      "Progress 7.069219440353461\n",
      "Progress 7.163475699558173\n",
      "Progress 7.257731958762887\n",
      "Progress 7.351988217967599\n",
      "Progress 7.4462444771723115\n",
      "Progress 7.540500736377025\n",
      "Progress 7.634756995581737\n",
      "Progress 7.72901325478645\n",
      "Progress 7.823269513991163\n",
      "Progress 7.917525773195876\n",
      "Progress 8.011782032400589\n",
      "Progress 8.106038291605303\n",
      "Progress 8.200294550810016\n",
      "Progress 8.294550810014728\n",
      "Progress 8.38880706921944\n",
      "Progress 8.483063328424153\n",
      "Progress 8.577319587628866\n",
      "Progress 8.67157584683358\n",
      "Progress 8.765832106038292\n",
      "Progress 8.860088365243005\n",
      "Progress 8.954344624447717\n",
      "Progress 9.04860088365243\n",
      "Progress 9.142857142857142\n",
      "Progress 9.237113402061855\n",
      "Progress 9.331369661266569\n",
      "Progress 9.425625920471282\n",
      "Progress 9.519882179675994\n",
      "Progress 9.614138438880707\n",
      "Progress 9.708394698085419\n",
      "Progress 9.802650957290131\n",
      "Progress 9.896907216494846\n",
      "Progress 9.991163475699558\n",
      "Progress 10.08541973490427\n",
      "Progress 10.179675994108983\n",
      "Progress 10.273932253313697\n",
      "Progress 10.36818851251841\n",
      "Progress 10.462444771723122\n",
      "Progress 10.556701030927835\n",
      "Progress 10.650957290132549\n",
      "Progress 10.745213549337262\n",
      "Progress 10.839469808541974\n",
      "Progress 10.933726067746687\n",
      "Progress 11.027982326951399\n",
      "Progress 11.122238586156111\n",
      "Progress 11.216494845360824\n",
      "Progress 11.310751104565538\n",
      "Progress 11.40500736377025\n",
      "Progress 11.499263622974963\n",
      "Progress 11.593519882179676\n",
      "Progress 11.687776141384388\n",
      "Progress 11.7820324005891\n",
      "Progress 11.876288659793815\n",
      "Progress 11.970544918998527\n",
      "Progress 12.06480117820324\n",
      "Progress 12.159057437407952\n",
      "Progress 12.253313696612665\n",
      "Progress 12.347569955817377\n",
      "Progress 12.441826215022092\n",
      "Progress 12.536082474226804\n",
      "Progress 12.630338733431518\n",
      "Progress 12.724594992636229\n",
      "Progress 12.818851251840943\n",
      "Progress 12.913107511045654\n",
      "Progress 13.007363770250368\n",
      "Progress 13.10162002945508\n",
      "Progress 13.195876288659795\n",
      "Progress 13.290132547864506\n",
      "Progress 13.38438880706922\n",
      "Progress 13.47864506627393\n",
      "Progress 13.572901325478645\n",
      "Progress 13.667157584683357\n",
      "Progress 13.761413843888072\n",
      "Progress 13.855670103092784\n",
      "Progress 13.949926362297496\n",
      "Progress 14.04418262150221\n",
      "Progress 14.138438880706921\n",
      "Progress 14.232695139911636\n",
      "Progress 14.326951399116346\n",
      "Progress 14.42120765832106\n",
      "Progress 14.515463917525773\n",
      "Progress 14.609720176730487\n",
      "Progress 14.703976435935198\n",
      "Progress 14.798232695139912\n",
      "Progress 14.892488954344623\n",
      "Progress 14.986745213549337\n",
      "Progress 15.08100147275405\n",
      "Progress 15.175257731958764\n",
      "Progress 15.269513991163475\n",
      "Progress 15.363770250368189\n",
      "Progress 15.4580265095729\n",
      "Progress 15.552282768777614\n",
      "Progress 15.646539027982326\n",
      "Progress 15.74079528718704\n",
      "Progress 15.835051546391751\n",
      "Progress 15.929307805596466\n",
      "Progress 16.023564064801178\n",
      "Progress 16.11782032400589\n",
      "Progress 16.212076583210607\n",
      "Progress 16.306332842415316\n",
      "Progress 16.40058910162003\n",
      "Progress 16.49484536082474\n",
      "Progress 16.589101620029457\n",
      "Progress 16.68335787923417\n",
      "Progress 16.77761413843888\n",
      "Progress 16.871870397643594\n",
      "Progress 16.966126656848306\n",
      "Progress 17.06038291605302\n",
      "Progress 17.15463917525773\n",
      "Progress 17.248895434462444\n",
      "Progress 17.34315169366716\n",
      "Progress 17.43740795287187\n",
      "Progress 17.531664212076585\n",
      "Progress 17.625920471281294\n",
      "Progress 17.72017673048601\n",
      "Progress 17.814432989690722\n",
      "Progress 17.908689248895435\n",
      "Progress 18.002945508100147\n",
      "Progress 18.09720176730486\n",
      "Progress 18.191458026509572\n",
      "Progress 18.285714285714285\n",
      "Progress 18.379970544919\n",
      "Progress 18.47422680412371\n",
      "Progress 18.568483063328426\n",
      "Progress 18.662739322533138\n",
      "Progress 18.75699558173785\n",
      "Progress 18.851251840942563\n",
      "Progress 18.945508100147276\n",
      "Progress 19.039764359351988\n",
      "Progress 19.1340206185567\n",
      "Progress 19.228276877761413\n",
      "Progress 19.32253313696613\n",
      "Progress 19.416789396170838\n",
      "Progress 19.511045655375554\n",
      "Progress 19.605301914580263\n",
      "Progress 19.69955817378498\n",
      "Progress 19.79381443298969\n",
      "Progress 19.888070692194404\n",
      "Progress 19.982326951399116\n",
      "Progress 20.07658321060383\n",
      "Progress 20.17083946980854\n",
      "Progress 20.265095729013254\n",
      "Progress 20.359351988217966\n",
      "Progress 20.45360824742268\n",
      "Progress 20.547864506627395\n",
      "Progress 20.642120765832107\n",
      "Progress 20.73637702503682\n",
      "Progress 20.830633284241532\n",
      "Progress 20.924889543446245\n",
      "Progress 21.019145802650957\n",
      "Progress 21.11340206185567\n",
      "Progress 21.207658321060382\n",
      "Progress 21.301914580265098\n",
      "Progress 21.396170839469807\n",
      "Progress 21.490427098674523\n",
      "Progress 21.584683357879232\n",
      "Progress 21.678939617083948\n",
      "Progress 21.77319587628866\n",
      "Progress 21.867452135493373\n",
      "Progress 21.961708394698086\n",
      "Progress 22.055964653902798\n",
      "Progress 22.15022091310751\n",
      "Progress 22.244477172312223\n",
      "Progress 22.338733431516935\n",
      "Progress 22.432989690721648\n",
      "Progress 22.52724594992636\n",
      "Progress 22.621502209131076\n",
      "Progress 22.715758468335785\n",
      "Progress 22.8100147275405\n",
      "Progress 22.904270986745214\n",
      "Progress 22.998527245949926\n",
      "Progress 23.09278350515464\n",
      "Progress 23.18703976435935\n",
      "Progress 23.281296023564067\n",
      "Progress 23.375552282768776\n",
      "Progress 23.469808541973492\n",
      "Progress 23.5640648011782\n",
      "Progress 23.658321060382917\n",
      "Progress 23.75257731958763\n",
      "Progress 23.846833578792342\n",
      "Progress 23.941089837997055\n",
      "Progress 24.035346097201767\n",
      "Progress 24.12960235640648\n",
      "Progress 24.223858615611192\n",
      "Progress 24.318114874815905\n",
      "Progress 24.41237113402062\n",
      "Progress 24.50662739322533\n",
      "Progress 24.600883652430046\n",
      "Progress 24.695139911634755\n",
      "Progress 24.78939617083947\n",
      "Progress 24.883652430044183\n",
      "Progress 24.977908689248896\n",
      "Progress 25.072164948453608\n",
      "Progress 25.166421207658324\n",
      "Progress 25.260677466863036\n",
      "Progress 25.354933726067745\n",
      "Progress 25.449189985272458\n",
      "Progress 25.543446244477174\n",
      "Progress 25.637702503681886\n",
      "Progress 25.7319587628866\n",
      "Progress 25.826215022091308\n",
      "Progress 25.920471281296027\n",
      "Progress 26.014727540500736\n",
      "Progress 26.10898379970545\n",
      "Progress 26.20324005891016\n",
      "Progress 26.297496318114877\n",
      "Progress 26.39175257731959\n",
      "Progress 26.4860088365243\n",
      "Progress 26.58026509572901\n",
      "Progress 26.674521354933727\n",
      "Progress 26.76877761413844\n",
      "Progress 26.863033873343152\n",
      "Progress 26.95729013254786\n",
      "Progress 27.05154639175258\n",
      "Progress 27.14580265095729\n",
      "Progress 27.240058910162002\n",
      "Progress 27.334315169366715\n",
      "Progress 27.42857142857143\n",
      "Progress 27.522827687776143\n",
      "Progress 27.617083946980852\n",
      "Progress 27.711340206185568\n",
      "Progress 27.80559646539028\n",
      "Progress 27.899852724594993\n",
      "Progress 27.994108983799705\n",
      "Progress 28.08836524300442\n",
      "Progress 28.18262150220913\n",
      "Progress 28.276877761413843\n",
      "Progress 28.371134020618555\n",
      "Progress 28.46539027982327\n",
      "Progress 28.559646539027984\n",
      "Progress 28.653902798232693\n",
      "Progress 28.748159057437405\n",
      "Progress 28.84241531664212\n",
      "Progress 28.936671575846834\n",
      "Progress 29.030927835051546\n",
      "Progress 29.125184094256255\n",
      "Progress 29.219440353460975\n",
      "Progress 29.313696612665684\n",
      "Progress 29.407952871870396\n",
      "Progress 29.50220913107511\n",
      "Progress 29.596465390279825\n",
      "Progress 29.690721649484537\n",
      "Progress 29.784977908689246\n",
      "Progress 29.879234167893966\n",
      "Progress 29.973490427098675\n",
      "Progress 30.067746686303387\n",
      "Progress 30.1620029455081\n",
      "Progress 30.256259204712816\n",
      "Progress 30.350515463917528\n",
      "Progress 30.444771723122237\n",
      "Progress 30.53902798232695\n",
      "Progress 30.633284241531666\n",
      "Progress 30.727540500736378\n",
      "Progress 30.82179675994109\n",
      "Progress 30.9160530191458\n",
      "Progress 31.01030927835052\n",
      "Progress 31.104565537555228\n",
      "Progress 31.19882179675994\n",
      "Progress 31.293078055964653\n",
      "Progress 31.38733431516937\n",
      "Progress 31.48159057437408\n",
      "Progress 31.57584683357879\n",
      "Progress 31.670103092783503\n",
      "Progress 31.76435935198822\n",
      "Progress 31.85861561119293\n",
      "Progress 31.952871870397644\n",
      "Progress 32.047128129602356\n",
      "Progress 32.14138438880707\n",
      "Progress 32.23564064801178\n",
      "Progress 32.329896907216494\n",
      "Progress 32.42415316642121\n",
      "Progress 32.51840942562592\n",
      "Progress 32.61266568483063\n",
      "Progress 32.706921944035344\n",
      "Progress 32.80117820324006\n",
      "Progress 32.895434462444776\n",
      "Progress 32.98969072164948\n",
      "Progress 33.08394698085419\n",
      "Progress 33.17820324005891\n",
      "Progress 33.272459499263626\n",
      "Progress 33.36671575846834\n",
      "Progress 33.46097201767304\n",
      "Progress 33.55522827687776\n",
      "Progress 33.649484536082475\n",
      "Progress 33.74374079528719\n",
      "Progress 33.8379970544919\n",
      "Progress 33.93225331369661\n",
      "Progress 34.026509572901325\n",
      "Progress 34.12076583210604\n",
      "Progress 34.21502209131075\n",
      "Progress 34.30927835051546\n",
      "Progress 34.403534609720175\n",
      "Progress 34.49779086892489\n",
      "Progress 34.59204712812961\n",
      "Progress 34.68630338733432\n",
      "Progress 34.780559646539025\n",
      "Progress 34.87481590574374\n",
      "Progress 34.96907216494846\n",
      "Progress 35.06332842415317\n",
      "Progress 35.15758468335788\n",
      "Progress 35.25184094256259\n",
      "Progress 35.34609720176731\n",
      "Progress 35.44035346097202\n",
      "Progress 35.53460972017673\n",
      "Progress 35.628865979381445\n",
      "Progress 35.72312223858616\n",
      "Progress 35.81737849779087\n",
      "Progress 35.91163475699558\n",
      "Progress 36.005891016200295\n",
      "Progress 36.10014727540501\n",
      "Progress 36.19440353460972\n",
      "Progress 36.28865979381443\n",
      "Progress 36.382916053019144\n",
      "Progress 36.47717231222386\n",
      "Progress 36.57142857142857\n",
      "Progress 36.66568483063328\n",
      "Progress 36.759941089838\n",
      "Progress 36.854197349042714\n",
      "Progress 36.94845360824742\n",
      "Progress 37.04270986745213\n",
      "Progress 37.13696612665685\n",
      "Progress 37.231222385861564\n",
      "Progress 37.325478645066276\n",
      "Progress 37.41973490427098\n",
      "Progress 37.5139911634757\n",
      "Progress 37.608247422680414\n",
      "Progress 37.702503681885126\n",
      "Progress 37.79675994108984\n",
      "Progress 37.89101620029455\n",
      "Progress 37.985272459499264\n",
      "Progress 38.079528718703976\n",
      "Progress 38.17378497790869\n",
      "Progress 38.2680412371134\n",
      "Progress 38.362297496318114\n",
      "Progress 38.456553755522826\n",
      "Progress 38.55081001472754\n",
      "Progress 38.64506627393226\n",
      "Progress 38.73932253313696\n",
      "Progress 38.833578792341676\n",
      "Progress 38.927835051546396\n",
      "Progress 39.02209131075111\n",
      "Progress 39.11634756995582\n",
      "Progress 39.210603829160526\n",
      "Progress 39.304860088365245\n",
      "Progress 39.39911634756996\n",
      "Progress 39.49337260677467\n",
      "Progress 39.58762886597938\n",
      "Progress 39.681885125184095\n",
      "Progress 39.77614138438881\n",
      "Progress 39.87039764359352\n",
      "Progress 39.96465390279823\n",
      "Progress 40.058910162002945\n",
      "Progress 40.15316642120766\n",
      "Progress 40.24742268041237\n",
      "Progress 40.34167893961708\n",
      "Progress 40.435935198821795\n",
      "Progress 40.53019145802651\n",
      "Progress 40.62444771723122\n",
      "Progress 40.71870397643593\n",
      "Progress 40.81296023564065\n",
      "Progress 40.90721649484536\n",
      "Progress 41.00147275405007\n",
      "Progress 41.09572901325479\n",
      "Progress 41.1899852724595\n",
      "Progress 41.284241531664215\n",
      "Progress 41.37849779086892\n",
      "Progress 41.47275405007364\n",
      "Progress 41.56701030927835\n",
      "Progress 41.661266568483065\n",
      "Progress 41.75552282768778\n",
      "Progress 41.84977908689249\n",
      "Progress 41.9440353460972\n",
      "Progress 42.038291605301914\n",
      "Progress 42.13254786450663\n",
      "Progress 42.22680412371134\n",
      "Progress 42.32106038291605\n",
      "Progress 42.415316642120764\n",
      "Progress 42.50957290132548\n",
      "Progress 42.603829160530196\n",
      "Progress 42.6980854197349\n",
      "Progress 42.792341678939614\n",
      "Progress 42.88659793814433\n",
      "Progress 42.980854197349046\n",
      "Progress 43.07511045655376\n",
      "Progress 43.169366715758464\n",
      "Progress 43.26362297496318\n",
      "Progress 43.357879234167896\n",
      "Progress 43.45213549337261\n",
      "Progress 43.54639175257732\n",
      "Progress 43.640648011782034\n",
      "Progress 43.734904270986746\n",
      "Progress 43.82916053019146\n",
      "Progress 43.92341678939617\n",
      "Progress 44.017673048600884\n",
      "Progress 44.111929307805596\n",
      "Progress 44.20618556701031\n",
      "Progress 44.30044182621502\n",
      "Progress 44.39469808541973\n",
      "Progress 44.488954344624446\n",
      "Progress 44.58321060382916\n",
      "Progress 44.67746686303387\n",
      "Progress 44.77172312223859\n",
      "Progress 44.865979381443296\n",
      "Progress 44.96023564064801\n",
      "Progress 45.05449189985272\n",
      "Progress 45.14874815905744\n",
      "Progress 45.24300441826215\n",
      "Progress 45.33726067746686\n",
      "Progress 45.43151693667157\n",
      "Progress 45.52577319587629\n",
      "Progress 45.620029455081\n",
      "Progress 45.714285714285715\n",
      "Progress 45.80854197349043\n",
      "Progress 45.90279823269514\n",
      "Progress 45.99705449189985\n",
      "Progress 46.091310751104565\n",
      "Progress 46.18556701030928\n",
      "Progress 46.27982326951399\n",
      "Progress 46.3740795287187\n",
      "Progress 46.468335787923415\n",
      "Progress 46.562592047128135\n",
      "Progress 46.65684830633284\n",
      "Progress 46.75110456553755\n",
      "Progress 46.845360824742265\n",
      "Progress 46.939617083946985\n",
      "Progress 47.0338733431517\n",
      "Progress 47.1281296023564\n",
      "Progress 47.222385861561115\n",
      "Progress 47.316642120765835\n",
      "Progress 47.41089837997055\n",
      "Progress 47.50515463917526\n",
      "Progress 47.599410898379965\n",
      "Progress 47.693667157584684\n",
      "Progress 47.7879234167894\n",
      "Progress 47.88217967599411\n",
      "Progress 47.97643593519882\n",
      "Progress 48.070692194403534\n",
      "Progress 48.16494845360825\n",
      "Progress 48.25920471281296\n",
      "Progress 48.35346097201768\n",
      "Progress 48.447717231222384\n",
      "Progress 48.5419734904271\n",
      "Progress 48.63622974963181\n",
      "Progress 48.73048600883653\n",
      "Progress 48.82474226804124\n",
      "Progress 48.91899852724595\n",
      "Progress 49.01325478645066\n",
      "Progress 49.10751104565538\n",
      "Progress 49.20176730486009\n",
      "Progress 49.296023564064804\n",
      "Progress 49.39027982326951\n",
      "Progress 49.48453608247423\n",
      "Progress 49.57879234167894\n",
      "Progress 49.673048600883654\n",
      "Progress 49.767304860088366\n",
      "Progress 49.86156111929308\n",
      "Progress 49.95581737849779\n",
      "Progress 50.05007363770251\n",
      "Progress 50.144329896907216\n",
      "Progress 50.23858615611193\n",
      "Progress 50.33284241531665\n",
      "Progress 50.42709867452135\n",
      "Progress 50.52135493372607\n",
      "Progress 50.61561119293078\n",
      "Progress 50.70986745213549\n",
      "Progress 50.80412371134021\n",
      "Progress 50.898379970544916\n",
      "Progress 50.992636229749635\n",
      "Progress 51.08689248895435\n",
      "Progress 51.18114874815905\n",
      "Progress 51.27540500736377\n",
      "Progress 51.36966126656848\n",
      "Progress 51.4639175257732\n",
      "Progress 51.55817378497791\n",
      "Progress 51.652430044182616\n",
      "Progress 51.746686303387335\n",
      "Progress 51.840942562592055\n",
      "Progress 51.93519882179676\n",
      "Progress 52.02945508100147\n",
      "Progress 52.12371134020618\n",
      "Progress 52.2179675994109\n",
      "Progress 52.31222385861562\n",
      "Progress 52.40648011782032\n",
      "Progress 52.500736377025035\n",
      "Progress 52.594992636229755\n",
      "Progress 52.68924889543446\n",
      "Progress 52.78350515463918\n",
      "Progress 52.87776141384389\n",
      "Progress 52.9720176730486\n",
      "Progress 53.06627393225332\n",
      "Progress 53.16053019145802\n",
      "Progress 53.25478645066274\n",
      "Progress 53.349042709867454\n",
      "Progress 53.44329896907216\n",
      "Progress 53.53755522827688\n",
      "Progress 53.6318114874816\n",
      "Progress 53.726067746686304\n",
      "Progress 53.82032400589102\n",
      "Progress 53.91458026509572\n",
      "Progress 54.00883652430044\n",
      "Progress 54.10309278350516\n",
      "Progress 54.19734904270987\n",
      "Progress 54.29160530191458\n",
      "Progress 54.3858615611193\n",
      "Progress 54.480117820324004\n",
      "Progress 54.574374079528724\n",
      "Progress 54.66863033873343\n",
      "Progress 54.76288659793814\n",
      "Progress 54.85714285714286\n",
      "Progress 54.95139911634757\n",
      "Progress 55.045655375552286\n",
      "Progress 55.139911634757\n",
      "Progress 55.234167893961704\n",
      "Progress 55.328424153166424\n",
      "Progress 55.422680412371136\n",
      "Progress 55.51693667157585\n",
      "Progress 55.61119293078056\n",
      "Progress 55.705449189985266\n",
      "Progress 55.799705449189986\n",
      "Progress 55.8939617083947\n",
      "Progress 55.98821796759941\n",
      "Progress 56.08247422680412\n",
      "Progress 56.17673048600884\n",
      "Progress 56.27098674521355\n",
      "Progress 56.36524300441826\n",
      "Progress 56.45949926362297\n",
      "Progress 56.553755522827686\n",
      "Progress 56.648011782032405\n",
      "Progress 56.74226804123711\n",
      "Progress 56.83652430044182\n",
      "Progress 56.93078055964654\n",
      "Progress 57.02503681885125\n",
      "Progress 57.11929307805597\n",
      "Progress 57.21354933726068\n",
      "Progress 57.307805596465386\n",
      "Progress 57.402061855670105\n",
      "Progress 57.49631811487481\n",
      "Progress 57.59057437407953\n",
      "Progress 57.68483063328424\n",
      "Progress 57.77908689248895\n",
      "Progress 57.87334315169367\n",
      "Progress 57.96759941089839\n",
      "Progress 58.06185567010309\n",
      "Progress 58.156111929307805\n",
      "Progress 58.25036818851251\n",
      "Progress 58.34462444771723\n",
      "Progress 58.43888070692195\n",
      "Progress 58.533136966126655\n",
      "Progress 58.62739322533137\n",
      "Progress 58.72164948453609\n",
      "Progress 58.81590574374079\n",
      "Progress 58.91016200294551\n",
      "Progress 59.00441826215022\n",
      "Progress 59.09867452135493\n",
      "Progress 59.19293078055965\n",
      "Progress 59.287187039764355\n",
      "Progress 59.381443298969074\n",
      "Progress 59.47569955817379\n",
      "Progress 59.56995581737849\n",
      "Progress 59.66421207658321\n",
      "Progress 59.75846833578793\n",
      "Progress 59.85272459499264\n",
      "Progress 59.94698085419735\n",
      "Progress 60.041237113402055\n",
      "Progress 60.135493372606774\n",
      "Progress 60.229749631811494\n",
      "Progress 60.3240058910162\n",
      "Progress 60.41826215022091\n",
      "Progress 60.51251840942563\n",
      "Progress 60.60677466863034\n",
      "Progress 60.701030927835056\n",
      "Progress 60.79528718703976\n",
      "Progress 60.889543446244474\n",
      "Progress 60.983799705449194\n",
      "Progress 61.0780559646539\n",
      "Progress 61.17231222385862\n",
      "Progress 61.26656848306333\n",
      "Progress 61.360824742268036\n",
      "Progress 61.455081001472756\n",
      "Progress 61.54933726067746\n",
      "Progress 61.64359351988218\n",
      "Progress 61.73784977908689\n",
      "Progress 61.8321060382916\n",
      "Progress 61.92636229749632\n",
      "Progress 62.02061855670104\n",
      "Progress 62.11487481590574\n",
      "Progress 62.209131075110456\n",
      "Progress 62.303387334315175\n",
      "Progress 62.39764359351988\n",
      "Progress 62.4918998527246\n",
      "Progress 62.586156111929306\n",
      "Progress 62.68041237113402\n",
      "Progress 62.77466863033874\n",
      "Progress 62.86892488954344\n",
      "Progress 62.96318114874816\n",
      "Progress 63.057437407952875\n",
      "Progress 63.15169366715758\n",
      "Progress 63.2459499263623\n",
      "Progress 63.340206185567006\n",
      "Progress 63.434462444771725\n",
      "Progress 63.52871870397644\n",
      "Progress 63.62297496318114\n",
      "Progress 63.71723122238586\n",
      "Progress 63.811487481590575\n",
      "Progress 63.90574374079529\n",
      "Progress 64.0\n",
      "Progress 64.09425625920471\n",
      "Progress 64.18851251840942\n",
      "Progress 64.28276877761414\n",
      "Progress 64.37702503681885\n",
      "Progress 64.47128129602356\n",
      "Progress 64.56553755522827\n",
      "Progress 64.65979381443299\n",
      "Progress 64.7540500736377\n",
      "Progress 64.84830633284243\n",
      "Progress 64.94256259204712\n",
      "Progress 65.03681885125184\n",
      "Progress 65.13107511045655\n",
      "Progress 65.22533136966126\n",
      "Progress 65.31958762886599\n",
      "Progress 65.41384388807069\n",
      "Progress 65.5081001472754\n",
      "Progress 65.60235640648013\n",
      "Progress 65.69661266568482\n",
      "Progress 65.79086892488955\n",
      "Progress 65.88512518409425\n",
      "Progress 65.97938144329896\n",
      "Progress 66.07363770250369\n",
      "Progress 66.16789396170839\n",
      "Progress 66.26215022091311\n",
      "Progress 66.35640648011783\n",
      "Progress 66.45066273932252\n",
      "Progress 66.54491899852725\n",
      "Progress 66.63917525773196\n",
      "Progress 66.73343151693668\n",
      "Progress 66.82768777614139\n",
      "Progress 66.92194403534609\n",
      "Progress 67.01620029455081\n",
      "Progress 67.11045655375553\n",
      "Progress 67.20471281296024\n",
      "Progress 67.29896907216495\n",
      "Progress 67.39322533136966\n",
      "Progress 67.48748159057438\n",
      "Progress 67.58173784977909\n",
      "Progress 67.6759941089838\n",
      "Progress 67.77025036818851\n",
      "Progress 67.86450662739323\n",
      "Progress 67.95876288659794\n",
      "Progress 68.05301914580265\n",
      "Progress 68.14727540500736\n",
      "Progress 68.24153166421208\n",
      "Progress 68.33578792341679\n",
      "Progress 68.4300441826215\n",
      "Progress 68.52430044182621\n",
      "Progress 68.61855670103093\n",
      "Progress 68.71281296023564\n",
      "Progress 68.80706921944035\n",
      "Progress 68.90132547864508\n",
      "Progress 68.99558173784978\n",
      "Progress 69.08983799705449\n",
      "Progress 69.18409425625921\n",
      "Progress 69.27835051546391\n",
      "Progress 69.37260677466864\n",
      "Progress 69.46686303387334\n",
      "Progress 69.56111929307805\n",
      "Progress 69.65537555228278\n",
      "Progress 69.74963181148748\n",
      "Progress 69.8438880706922\n",
      "Progress 69.93814432989691\n",
      "Progress 70.03240058910161\n",
      "Progress 70.12665684830634\n",
      "Progress 70.22091310751104\n",
      "Progress 70.31516936671576\n",
      "Progress 70.40942562592048\n",
      "Progress 70.50368188512518\n",
      "Progress 70.5979381443299\n",
      "Progress 70.69219440353461\n",
      "Progress 70.78645066273933\n",
      "Progress 70.88070692194404\n",
      "Progress 70.97496318114875\n",
      "Progress 71.06921944035346\n",
      "Progress 71.16347569955818\n",
      "Progress 71.25773195876289\n",
      "Progress 71.3519882179676\n",
      "Progress 71.44624447717231\n",
      "Progress 71.54050073637703\n",
      "Progress 71.63475699558174\n",
      "Progress 71.72901325478645\n",
      "Progress 71.82326951399116\n",
      "Progress 71.91752577319588\n",
      "Progress 72.01178203240059\n",
      "Progress 72.1060382916053\n",
      "Progress 72.20029455081001\n",
      "Progress 72.29455081001473\n",
      "Progress 72.38880706921944\n",
      "Progress 72.48306332842415\n",
      "Progress 72.57731958762886\n",
      "Progress 72.67157584683358\n",
      "Progress 72.76583210603829\n",
      "Progress 72.860088365243\n",
      "Progress 72.95434462444771\n",
      "Progress 73.04860088365243\n",
      "Progress 73.14285714285714\n",
      "Progress 73.23711340206187\n",
      "Progress 73.33136966126656\n",
      "Progress 73.42562592047128\n",
      "Progress 73.519882179676\n",
      "Progress 73.6141384388807\n",
      "Progress 73.70839469808543\n",
      "Progress 73.80265095729013\n",
      "Progress 73.89690721649484\n",
      "Progress 73.99116347569957\n",
      "Progress 74.08541973490426\n",
      "Progress 74.17967599410899\n",
      "Progress 74.2739322533137\n",
      "Progress 74.3681885125184\n",
      "Progress 74.46244477172313\n",
      "Progress 74.55670103092783\n",
      "Progress 74.65095729013255\n",
      "Progress 74.74521354933727\n",
      "Progress 74.83946980854196\n",
      "Progress 74.93372606774669\n",
      "Progress 75.0279823269514\n",
      "Progress 75.12223858615612\n",
      "Progress 75.21649484536083\n",
      "Progress 75.31075110456553\n",
      "Progress 75.40500736377025\n",
      "Progress 75.49926362297496\n",
      "Progress 75.59351988217968\n",
      "Progress 75.68777614138439\n",
      "Progress 75.7820324005891\n",
      "Progress 75.87628865979381\n",
      "Progress 75.97054491899853\n",
      "Progress 76.06480117820324\n",
      "Progress 76.15905743740795\n",
      "Progress 76.25331369661266\n",
      "Progress 76.34756995581738\n",
      "Progress 76.44182621502209\n",
      "Progress 76.5360824742268\n",
      "Progress 76.63033873343151\n",
      "Progress 76.72459499263623\n",
      "Progress 76.81885125184095\n",
      "Progress 76.91310751104565\n",
      "Progress 77.00736377025036\n",
      "Progress 77.10162002945508\n",
      "Progress 77.19587628865979\n",
      "Progress 77.29013254786452\n",
      "Progress 77.38438880706921\n",
      "Progress 77.47864506627393\n",
      "Progress 77.57290132547865\n",
      "Progress 77.66715758468335\n",
      "Progress 77.76141384388808\n",
      "Progress 77.85567010309279\n",
      "Progress 77.94992636229749\n",
      "Progress 78.04418262150222\n",
      "Progress 78.13843888070691\n",
      "Progress 78.23269513991164\n",
      "Progress 78.32695139911635\n",
      "Progress 78.42120765832105\n",
      "Progress 78.51546391752578\n",
      "Progress 78.60972017673049\n",
      "Progress 78.7039764359352\n",
      "Progress 78.79823269513992\n",
      "Progress 78.89248895434461\n",
      "Progress 78.98674521354934\n",
      "Progress 79.08100147275405\n",
      "Progress 79.17525773195877\n",
      "Progress 79.26951399116348\n",
      "Progress 79.36377025036819\n",
      "Progress 79.4580265095729\n",
      "Progress 79.55228276877762\n",
      "Progress 79.64653902798233\n",
      "Progress 79.74079528718704\n",
      "Progress 79.83505154639175\n",
      "Progress 79.92930780559647\n",
      "Progress 80.02356406480118\n",
      "Progress 80.11782032400589\n",
      "Progress 80.2120765832106\n",
      "Progress 80.30633284241532\n",
      "Progress 80.40058910162003\n",
      "Progress 80.49484536082474\n",
      "Progress 80.58910162002945\n",
      "Progress 80.68335787923417\n",
      "Progress 80.77761413843888\n",
      "Progress 80.87187039764359\n",
      "Progress 80.9661266568483\n",
      "Progress 81.06038291605302\n",
      "Progress 81.15463917525774\n",
      "Progress 81.24889543446244\n",
      "Progress 81.34315169366715\n",
      "Progress 81.43740795287187\n",
      "Progress 81.53166421207658\n",
      "Progress 81.6259204712813\n",
      "Progress 81.720176730486\n",
      "Progress 81.81443298969072\n",
      "Progress 81.90868924889544\n",
      "Progress 82.00294550810014\n",
      "Progress 82.09720176730487\n",
      "Progress 82.19145802650958\n",
      "Progress 82.28571428571428\n",
      "Progress 82.379970544919\n",
      "Progress 82.4742268041237\n",
      "Progress 82.56848306332843\n",
      "Progress 82.66273932253314\n",
      "Progress 82.75699558173784\n",
      "Progress 82.85125184094257\n",
      "Progress 82.94550810014728\n",
      "Progress 83.03976435935199\n",
      "Progress 83.1340206185567\n",
      "Progress 83.2282768777614\n",
      "Progress 83.32253313696613\n",
      "Progress 83.41678939617084\n",
      "Progress 83.51104565537555\n",
      "Progress 83.60530191458027\n",
      "Progress 83.69955817378498\n",
      "Progress 83.79381443298969\n",
      "Progress 83.8880706921944\n",
      "Progress 83.98232695139912\n",
      "Progress 84.07658321060383\n",
      "Progress 84.17083946980854\n",
      "Progress 84.26509572901325\n",
      "Progress 84.35935198821797\n",
      "Progress 84.45360824742268\n",
      "Progress 84.54786450662739\n",
      "Progress 84.6421207658321\n",
      "Progress 84.73637702503683\n",
      "Progress 84.83063328424153\n",
      "Progress 84.92488954344624\n",
      "Progress 85.01914580265095\n",
      "Progress 85.11340206185567\n",
      "Progress 85.20765832106039\n",
      "Progress 85.30191458026509\n",
      "Progress 85.3961708394698\n",
      "Progress 85.49042709867453\n",
      "Progress 85.58468335787923\n",
      "Progress 85.67893961708396\n",
      "Progress 85.77319587628865\n",
      "Progress 85.86745213549337\n",
      "Progress 85.96170839469809\n",
      "Progress 86.05596465390279\n",
      "Progress 86.15022091310752\n",
      "Progress 86.24447717231223\n",
      "Progress 86.33873343151693\n",
      "Progress 86.43298969072166\n",
      "Progress 86.52724594992635\n",
      "Progress 86.62150220913108\n",
      "Progress 86.71575846833579\n",
      "Progress 86.81001472754049\n",
      "Progress 86.90427098674522\n",
      "Progress 86.99852724594993\n",
      "Progress 87.09278350515464\n",
      "Progress 87.18703976435935\n",
      "Progress 87.28129602356407\n",
      "Progress 87.37555228276878\n",
      "Progress 87.46980854197349\n",
      "Progress 87.5640648011782\n",
      "Progress 87.65832106038292\n",
      "Progress 87.75257731958763\n",
      "Progress 87.84683357879234\n",
      "Progress 87.94108983799705\n",
      "Progress 88.03534609720177\n",
      "Progress 88.12960235640648\n",
      "Progress 88.22385861561119\n",
      "Progress 88.3181148748159\n",
      "Progress 88.41237113402062\n",
      "Progress 88.50662739322533\n",
      "Progress 88.60088365243004\n",
      "Progress 88.69513991163475\n",
      "Progress 88.78939617083947\n",
      "Progress 88.88365243004418\n",
      "Progress 88.97790868924889\n",
      "Progress 89.07216494845362\n",
      "Progress 89.16642120765832\n",
      "Progress 89.26067746686303\n",
      "Progress 89.35493372606774\n",
      "Progress 89.44918998527245\n",
      "Progress 89.54344624447718\n",
      "Progress 89.63770250368188\n",
      "Progress 89.73195876288659\n",
      "Progress 89.82621502209132\n",
      "Progress 89.92047128129602\n",
      "Progress 90.01472754050074\n",
      "Progress 90.10898379970544\n",
      "Progress 90.20324005891015\n",
      "Progress 90.29749631811488\n",
      "Progress 90.39175257731958\n",
      "Progress 90.4860088365243\n",
      "Progress 90.58026509572902\n",
      "Progress 90.67452135493372\n",
      "Progress 90.76877761413844\n",
      "Progress 90.86303387334314\n",
      "Progress 90.95729013254787\n",
      "Progress 91.05154639175258\n",
      "Progress 91.14580265095728\n",
      "Progress 91.240058910162\n",
      "Progress 91.33431516936672\n",
      "Progress 91.42857142857143\n",
      "Progress 91.52282768777614\n",
      "Progress 91.61708394698086\n",
      "Progress 91.71134020618557\n",
      "Progress 91.80559646539028\n",
      "Progress 91.899852724595\n",
      "Progress 91.9941089837997\n",
      "Progress 92.08836524300442\n",
      "Progress 92.18262150220913\n",
      "Progress 92.27687776141384\n",
      "Progress 92.37113402061856\n",
      "Progress 92.46539027982327\n",
      "Progress 92.55964653902798\n",
      "Progress 92.65390279823269\n",
      "Progress 92.7481590574374\n",
      "Progress 92.84241531664212\n",
      "Progress 92.93667157584683\n",
      "Progress 93.03092783505154\n",
      "Progress 93.12518409425627\n",
      "Progress 93.21944035346097\n",
      "Progress 93.31369661266568\n",
      "Progress 93.40795287187039\n",
      "Progress 93.5022091310751\n",
      "Progress 93.59646539027983\n",
      "Progress 93.69072164948453\n",
      "Progress 93.78497790868924\n",
      "Progress 93.87923416789397\n",
      "Progress 93.97349042709867\n",
      "Progress 94.0677466863034\n",
      "Progress 94.1620029455081\n",
      "Progress 94.2562592047128\n",
      "Progress 94.35051546391753\n",
      "Progress 94.44477172312223\n",
      "Progress 94.53902798232696\n",
      "Progress 94.63328424153167\n",
      "Progress 94.72754050073637\n",
      "Progress 94.8217967599411\n",
      "Progress 94.9160530191458\n",
      "Progress 95.01030927835052\n",
      "Progress 95.10456553755523\n",
      "Progress 95.19882179675993\n",
      "Progress 95.29307805596466\n",
      "Progress 95.38733431516937\n",
      "Progress 95.48159057437408\n",
      "Progress 95.5758468335788\n",
      "Progress 95.6701030927835\n",
      "Progress 95.76435935198822\n",
      "Progress 95.85861561119293\n",
      "Progress 95.95287187039764\n",
      "Progress 96.04712812960236\n",
      "Progress 96.14138438880707\n",
      "Progress 96.23564064801178\n",
      "Progress 96.3298969072165\n",
      "Progress 96.4241531664212\n",
      "Progress 96.51840942562592\n",
      "Progress 96.61266568483063\n",
      "Progress 96.70692194403536\n",
      "Progress 96.80117820324006\n",
      "Progress 96.89543446244477\n",
      "Progress 96.98969072164948\n",
      "Progress 97.0839469808542\n",
      "Progress 97.17820324005892\n",
      "Progress 97.27245949926362\n",
      "Progress 97.36671575846833\n",
      "Progress 97.46097201767306\n",
      "Progress 97.55522827687776\n",
      "Progress 97.64948453608248\n",
      "Progress 97.74374079528718\n",
      "Progress 97.8379970544919\n",
      "Progress 97.93225331369662\n",
      "Progress 98.02650957290132\n",
      "Progress 98.12076583210604\n",
      "Progress 98.21502209131076\n",
      "Progress 98.30927835051546\n",
      "Progress 98.40353460972018\n",
      "Progress 98.4977908689249\n",
      "Progress 98.59204712812961\n",
      "Progress 98.68630338733432\n",
      "Progress 98.78055964653902\n",
      "Progress 98.87481590574374\n",
      "Progress 98.96907216494846\n",
      "Progress 99.06332842415317\n",
      "Progress 99.15758468335788\n",
      "Progress 99.2518409425626\n",
      "Progress 99.34609720176731\n",
      "Progress 99.44035346097202\n",
      "Progress 99.53460972017673\n",
      "Progress 99.62886597938144\n",
      "Progress 99.72312223858616\n",
      "Progress 99.81737849779087\n",
      "Progress 99.91163475699558\n",
      "Progress 0.0\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.7540500736377025\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.508100147275405\n",
      "Progress 1.8851251840942562\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.6391752577319587\n",
      "Progress 3.01620029455081\n",
      "Progress 3.393225331369661\n",
      "Progress 3.7702503681885124\n",
      "Progress 4.147275405007364\n",
      "Progress 4.524300441826215\n",
      "Progress 4.901325478645066\n",
      "Progress 5.278350515463917\n",
      "Progress 5.655375552282769\n",
      "Progress 6.03240058910162\n",
      "Progress 6.409425625920472\n",
      "Progress 6.786450662739322\n",
      "Progress 7.163475699558173\n",
      "Progress 7.540500736377025\n",
      "Progress 7.917525773195876\n",
      "Progress 8.294550810014728\n",
      "Progress 8.67157584683358\n",
      "Progress 9.04860088365243\n",
      "Progress 9.425625920471282\n",
      "Progress 9.802650957290131\n",
      "Progress 10.179675994108983\n",
      "Progress 10.556701030927835\n",
      "Progress 10.933726067746687\n",
      "Progress 11.310751104565538\n",
      "Progress 11.687776141384388\n",
      "Progress 12.06480117820324\n",
      "Progress 12.441826215022092\n",
      "Progress 12.818851251840943\n",
      "Progress 13.195876288659795\n",
      "Progress 13.572901325478645\n",
      "Progress 13.949926362297496\n",
      "Progress 14.326951399116346\n",
      "Progress 14.703976435935198\n",
      "Progress 15.08100147275405\n",
      "Progress 15.4580265095729\n",
      "Progress 15.835051546391751\n",
      "Progress 16.212076583210607\n",
      "Progress 16.589101620029457\n",
      "Progress 16.966126656848306\n",
      "Progress 17.34315169366716\n",
      "Progress 17.72017673048601\n",
      "Progress 18.09720176730486\n",
      "Progress 18.47422680412371\n",
      "Progress 18.851251840942563\n",
      "Progress 19.228276877761413\n",
      "Progress 19.605301914580263\n",
      "Progress 19.982326951399116\n",
      "Progress 20.359351988217966\n",
      "Progress 20.73637702503682\n",
      "Progress 21.11340206185567\n",
      "Progress 21.490427098674523\n",
      "Progress 21.867452135493373\n",
      "Progress 22.244477172312223\n",
      "Progress 22.621502209131076\n",
      "Progress 22.998527245949926\n",
      "Progress 23.375552282768776\n",
      "Progress 23.75257731958763\n",
      "Progress 24.12960235640648\n",
      "Progress 24.50662739322533\n",
      "Progress 24.883652430044183\n",
      "Progress 25.260677466863036\n",
      "Progress 25.637702503681886\n",
      "Progress 26.014727540500736\n",
      "Progress 26.39175257731959\n",
      "Progress 26.76877761413844\n",
      "Progress 27.14580265095729\n",
      "Progress 27.522827687776143\n",
      "Progress 27.899852724594993\n",
      "Progress 28.276877761413843\n",
      "Progress 28.653902798232693\n",
      "Progress 29.030927835051546\n",
      "Progress 29.407952871870396\n",
      "Progress 29.784977908689246\n",
      "Progress 30.1620029455081\n",
      "Progress 30.53902798232695\n",
      "Progress 30.9160530191458\n",
      "Progress 31.293078055964653\n",
      "Progress 31.670103092783503\n",
      "Progress 32.047128129602356\n",
      "Progress 32.42415316642121\n",
      "Progress 32.80117820324006\n",
      "Progress 33.17820324005891\n",
      "Progress 33.55522827687776\n",
      "Progress 33.93225331369661\n",
      "Progress 34.30927835051546\n",
      "Progress 34.68630338733432\n",
      "Progress 35.06332842415317\n",
      "Progress 35.44035346097202\n",
      "Progress 35.81737849779087\n",
      "Progress 36.19440353460972\n",
      "Progress 36.57142857142857\n",
      "Progress 36.94845360824742\n",
      "Progress 37.325478645066276\n",
      "Progress 37.702503681885126\n",
      "Progress 38.079528718703976\n",
      "Progress 38.456553755522826\n",
      "Progress 38.833578792341676\n",
      "Progress 39.210603829160526\n",
      "Progress 39.58762886597938\n",
      "Progress 39.96465390279823\n",
      "Progress 40.34167893961708\n",
      "Progress 40.71870397643593\n",
      "Progress 41.09572901325479\n",
      "Progress 41.47275405007364\n",
      "Progress 41.84977908689249\n",
      "Progress 42.22680412371134\n",
      "Progress 42.603829160530196\n",
      "Progress 42.980854197349046\n",
      "Progress 43.357879234167896\n",
      "Progress 43.734904270986746\n",
      "Progress 44.111929307805596\n",
      "Progress 44.488954344624446\n",
      "Progress 44.865979381443296\n",
      "Progress 45.24300441826215\n",
      "Progress 45.620029455081\n",
      "Progress 45.99705449189985\n",
      "Progress 46.3740795287187\n",
      "Progress 46.75110456553755\n",
      "Progress 47.1281296023564\n",
      "Progress 47.50515463917526\n",
      "Progress 47.88217967599411\n",
      "Progress 48.25920471281296\n",
      "Progress 48.63622974963181\n",
      "Progress 49.01325478645066\n",
      "Progress 49.39027982326951\n",
      "Progress 49.767304860088366\n",
      "Progress 50.144329896907216\n",
      "Progress 50.52135493372607\n",
      "Progress 50.898379970544916\n",
      "Progress 51.27540500736377\n",
      "Progress 51.652430044182616\n",
      "Progress 52.02945508100147\n",
      "Progress 52.40648011782032\n",
      "Progress 52.78350515463918\n",
      "Progress 53.16053019145802\n",
      "Progress 53.53755522827688\n",
      "Progress 53.91458026509572\n",
      "Progress 54.29160530191458\n",
      "Progress 54.66863033873343\n",
      "Progress 55.045655375552286\n",
      "Progress 55.422680412371136\n",
      "Progress 55.799705449189986\n",
      "Progress 56.17673048600884\n",
      "Progress 56.553755522827686\n",
      "Progress 56.93078055964654\n",
      "Progress 57.307805596465386\n",
      "Progress 57.68483063328424\n",
      "Progress 58.06185567010309\n",
      "Progress 58.43888070692195\n",
      "Progress 58.81590574374079\n",
      "Progress 59.19293078055965\n",
      "Progress 59.56995581737849\n",
      "Progress 59.94698085419735\n",
      "Progress 60.3240058910162\n",
      "Progress 60.701030927835056\n",
      "Progress 61.0780559646539\n",
      "Progress 61.455081001472756\n",
      "Progress 61.8321060382916\n",
      "Progress 62.209131075110456\n",
      "Progress 62.586156111929306\n",
      "Progress 62.96318114874816\n",
      "Progress 63.340206185567006\n",
      "Progress 63.71723122238586\n",
      "Progress 64.09425625920471\n",
      "Progress 64.47128129602356\n",
      "Progress 64.84830633284243\n",
      "Progress 65.22533136966126\n",
      "Progress 65.60235640648013\n",
      "Progress 65.97938144329896\n",
      "Progress 66.35640648011783\n",
      "Progress 66.73343151693668\n",
      "Progress 67.11045655375553\n",
      "Progress 67.48748159057438\n",
      "Progress 67.86450662739323\n",
      "Progress 68.24153166421208\n",
      "Progress 68.61855670103093\n",
      "Progress 68.99558173784978\n",
      "Progress 69.37260677466864\n",
      "Progress 69.74963181148748\n",
      "Progress 70.12665684830634\n",
      "Progress 70.50368188512518\n",
      "Progress 70.88070692194404\n",
      "Progress 71.25773195876289\n",
      "Progress 71.63475699558174\n",
      "Progress 72.01178203240059\n",
      "Progress 72.38880706921944\n",
      "Progress 72.76583210603829\n",
      "Progress 73.14285714285714\n",
      "Progress 73.519882179676\n",
      "Progress 73.89690721649484\n",
      "Progress 74.2739322533137\n",
      "Progress 74.65095729013255\n",
      "Progress 75.0279823269514\n",
      "Progress 75.40500736377025\n",
      "Progress 75.7820324005891\n",
      "Progress 76.15905743740795\n",
      "Progress 76.5360824742268\n",
      "Progress 76.91310751104565\n",
      "Progress 77.29013254786452\n",
      "Progress 77.66715758468335\n",
      "Progress 78.04418262150222\n",
      "Progress 78.42120765832105\n",
      "Progress 78.79823269513992\n",
      "Progress 79.17525773195877\n",
      "Progress 79.55228276877762\n",
      "Progress 79.92930780559647\n",
      "Progress 80.30633284241532\n",
      "Progress 80.68335787923417\n",
      "Progress 81.06038291605302\n",
      "Progress 81.43740795287187\n",
      "Progress 81.81443298969072\n",
      "Progress 82.19145802650958\n",
      "Progress 82.56848306332843\n",
      "Progress 82.94550810014728\n",
      "Progress 83.32253313696613\n",
      "Progress 83.69955817378498\n",
      "Progress 84.07658321060383\n",
      "Progress 84.45360824742268\n",
      "Progress 84.83063328424153\n",
      "Progress 85.20765832106039\n",
      "Progress 85.58468335787923\n",
      "Progress 85.96170839469809\n",
      "Progress 86.33873343151693\n",
      "Progress 86.71575846833579\n",
      "Progress 87.09278350515464\n",
      "Progress 87.46980854197349\n",
      "Progress 87.84683357879234\n",
      "Progress 88.22385861561119\n",
      "Progress 88.60088365243004\n",
      "Progress 88.97790868924889\n",
      "Progress 89.35493372606774\n",
      "Progress 89.73195876288659\n",
      "Progress 90.10898379970544\n",
      "Progress 90.4860088365243\n",
      "Progress 90.86303387334314\n",
      "Progress 91.240058910162\n",
      "Progress 91.61708394698086\n",
      "Progress 91.9941089837997\n",
      "Progress 92.37113402061856\n",
      "Progress 92.7481590574374\n",
      "Progress 93.12518409425627\n",
      "Progress 93.5022091310751\n",
      "Progress 93.87923416789397\n",
      "Progress 94.2562592047128\n",
      "Progress 94.63328424153167\n",
      "Progress 95.01030927835052\n",
      "Progress 95.38733431516937\n",
      "Progress 95.76435935198822\n",
      "Progress 96.14138438880707\n",
      "Progress 96.51840942562592\n",
      "Progress 96.89543446244477\n",
      "Progress 97.27245949926362\n",
      "Progress 97.64948453608248\n",
      "Progress 98.02650957290132\n",
      "Progress 98.40353460972018\n",
      "Progress 98.78055964653902\n",
      "Progress 99.15758468335788\n",
      "Progress 99.53460972017673\n",
      "Progress 99.91163475699558\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   3.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   7.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50447e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49345e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50543e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49623e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49957e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.17141665 0.17145709        nan        nan\n",
      " 0.20802149 0.20783598        nan        nan 0.21890217        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [39:41, 1196.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Progress 0.0\n",
      "Progress 0.09425625920471281\n",
      "Progress 0.18851251840942562\n",
      "Progress 0.28276877761413843\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.47128129602356406\n",
      "Progress 0.5655375552282769\n",
      "Progress 0.6597938144329897\n",
      "Progress 0.7540500736377025\n",
      "Progress 0.8483063328424153\n",
      "Progress 0.9425625920471281\n",
      "Progress 1.036818851251841\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.2253313696612664\n",
      "Progress 1.3195876288659794\n",
      "Progress 1.4138438880706923\n",
      "Progress 1.508100147275405\n",
      "Progress 1.602356406480118\n",
      "Progress 1.6966126656848306\n",
      "Progress 1.7908689248895433\n",
      "Progress 1.8851251840942562\n",
      "Progress 1.979381443298969\n",
      "Progress 2.073637702503682\n",
      "Progress 2.167893961708395\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.3564064801178204\n",
      "Progress 2.450662739322533\n",
      "Progress 2.544918998527246\n",
      "Progress 2.6391752577319587\n",
      "Progress 2.7334315169366716\n",
      "Progress 2.8276877761413846\n",
      "Progress 2.921944035346097\n",
      "Progress 3.01620029455081\n",
      "Progress 3.110456553755523\n",
      "Progress 3.204712812960236\n",
      "Progress 3.2989690721649487\n",
      "Progress 3.393225331369661\n",
      "Progress 3.487481590574374\n",
      "Progress 3.5817378497790866\n",
      "Progress 3.6759941089837995\n",
      "Progress 3.7702503681885124\n",
      "Progress 3.864506627393225\n",
      "Progress 3.958762886597938\n",
      "Progress 4.053019145802652\n",
      "Progress 4.147275405007364\n",
      "Progress 4.241531664212077\n",
      "Progress 4.33578792341679\n",
      "Progress 4.4300441826215025\n",
      "Progress 4.524300441826215\n",
      "Progress 4.618556701030927\n",
      "Progress 4.712812960235641\n",
      "Progress 4.807069219440353\n",
      "Progress 4.901325478645066\n",
      "Progress 4.995581737849779\n",
      "Progress 5.089837997054492\n",
      "Progress 5.184094256259205\n",
      "Progress 5.278350515463917\n",
      "Progress 5.372606774668631\n",
      "Progress 5.466863033873343\n",
      "Progress 5.561119293078056\n",
      "Progress 5.655375552282769\n",
      "Progress 5.749631811487482\n",
      "Progress 5.843888070692194\n",
      "Progress 5.938144329896907\n",
      "Progress 6.03240058910162\n",
      "Progress 6.126656848306332\n",
      "Progress 6.220913107511046\n",
      "Progress 6.315169366715759\n",
      "Progress 6.409425625920472\n",
      "Progress 6.503681885125184\n",
      "Progress 6.5979381443298974\n",
      "Progress 6.69219440353461\n",
      "Progress 6.786450662739322\n",
      "Progress 6.880706921944036\n",
      "Progress 6.974963181148748\n",
      "Progress 7.069219440353461\n",
      "Progress 7.163475699558173\n",
      "Progress 7.257731958762887\n",
      "Progress 7.351988217967599\n",
      "Progress 7.4462444771723115\n",
      "Progress 7.540500736377025\n",
      "Progress 7.634756995581737\n",
      "Progress 7.72901325478645\n",
      "Progress 7.823269513991163\n",
      "Progress 7.917525773195876\n",
      "Progress 8.011782032400589\n",
      "Progress 8.106038291605303\n",
      "Progress 8.200294550810016\n",
      "Progress 8.294550810014728\n",
      "Progress 8.38880706921944\n",
      "Progress 8.483063328424153\n",
      "Progress 8.577319587628866\n",
      "Progress 8.67157584683358\n",
      "Progress 8.765832106038292\n",
      "Progress 8.860088365243005\n",
      "Progress 8.954344624447717\n",
      "Progress 9.04860088365243\n",
      "Progress 9.142857142857142\n",
      "Progress 9.237113402061855\n",
      "Progress 9.331369661266569\n",
      "Progress 9.425625920471282\n",
      "Progress 9.519882179675994\n",
      "Progress 9.614138438880707\n",
      "Progress 9.708394698085419\n",
      "Progress 9.802650957290131\n",
      "Progress 9.896907216494846\n",
      "Progress 9.991163475699558\n",
      "Progress 10.08541973490427\n",
      "Progress 10.179675994108983\n",
      "Progress 10.273932253313697\n",
      "Progress 10.36818851251841\n",
      "Progress 10.462444771723122\n",
      "Progress 10.556701030927835\n",
      "Progress 10.650957290132549\n",
      "Progress 10.745213549337262\n",
      "Progress 10.839469808541974\n",
      "Progress 10.933726067746687\n",
      "Progress 11.027982326951399\n",
      "Progress 11.122238586156111\n",
      "Progress 11.216494845360824\n",
      "Progress 11.310751104565538\n",
      "Progress 11.40500736377025\n",
      "Progress 11.499263622974963\n",
      "Progress 11.593519882179676\n",
      "Progress 11.687776141384388\n",
      "Progress 11.7820324005891\n",
      "Progress 11.876288659793815\n",
      "Progress 11.970544918998527\n",
      "Progress 12.06480117820324\n",
      "Progress 12.159057437407952\n",
      "Progress 12.253313696612665\n",
      "Progress 12.347569955817377\n",
      "Progress 12.441826215022092\n",
      "Progress 12.536082474226804\n",
      "Progress 12.630338733431518\n",
      "Progress 12.724594992636229\n",
      "Progress 12.818851251840943\n",
      "Progress 12.913107511045654\n",
      "Progress 13.007363770250368\n",
      "Progress 13.10162002945508\n",
      "Progress 13.195876288659795\n",
      "Progress 13.290132547864506\n",
      "Progress 13.38438880706922\n",
      "Progress 13.47864506627393\n",
      "Progress 13.572901325478645\n",
      "Progress 13.667157584683357\n",
      "Progress 13.761413843888072\n",
      "Progress 13.855670103092784\n",
      "Progress 13.949926362297496\n",
      "Progress 14.04418262150221\n",
      "Progress 14.138438880706921\n",
      "Progress 14.232695139911636\n",
      "Progress 14.326951399116346\n",
      "Progress 14.42120765832106\n",
      "Progress 14.515463917525773\n",
      "Progress 14.609720176730487\n",
      "Progress 14.703976435935198\n",
      "Progress 14.798232695139912\n",
      "Progress 14.892488954344623\n",
      "Progress 14.986745213549337\n",
      "Progress 15.08100147275405\n",
      "Progress 15.175257731958764\n",
      "Progress 15.269513991163475\n",
      "Progress 15.363770250368189\n",
      "Progress 15.4580265095729\n",
      "Progress 15.552282768777614\n",
      "Progress 15.646539027982326\n",
      "Progress 15.74079528718704\n",
      "Progress 15.835051546391751\n",
      "Progress 15.929307805596466\n",
      "Progress 16.023564064801178\n",
      "Progress 16.11782032400589\n",
      "Progress 16.212076583210607\n",
      "Progress 16.306332842415316\n",
      "Progress 16.40058910162003\n",
      "Progress 16.49484536082474\n",
      "Progress 16.589101620029457\n",
      "Progress 16.68335787923417\n",
      "Progress 16.77761413843888\n",
      "Progress 16.871870397643594\n",
      "Progress 16.966126656848306\n",
      "Progress 17.06038291605302\n",
      "Progress 17.15463917525773\n",
      "Progress 17.248895434462444\n",
      "Progress 17.34315169366716\n",
      "Progress 17.43740795287187\n",
      "Progress 17.531664212076585\n",
      "Progress 17.625920471281294\n",
      "Progress 17.72017673048601\n",
      "Progress 17.814432989690722\n",
      "Progress 17.908689248895435\n",
      "Progress 18.002945508100147\n",
      "Progress 18.09720176730486\n",
      "Progress 18.191458026509572\n",
      "Progress 18.285714285714285\n",
      "Progress 18.379970544919\n",
      "Progress 18.47422680412371\n",
      "Progress 18.568483063328426\n",
      "Progress 18.662739322533138\n",
      "Progress 18.75699558173785\n",
      "Progress 18.851251840942563\n",
      "Progress 18.945508100147276\n",
      "Progress 19.039764359351988\n",
      "Progress 19.1340206185567\n",
      "Progress 19.228276877761413\n",
      "Progress 19.32253313696613\n",
      "Progress 19.416789396170838\n",
      "Progress 19.511045655375554\n",
      "Progress 19.605301914580263\n",
      "Progress 19.69955817378498\n",
      "Progress 19.79381443298969\n",
      "Progress 19.888070692194404\n",
      "Progress 19.982326951399116\n",
      "Progress 20.07658321060383\n",
      "Progress 20.17083946980854\n",
      "Progress 20.265095729013254\n",
      "Progress 20.359351988217966\n",
      "Progress 20.45360824742268\n",
      "Progress 20.547864506627395\n",
      "Progress 20.642120765832107\n",
      "Progress 20.73637702503682\n",
      "Progress 20.830633284241532\n",
      "Progress 20.924889543446245\n",
      "Progress 21.019145802650957\n",
      "Progress 21.11340206185567\n",
      "Progress 21.207658321060382\n",
      "Progress 21.301914580265098\n",
      "Progress 21.396170839469807\n",
      "Progress 21.490427098674523\n",
      "Progress 21.584683357879232\n",
      "Progress 21.678939617083948\n",
      "Progress 21.77319587628866\n",
      "Progress 21.867452135493373\n",
      "Progress 21.961708394698086\n",
      "Progress 22.055964653902798\n",
      "Progress 22.15022091310751\n",
      "Progress 22.244477172312223\n",
      "Progress 22.338733431516935\n",
      "Progress 22.432989690721648\n",
      "Progress 22.52724594992636\n",
      "Progress 22.621502209131076\n",
      "Progress 22.715758468335785\n",
      "Progress 22.8100147275405\n",
      "Progress 22.904270986745214\n",
      "Progress 22.998527245949926\n",
      "Progress 23.09278350515464\n",
      "Progress 23.18703976435935\n",
      "Progress 23.281296023564067\n",
      "Progress 23.375552282768776\n",
      "Progress 23.469808541973492\n",
      "Progress 23.5640648011782\n",
      "Progress 23.658321060382917\n",
      "Progress 23.75257731958763\n",
      "Progress 23.846833578792342\n",
      "Progress 23.941089837997055\n",
      "Progress 24.035346097201767\n",
      "Progress 24.12960235640648\n",
      "Progress 24.223858615611192\n",
      "Progress 24.318114874815905\n",
      "Progress 24.41237113402062\n",
      "Progress 24.50662739322533\n",
      "Progress 24.600883652430046\n",
      "Progress 24.695139911634755\n",
      "Progress 24.78939617083947\n",
      "Progress 24.883652430044183\n",
      "Progress 24.977908689248896\n",
      "Progress 25.072164948453608\n",
      "Progress 25.166421207658324\n",
      "Progress 25.260677466863036\n",
      "Progress 25.354933726067745\n",
      "Progress 25.449189985272458\n",
      "Progress 25.543446244477174\n",
      "Progress 25.637702503681886\n",
      "Progress 25.7319587628866\n",
      "Progress 25.826215022091308\n",
      "Progress 25.920471281296027\n",
      "Progress 26.014727540500736\n",
      "Progress 26.10898379970545\n",
      "Progress 26.20324005891016\n",
      "Progress 26.297496318114877\n",
      "Progress 26.39175257731959\n",
      "Progress 26.4860088365243\n",
      "Progress 26.58026509572901\n",
      "Progress 26.674521354933727\n",
      "Progress 26.76877761413844\n",
      "Progress 26.863033873343152\n",
      "Progress 26.95729013254786\n",
      "Progress 27.05154639175258\n",
      "Progress 27.14580265095729\n",
      "Progress 27.240058910162002\n",
      "Progress 27.334315169366715\n",
      "Progress 27.42857142857143\n",
      "Progress 27.522827687776143\n",
      "Progress 27.617083946980852\n",
      "Progress 27.711340206185568\n",
      "Progress 27.80559646539028\n",
      "Progress 27.899852724594993\n",
      "Progress 27.994108983799705\n",
      "Progress 28.08836524300442\n",
      "Progress 28.18262150220913\n",
      "Progress 28.276877761413843\n",
      "Progress 28.371134020618555\n",
      "Progress 28.46539027982327\n",
      "Progress 28.559646539027984\n",
      "Progress 28.653902798232693\n",
      "Progress 28.748159057437405\n",
      "Progress 28.84241531664212\n",
      "Progress 28.936671575846834\n",
      "Progress 29.030927835051546\n",
      "Progress 29.125184094256255\n",
      "Progress 29.219440353460975\n",
      "Progress 29.313696612665684\n",
      "Progress 29.407952871870396\n",
      "Progress 29.50220913107511\n",
      "Progress 29.596465390279825\n",
      "Progress 29.690721649484537\n",
      "Progress 29.784977908689246\n",
      "Progress 29.879234167893966\n",
      "Progress 29.973490427098675\n",
      "Progress 30.067746686303387\n",
      "Progress 30.1620029455081\n",
      "Progress 30.256259204712816\n",
      "Progress 30.350515463917528\n",
      "Progress 30.444771723122237\n",
      "Progress 30.53902798232695\n",
      "Progress 30.633284241531666\n",
      "Progress 30.727540500736378\n",
      "Progress 30.82179675994109\n",
      "Progress 30.9160530191458\n",
      "Progress 31.01030927835052\n",
      "Progress 31.104565537555228\n",
      "Progress 31.19882179675994\n",
      "Progress 31.293078055964653\n",
      "Progress 31.38733431516937\n",
      "Progress 31.48159057437408\n",
      "Progress 31.57584683357879\n",
      "Progress 31.670103092783503\n",
      "Progress 31.76435935198822\n",
      "Progress 31.85861561119293\n",
      "Progress 31.952871870397644\n",
      "Progress 32.047128129602356\n",
      "Progress 32.14138438880707\n",
      "Progress 32.23564064801178\n",
      "Progress 32.329896907216494\n",
      "Progress 32.42415316642121\n",
      "Progress 32.51840942562592\n",
      "Progress 32.61266568483063\n",
      "Progress 32.706921944035344\n",
      "Progress 32.80117820324006\n",
      "Progress 32.895434462444776\n",
      "Progress 32.98969072164948\n",
      "Progress 33.08394698085419\n",
      "Progress 33.17820324005891\n",
      "Progress 33.272459499263626\n",
      "Progress 33.36671575846834\n",
      "Progress 33.46097201767304\n",
      "Progress 33.55522827687776\n",
      "Progress 33.649484536082475\n",
      "Progress 33.74374079528719\n",
      "Progress 33.8379970544919\n",
      "Progress 33.93225331369661\n",
      "Progress 34.026509572901325\n",
      "Progress 34.12076583210604\n",
      "Progress 34.21502209131075\n",
      "Progress 34.30927835051546\n",
      "Progress 34.403534609720175\n",
      "Progress 34.49779086892489\n",
      "Progress 34.59204712812961\n",
      "Progress 34.68630338733432\n",
      "Progress 34.780559646539025\n",
      "Progress 34.87481590574374\n",
      "Progress 34.96907216494846\n",
      "Progress 35.06332842415317\n",
      "Progress 35.15758468335788\n",
      "Progress 35.25184094256259\n",
      "Progress 35.34609720176731\n",
      "Progress 35.44035346097202\n",
      "Progress 35.53460972017673\n",
      "Progress 35.628865979381445\n",
      "Progress 35.72312223858616\n",
      "Progress 35.81737849779087\n",
      "Progress 35.91163475699558\n",
      "Progress 36.005891016200295\n",
      "Progress 36.10014727540501\n",
      "Progress 36.19440353460972\n",
      "Progress 36.28865979381443\n",
      "Progress 36.382916053019144\n",
      "Progress 36.47717231222386\n",
      "Progress 36.57142857142857\n",
      "Progress 36.66568483063328\n",
      "Progress 36.759941089838\n",
      "Progress 36.854197349042714\n",
      "Progress 36.94845360824742\n",
      "Progress 37.04270986745213\n",
      "Progress 37.13696612665685\n",
      "Progress 37.231222385861564\n",
      "Progress 37.325478645066276\n",
      "Progress 37.41973490427098\n",
      "Progress 37.5139911634757\n",
      "Progress 37.608247422680414\n",
      "Progress 37.702503681885126\n",
      "Progress 37.79675994108984\n",
      "Progress 37.89101620029455\n",
      "Progress 37.985272459499264\n",
      "Progress 38.079528718703976\n",
      "Progress 38.17378497790869\n",
      "Progress 38.2680412371134\n",
      "Progress 38.362297496318114\n",
      "Progress 38.456553755522826\n",
      "Progress 38.55081001472754\n",
      "Progress 38.64506627393226\n",
      "Progress 38.73932253313696\n",
      "Progress 38.833578792341676\n",
      "Progress 38.927835051546396\n",
      "Progress 39.02209131075111\n",
      "Progress 39.11634756995582\n",
      "Progress 39.210603829160526\n",
      "Progress 39.304860088365245\n",
      "Progress 39.39911634756996\n",
      "Progress 39.49337260677467\n",
      "Progress 39.58762886597938\n",
      "Progress 39.681885125184095\n",
      "Progress 39.77614138438881\n",
      "Progress 39.87039764359352\n",
      "Progress 39.96465390279823\n",
      "Progress 40.058910162002945\n",
      "Progress 40.15316642120766\n",
      "Progress 40.24742268041237\n",
      "Progress 40.34167893961708\n",
      "Progress 40.435935198821795\n",
      "Progress 40.53019145802651\n",
      "Progress 40.62444771723122\n",
      "Progress 40.71870397643593\n",
      "Progress 40.81296023564065\n",
      "Progress 40.90721649484536\n",
      "Progress 41.00147275405007\n",
      "Progress 41.09572901325479\n",
      "Progress 41.1899852724595\n",
      "Progress 41.284241531664215\n",
      "Progress 41.37849779086892\n",
      "Progress 41.47275405007364\n",
      "Progress 41.56701030927835\n",
      "Progress 41.661266568483065\n",
      "Progress 41.75552282768778\n",
      "Progress 41.84977908689249\n",
      "Progress 41.9440353460972\n",
      "Progress 42.038291605301914\n",
      "Progress 42.13254786450663\n",
      "Progress 42.22680412371134\n",
      "Progress 42.32106038291605\n",
      "Progress 42.415316642120764\n",
      "Progress 42.50957290132548\n",
      "Progress 42.603829160530196\n",
      "Progress 42.6980854197349\n",
      "Progress 42.792341678939614\n",
      "Progress 42.88659793814433\n",
      "Progress 42.980854197349046\n",
      "Progress 43.07511045655376\n",
      "Progress 43.169366715758464\n",
      "Progress 43.26362297496318\n",
      "Progress 43.357879234167896\n",
      "Progress 43.45213549337261\n",
      "Progress 43.54639175257732\n",
      "Progress 43.640648011782034\n",
      "Progress 43.734904270986746\n",
      "Progress 43.82916053019146\n",
      "Progress 43.92341678939617\n",
      "Progress 44.017673048600884\n",
      "Progress 44.111929307805596\n",
      "Progress 44.20618556701031\n",
      "Progress 44.30044182621502\n",
      "Progress 44.39469808541973\n",
      "Progress 44.488954344624446\n",
      "Progress 44.58321060382916\n",
      "Progress 44.67746686303387\n",
      "Progress 44.77172312223859\n",
      "Progress 44.865979381443296\n",
      "Progress 44.96023564064801\n",
      "Progress 45.05449189985272\n",
      "Progress 45.14874815905744\n",
      "Progress 45.24300441826215\n",
      "Progress 45.33726067746686\n",
      "Progress 45.43151693667157\n",
      "Progress 45.52577319587629\n",
      "Progress 45.620029455081\n",
      "Progress 45.714285714285715\n",
      "Progress 45.80854197349043\n",
      "Progress 45.90279823269514\n",
      "Progress 45.99705449189985\n",
      "Progress 46.091310751104565\n",
      "Progress 46.18556701030928\n",
      "Progress 46.27982326951399\n",
      "Progress 46.3740795287187\n",
      "Progress 46.468335787923415\n",
      "Progress 46.562592047128135\n",
      "Progress 46.65684830633284\n",
      "Progress 46.75110456553755\n",
      "Progress 46.845360824742265\n",
      "Progress 46.939617083946985\n",
      "Progress 47.0338733431517\n",
      "Progress 47.1281296023564\n",
      "Progress 47.222385861561115\n",
      "Progress 47.316642120765835\n",
      "Progress 47.41089837997055\n",
      "Progress 47.50515463917526\n",
      "Progress 47.599410898379965\n",
      "Progress 47.693667157584684\n",
      "Progress 47.7879234167894\n",
      "Progress 47.88217967599411\n",
      "Progress 47.97643593519882\n",
      "Progress 48.070692194403534\n",
      "Progress 48.16494845360825\n",
      "Progress 48.25920471281296\n",
      "Progress 48.35346097201768\n",
      "Progress 48.447717231222384\n",
      "Progress 48.5419734904271\n",
      "Progress 48.63622974963181\n",
      "Progress 48.73048600883653\n",
      "Progress 48.82474226804124\n",
      "Progress 48.91899852724595\n",
      "Progress 49.01325478645066\n",
      "Progress 49.10751104565538\n",
      "Progress 49.20176730486009\n",
      "Progress 49.296023564064804\n",
      "Progress 49.39027982326951\n",
      "Progress 49.48453608247423\n",
      "Progress 49.57879234167894\n",
      "Progress 49.673048600883654\n",
      "Progress 49.767304860088366\n",
      "Progress 49.86156111929308\n",
      "Progress 49.95581737849779\n",
      "Progress 50.05007363770251\n",
      "Progress 50.144329896907216\n",
      "Progress 50.23858615611193\n",
      "Progress 50.33284241531665\n",
      "Progress 50.42709867452135\n",
      "Progress 50.52135493372607\n",
      "Progress 50.61561119293078\n",
      "Progress 50.70986745213549\n",
      "Progress 50.80412371134021\n",
      "Progress 50.898379970544916\n",
      "Progress 50.992636229749635\n",
      "Progress 51.08689248895435\n",
      "Progress 51.18114874815905\n",
      "Progress 51.27540500736377\n",
      "Progress 51.36966126656848\n",
      "Progress 51.4639175257732\n",
      "Progress 51.55817378497791\n",
      "Progress 51.652430044182616\n",
      "Progress 51.746686303387335\n",
      "Progress 51.840942562592055\n",
      "Progress 51.93519882179676\n",
      "Progress 52.02945508100147\n",
      "Progress 52.12371134020618\n",
      "Progress 52.2179675994109\n",
      "Progress 52.31222385861562\n",
      "Progress 52.40648011782032\n",
      "Progress 52.500736377025035\n",
      "Progress 52.594992636229755\n",
      "Progress 52.68924889543446\n",
      "Progress 52.78350515463918\n",
      "Progress 52.87776141384389\n",
      "Progress 52.9720176730486\n",
      "Progress 53.06627393225332\n",
      "Progress 53.16053019145802\n",
      "Progress 53.25478645066274\n",
      "Progress 53.349042709867454\n",
      "Progress 53.44329896907216\n",
      "Progress 53.53755522827688\n",
      "Progress 53.6318114874816\n",
      "Progress 53.726067746686304\n",
      "Progress 53.82032400589102\n",
      "Progress 53.91458026509572\n",
      "Progress 54.00883652430044\n",
      "Progress 54.10309278350516\n",
      "Progress 54.19734904270987\n",
      "Progress 54.29160530191458\n",
      "Progress 54.3858615611193\n",
      "Progress 54.480117820324004\n",
      "Progress 54.574374079528724\n",
      "Progress 54.66863033873343\n",
      "Progress 54.76288659793814\n",
      "Progress 54.85714285714286\n",
      "Progress 54.95139911634757\n",
      "Progress 55.045655375552286\n",
      "Progress 55.139911634757\n",
      "Progress 55.234167893961704\n",
      "Progress 55.328424153166424\n",
      "Progress 55.422680412371136\n",
      "Progress 55.51693667157585\n",
      "Progress 55.61119293078056\n",
      "Progress 55.705449189985266\n",
      "Progress 55.799705449189986\n",
      "Progress 55.8939617083947\n",
      "Progress 55.98821796759941\n",
      "Progress 56.08247422680412\n",
      "Progress 56.17673048600884\n",
      "Progress 56.27098674521355\n",
      "Progress 56.36524300441826\n",
      "Progress 56.45949926362297\n",
      "Progress 56.553755522827686\n",
      "Progress 56.648011782032405\n",
      "Progress 56.74226804123711\n",
      "Progress 56.83652430044182\n",
      "Progress 56.93078055964654\n",
      "Progress 57.02503681885125\n",
      "Progress 57.11929307805597\n",
      "Progress 57.21354933726068\n",
      "Progress 57.307805596465386\n",
      "Progress 57.402061855670105\n",
      "Progress 57.49631811487481\n",
      "Progress 57.59057437407953\n",
      "Progress 57.68483063328424\n",
      "Progress 57.77908689248895\n",
      "Progress 57.87334315169367\n",
      "Progress 57.96759941089839\n",
      "Progress 58.06185567010309\n",
      "Progress 58.156111929307805\n",
      "Progress 58.25036818851251\n",
      "Progress 58.34462444771723\n",
      "Progress 58.43888070692195\n",
      "Progress 58.533136966126655\n",
      "Progress 58.62739322533137\n",
      "Progress 58.72164948453609\n",
      "Progress 58.81590574374079\n",
      "Progress 58.91016200294551\n",
      "Progress 59.00441826215022\n",
      "Progress 59.09867452135493\n",
      "Progress 59.19293078055965\n",
      "Progress 59.287187039764355\n",
      "Progress 59.381443298969074\n",
      "Progress 59.47569955817379\n",
      "Progress 59.56995581737849\n",
      "Progress 59.66421207658321\n",
      "Progress 59.75846833578793\n",
      "Progress 59.85272459499264\n",
      "Progress 59.94698085419735\n",
      "Progress 60.041237113402055\n",
      "Progress 60.135493372606774\n",
      "Progress 60.229749631811494\n",
      "Progress 60.3240058910162\n",
      "Progress 60.41826215022091\n",
      "Progress 60.51251840942563\n",
      "Progress 60.60677466863034\n",
      "Progress 60.701030927835056\n",
      "Progress 60.79528718703976\n",
      "Progress 60.889543446244474\n",
      "Progress 60.983799705449194\n",
      "Progress 61.0780559646539\n",
      "Progress 61.17231222385862\n",
      "Progress 61.26656848306333\n",
      "Progress 61.360824742268036\n",
      "Progress 61.455081001472756\n",
      "Progress 61.54933726067746\n",
      "Progress 61.64359351988218\n",
      "Progress 61.73784977908689\n",
      "Progress 61.8321060382916\n",
      "Progress 61.92636229749632\n",
      "Progress 62.02061855670104\n",
      "Progress 62.11487481590574\n",
      "Progress 62.209131075110456\n",
      "Progress 62.303387334315175\n",
      "Progress 62.39764359351988\n",
      "Progress 62.4918998527246\n",
      "Progress 62.586156111929306\n",
      "Progress 62.68041237113402\n",
      "Progress 62.77466863033874\n",
      "Progress 62.86892488954344\n",
      "Progress 62.96318114874816\n",
      "Progress 63.057437407952875\n",
      "Progress 63.15169366715758\n",
      "Progress 63.2459499263623\n",
      "Progress 63.340206185567006\n",
      "Progress 63.434462444771725\n",
      "Progress 63.52871870397644\n",
      "Progress 63.62297496318114\n",
      "Progress 63.71723122238586\n",
      "Progress 63.811487481590575\n",
      "Progress 63.90574374079529\n",
      "Progress 64.0\n",
      "Progress 64.09425625920471\n",
      "Progress 64.18851251840942\n",
      "Progress 64.28276877761414\n",
      "Progress 64.37702503681885\n",
      "Progress 64.47128129602356\n",
      "Progress 64.56553755522827\n",
      "Progress 64.65979381443299\n",
      "Progress 64.7540500736377\n",
      "Progress 64.84830633284243\n",
      "Progress 64.94256259204712\n",
      "Progress 65.03681885125184\n",
      "Progress 65.13107511045655\n",
      "Progress 65.22533136966126\n",
      "Progress 65.31958762886599\n",
      "Progress 65.41384388807069\n",
      "Progress 65.5081001472754\n",
      "Progress 65.60235640648013\n",
      "Progress 65.69661266568482\n",
      "Progress 65.79086892488955\n",
      "Progress 65.88512518409425\n",
      "Progress 65.97938144329896\n",
      "Progress 66.07363770250369\n",
      "Progress 66.16789396170839\n",
      "Progress 66.26215022091311\n",
      "Progress 66.35640648011783\n",
      "Progress 66.45066273932252\n",
      "Progress 66.54491899852725\n",
      "Progress 66.63917525773196\n",
      "Progress 66.73343151693668\n",
      "Progress 66.82768777614139\n",
      "Progress 66.92194403534609\n",
      "Progress 67.01620029455081\n",
      "Progress 67.11045655375553\n",
      "Progress 67.20471281296024\n",
      "Progress 67.29896907216495\n",
      "Progress 67.39322533136966\n",
      "Progress 67.48748159057438\n",
      "Progress 67.58173784977909\n",
      "Progress 67.6759941089838\n",
      "Progress 67.77025036818851\n",
      "Progress 67.86450662739323\n",
      "Progress 67.95876288659794\n",
      "Progress 68.05301914580265\n",
      "Progress 68.14727540500736\n",
      "Progress 68.24153166421208\n",
      "Progress 68.33578792341679\n",
      "Progress 68.4300441826215\n",
      "Progress 68.52430044182621\n",
      "Progress 68.61855670103093\n",
      "Progress 68.71281296023564\n",
      "Progress 68.80706921944035\n",
      "Progress 68.90132547864508\n",
      "Progress 68.99558173784978\n",
      "Progress 69.08983799705449\n",
      "Progress 69.18409425625921\n",
      "Progress 69.27835051546391\n",
      "Progress 69.37260677466864\n",
      "Progress 69.46686303387334\n",
      "Progress 69.56111929307805\n",
      "Progress 69.65537555228278\n",
      "Progress 69.74963181148748\n",
      "Progress 69.8438880706922\n",
      "Progress 69.93814432989691\n",
      "Progress 70.03240058910161\n",
      "Progress 70.12665684830634\n",
      "Progress 70.22091310751104\n",
      "Progress 70.31516936671576\n",
      "Progress 70.40942562592048\n",
      "Progress 70.50368188512518\n",
      "Progress 70.5979381443299\n",
      "Progress 70.69219440353461\n",
      "Progress 70.78645066273933\n",
      "Progress 70.88070692194404\n",
      "Progress 70.97496318114875\n",
      "Progress 71.06921944035346\n",
      "Progress 71.16347569955818\n",
      "Progress 71.25773195876289\n",
      "Progress 71.3519882179676\n",
      "Progress 71.44624447717231\n",
      "Progress 71.54050073637703\n",
      "Progress 71.63475699558174\n",
      "Progress 71.72901325478645\n",
      "Progress 71.82326951399116\n",
      "Progress 71.91752577319588\n",
      "Progress 72.01178203240059\n",
      "Progress 72.1060382916053\n",
      "Progress 72.20029455081001\n",
      "Progress 72.29455081001473\n",
      "Progress 72.38880706921944\n",
      "Progress 72.48306332842415\n",
      "Progress 72.57731958762886\n",
      "Progress 72.67157584683358\n",
      "Progress 72.76583210603829\n",
      "Progress 72.860088365243\n",
      "Progress 72.95434462444771\n",
      "Progress 73.04860088365243\n",
      "Progress 73.14285714285714\n",
      "Progress 73.23711340206187\n",
      "Progress 73.33136966126656\n",
      "Progress 73.42562592047128\n",
      "Progress 73.519882179676\n",
      "Progress 73.6141384388807\n",
      "Progress 73.70839469808543\n",
      "Progress 73.80265095729013\n",
      "Progress 73.89690721649484\n",
      "Progress 73.99116347569957\n",
      "Progress 74.08541973490426\n",
      "Progress 74.17967599410899\n",
      "Progress 74.2739322533137\n",
      "Progress 74.3681885125184\n",
      "Progress 74.46244477172313\n",
      "Progress 74.55670103092783\n",
      "Progress 74.65095729013255\n",
      "Progress 74.74521354933727\n",
      "Progress 74.83946980854196\n",
      "Progress 74.93372606774669\n",
      "Progress 75.0279823269514\n",
      "Progress 75.12223858615612\n",
      "Progress 75.21649484536083\n",
      "Progress 75.31075110456553\n",
      "Progress 75.40500736377025\n",
      "Progress 75.49926362297496\n",
      "Progress 75.59351988217968\n",
      "Progress 75.68777614138439\n",
      "Progress 75.7820324005891\n",
      "Progress 75.87628865979381\n",
      "Progress 75.97054491899853\n",
      "Progress 76.06480117820324\n",
      "Progress 76.15905743740795\n",
      "Progress 76.25331369661266\n",
      "Progress 76.34756995581738\n",
      "Progress 76.44182621502209\n",
      "Progress 76.5360824742268\n",
      "Progress 76.63033873343151\n",
      "Progress 76.72459499263623\n",
      "Progress 76.81885125184095\n",
      "Progress 76.91310751104565\n",
      "Progress 77.00736377025036\n",
      "Progress 77.10162002945508\n",
      "Progress 77.19587628865979\n",
      "Progress 77.29013254786452\n",
      "Progress 77.38438880706921\n",
      "Progress 77.47864506627393\n",
      "Progress 77.57290132547865\n",
      "Progress 77.66715758468335\n",
      "Progress 77.76141384388808\n",
      "Progress 77.85567010309279\n",
      "Progress 77.94992636229749\n",
      "Progress 78.04418262150222\n",
      "Progress 78.13843888070691\n",
      "Progress 78.23269513991164\n",
      "Progress 78.32695139911635\n",
      "Progress 78.42120765832105\n",
      "Progress 78.51546391752578\n",
      "Progress 78.60972017673049\n",
      "Progress 78.7039764359352\n",
      "Progress 78.79823269513992\n",
      "Progress 78.89248895434461\n",
      "Progress 78.98674521354934\n",
      "Progress 79.08100147275405\n",
      "Progress 79.17525773195877\n",
      "Progress 79.26951399116348\n",
      "Progress 79.36377025036819\n",
      "Progress 79.4580265095729\n",
      "Progress 79.55228276877762\n",
      "Progress 79.64653902798233\n",
      "Progress 79.74079528718704\n",
      "Progress 79.83505154639175\n",
      "Progress 79.92930780559647\n",
      "Progress 80.02356406480118\n",
      "Progress 80.11782032400589\n",
      "Progress 80.2120765832106\n",
      "Progress 80.30633284241532\n",
      "Progress 80.40058910162003\n",
      "Progress 80.49484536082474\n",
      "Progress 80.58910162002945\n",
      "Progress 80.68335787923417\n",
      "Progress 80.77761413843888\n",
      "Progress 80.87187039764359\n",
      "Progress 80.9661266568483\n",
      "Progress 81.06038291605302\n",
      "Progress 81.15463917525774\n",
      "Progress 81.24889543446244\n",
      "Progress 81.34315169366715\n",
      "Progress 81.43740795287187\n",
      "Progress 81.53166421207658\n",
      "Progress 81.6259204712813\n",
      "Progress 81.720176730486\n",
      "Progress 81.81443298969072\n",
      "Progress 81.90868924889544\n",
      "Progress 82.00294550810014\n",
      "Progress 82.09720176730487\n",
      "Progress 82.19145802650958\n",
      "Progress 82.28571428571428\n",
      "Progress 82.379970544919\n",
      "Progress 82.4742268041237\n",
      "Progress 82.56848306332843\n",
      "Progress 82.66273932253314\n",
      "Progress 82.75699558173784\n",
      "Progress 82.85125184094257\n",
      "Progress 82.94550810014728\n",
      "Progress 83.03976435935199\n",
      "Progress 83.1340206185567\n",
      "Progress 83.2282768777614\n",
      "Progress 83.32253313696613\n",
      "Progress 83.41678939617084\n",
      "Progress 83.51104565537555\n",
      "Progress 83.60530191458027\n",
      "Progress 83.69955817378498\n",
      "Progress 83.79381443298969\n",
      "Progress 83.8880706921944\n",
      "Progress 83.98232695139912\n",
      "Progress 84.07658321060383\n",
      "Progress 84.17083946980854\n",
      "Progress 84.26509572901325\n",
      "Progress 84.35935198821797\n",
      "Progress 84.45360824742268\n",
      "Progress 84.54786450662739\n",
      "Progress 84.6421207658321\n",
      "Progress 84.73637702503683\n",
      "Progress 84.83063328424153\n",
      "Progress 84.92488954344624\n",
      "Progress 85.01914580265095\n",
      "Progress 85.11340206185567\n",
      "Progress 85.20765832106039\n",
      "Progress 85.30191458026509\n",
      "Progress 85.3961708394698\n",
      "Progress 85.49042709867453\n",
      "Progress 85.58468335787923\n",
      "Progress 85.67893961708396\n",
      "Progress 85.77319587628865\n",
      "Progress 85.86745213549337\n",
      "Progress 85.96170839469809\n",
      "Progress 86.05596465390279\n",
      "Progress 86.15022091310752\n",
      "Progress 86.24447717231223\n",
      "Progress 86.33873343151693\n",
      "Progress 86.43298969072166\n",
      "Progress 86.52724594992635\n",
      "Progress 86.62150220913108\n",
      "Progress 86.71575846833579\n",
      "Progress 86.81001472754049\n",
      "Progress 86.90427098674522\n",
      "Progress 86.99852724594993\n",
      "Progress 87.09278350515464\n",
      "Progress 87.18703976435935\n",
      "Progress 87.28129602356407\n",
      "Progress 87.37555228276878\n",
      "Progress 87.46980854197349\n",
      "Progress 87.5640648011782\n",
      "Progress 87.65832106038292\n",
      "Progress 87.75257731958763\n",
      "Progress 87.84683357879234\n",
      "Progress 87.94108983799705\n",
      "Progress 88.03534609720177\n",
      "Progress 88.12960235640648\n",
      "Progress 88.22385861561119\n",
      "Progress 88.3181148748159\n",
      "Progress 88.41237113402062\n",
      "Progress 88.50662739322533\n",
      "Progress 88.60088365243004\n",
      "Progress 88.69513991163475\n",
      "Progress 88.78939617083947\n",
      "Progress 88.88365243004418\n",
      "Progress 88.97790868924889\n",
      "Progress 89.07216494845362\n",
      "Progress 89.16642120765832\n",
      "Progress 89.26067746686303\n",
      "Progress 89.35493372606774\n",
      "Progress 89.44918998527245\n",
      "Progress 89.54344624447718\n",
      "Progress 89.63770250368188\n",
      "Progress 89.73195876288659\n",
      "Progress 89.82621502209132\n",
      "Progress 89.92047128129602\n",
      "Progress 90.01472754050074\n",
      "Progress 90.10898379970544\n",
      "Progress 90.20324005891015\n",
      "Progress 90.29749631811488\n",
      "Progress 90.39175257731958\n",
      "Progress 90.4860088365243\n",
      "Progress 90.58026509572902\n",
      "Progress 90.67452135493372\n",
      "Progress 90.76877761413844\n",
      "Progress 90.86303387334314\n",
      "Progress 90.95729013254787\n",
      "Progress 91.05154639175258\n",
      "Progress 91.14580265095728\n",
      "Progress 91.240058910162\n",
      "Progress 91.33431516936672\n",
      "Progress 91.42857142857143\n",
      "Progress 91.52282768777614\n",
      "Progress 91.61708394698086\n",
      "Progress 91.71134020618557\n",
      "Progress 91.80559646539028\n",
      "Progress 91.899852724595\n",
      "Progress 91.9941089837997\n",
      "Progress 92.08836524300442\n",
      "Progress 92.18262150220913\n",
      "Progress 92.27687776141384\n",
      "Progress 92.37113402061856\n",
      "Progress 92.46539027982327\n",
      "Progress 92.55964653902798\n",
      "Progress 92.65390279823269\n",
      "Progress 92.7481590574374\n",
      "Progress 92.84241531664212\n",
      "Progress 92.93667157584683\n",
      "Progress 93.03092783505154\n",
      "Progress 93.12518409425627\n",
      "Progress 93.21944035346097\n",
      "Progress 93.31369661266568\n",
      "Progress 93.40795287187039\n",
      "Progress 93.5022091310751\n",
      "Progress 93.59646539027983\n",
      "Progress 93.69072164948453\n",
      "Progress 93.78497790868924\n",
      "Progress 93.87923416789397\n",
      "Progress 93.97349042709867\n",
      "Progress 94.0677466863034\n",
      "Progress 94.1620029455081\n",
      "Progress 94.2562592047128\n",
      "Progress 94.35051546391753\n",
      "Progress 94.44477172312223\n",
      "Progress 94.53902798232696\n",
      "Progress 94.63328424153167\n",
      "Progress 94.72754050073637\n",
      "Progress 94.8217967599411\n",
      "Progress 94.9160530191458\n",
      "Progress 95.01030927835052\n",
      "Progress 95.10456553755523\n",
      "Progress 95.19882179675993\n",
      "Progress 95.29307805596466\n",
      "Progress 95.38733431516937\n",
      "Progress 95.48159057437408\n",
      "Progress 95.5758468335788\n",
      "Progress 95.6701030927835\n",
      "Progress 95.76435935198822\n",
      "Progress 95.85861561119293\n",
      "Progress 95.95287187039764\n",
      "Progress 96.04712812960236\n",
      "Progress 96.14138438880707\n",
      "Progress 96.23564064801178\n",
      "Progress 96.3298969072165\n",
      "Progress 96.4241531664212\n",
      "Progress 96.51840942562592\n",
      "Progress 96.61266568483063\n",
      "Progress 96.70692194403536\n",
      "Progress 96.80117820324006\n",
      "Progress 96.89543446244477\n",
      "Progress 96.98969072164948\n",
      "Progress 97.0839469808542\n",
      "Progress 97.17820324005892\n",
      "Progress 97.27245949926362\n",
      "Progress 97.36671575846833\n",
      "Progress 97.46097201767306\n",
      "Progress 97.55522827687776\n",
      "Progress 97.64948453608248\n",
      "Progress 97.74374079528718\n",
      "Progress 97.8379970544919\n",
      "Progress 97.93225331369662\n",
      "Progress 98.02650957290132\n",
      "Progress 98.12076583210604\n",
      "Progress 98.21502209131076\n",
      "Progress 98.30927835051546\n",
      "Progress 98.40353460972018\n",
      "Progress 98.4977908689249\n",
      "Progress 98.59204712812961\n",
      "Progress 98.68630338733432\n",
      "Progress 98.78055964653902\n",
      "Progress 98.87481590574374\n",
      "Progress 98.96907216494846\n",
      "Progress 99.06332842415317\n",
      "Progress 99.15758468335788\n",
      "Progress 99.2518409425626\n",
      "Progress 99.34609720176731\n",
      "Progress 99.44035346097202\n",
      "Progress 99.53460972017673\n",
      "Progress 99.62886597938144\n",
      "Progress 99.72312223858616\n",
      "Progress 99.81737849779087\n",
      "Progress 99.91163475699558\n",
      "Progress 0.0\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.7540500736377025\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.508100147275405\n",
      "Progress 1.8851251840942562\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.6391752577319587\n",
      "Progress 3.01620029455081\n",
      "Progress 3.393225331369661\n",
      "Progress 3.7702503681885124\n",
      "Progress 4.147275405007364\n",
      "Progress 4.524300441826215\n",
      "Progress 4.901325478645066\n",
      "Progress 5.278350515463917\n",
      "Progress 5.655375552282769\n",
      "Progress 6.03240058910162\n",
      "Progress 6.409425625920472\n",
      "Progress 6.786450662739322\n",
      "Progress 7.163475699558173\n",
      "Progress 7.540500736377025\n",
      "Progress 7.917525773195876\n",
      "Progress 8.294550810014728\n",
      "Progress 8.67157584683358\n",
      "Progress 9.04860088365243\n",
      "Progress 9.425625920471282\n",
      "Progress 9.802650957290131\n",
      "Progress 10.179675994108983\n",
      "Progress 10.556701030927835\n",
      "Progress 10.933726067746687\n",
      "Progress 11.310751104565538\n",
      "Progress 11.687776141384388\n",
      "Progress 12.06480117820324\n",
      "Progress 12.441826215022092\n",
      "Progress 12.818851251840943\n",
      "Progress 13.195876288659795\n",
      "Progress 13.572901325478645\n",
      "Progress 13.949926362297496\n",
      "Progress 14.326951399116346\n",
      "Progress 14.703976435935198\n",
      "Progress 15.08100147275405\n",
      "Progress 15.4580265095729\n",
      "Progress 15.835051546391751\n",
      "Progress 16.212076583210607\n",
      "Progress 16.589101620029457\n",
      "Progress 16.966126656848306\n",
      "Progress 17.34315169366716\n",
      "Progress 17.72017673048601\n",
      "Progress 18.09720176730486\n",
      "Progress 18.47422680412371\n",
      "Progress 18.851251840942563\n",
      "Progress 19.228276877761413\n",
      "Progress 19.605301914580263\n",
      "Progress 19.982326951399116\n",
      "Progress 20.359351988217966\n",
      "Progress 20.73637702503682\n",
      "Progress 21.11340206185567\n",
      "Progress 21.490427098674523\n",
      "Progress 21.867452135493373\n",
      "Progress 22.244477172312223\n",
      "Progress 22.621502209131076\n",
      "Progress 22.998527245949926\n",
      "Progress 23.375552282768776\n",
      "Progress 23.75257731958763\n",
      "Progress 24.12960235640648\n",
      "Progress 24.50662739322533\n",
      "Progress 24.883652430044183\n",
      "Progress 25.260677466863036\n",
      "Progress 25.637702503681886\n",
      "Progress 26.014727540500736\n",
      "Progress 26.39175257731959\n",
      "Progress 26.76877761413844\n",
      "Progress 27.14580265095729\n",
      "Progress 27.522827687776143\n",
      "Progress 27.899852724594993\n",
      "Progress 28.276877761413843\n",
      "Progress 28.653902798232693\n",
      "Progress 29.030927835051546\n",
      "Progress 29.407952871870396\n",
      "Progress 29.784977908689246\n",
      "Progress 30.1620029455081\n",
      "Progress 30.53902798232695\n",
      "Progress 30.9160530191458\n",
      "Progress 31.293078055964653\n",
      "Progress 31.670103092783503\n",
      "Progress 32.047128129602356\n",
      "Progress 32.42415316642121\n",
      "Progress 32.80117820324006\n",
      "Progress 33.17820324005891\n",
      "Progress 33.55522827687776\n",
      "Progress 33.93225331369661\n",
      "Progress 34.30927835051546\n",
      "Progress 34.68630338733432\n",
      "Progress 35.06332842415317\n",
      "Progress 35.44035346097202\n",
      "Progress 35.81737849779087\n",
      "Progress 36.19440353460972\n",
      "Progress 36.57142857142857\n",
      "Progress 36.94845360824742\n",
      "Progress 37.325478645066276\n",
      "Progress 37.702503681885126\n",
      "Progress 38.079528718703976\n",
      "Progress 38.456553755522826\n",
      "Progress 38.833578792341676\n",
      "Progress 39.210603829160526\n",
      "Progress 39.58762886597938\n",
      "Progress 39.96465390279823\n",
      "Progress 40.34167893961708\n",
      "Progress 40.71870397643593\n",
      "Progress 41.09572901325479\n",
      "Progress 41.47275405007364\n",
      "Progress 41.84977908689249\n",
      "Progress 42.22680412371134\n",
      "Progress 42.603829160530196\n",
      "Progress 42.980854197349046\n",
      "Progress 43.357879234167896\n",
      "Progress 43.734904270986746\n",
      "Progress 44.111929307805596\n",
      "Progress 44.488954344624446\n",
      "Progress 44.865979381443296\n",
      "Progress 45.24300441826215\n",
      "Progress 45.620029455081\n",
      "Progress 45.99705449189985\n",
      "Progress 46.3740795287187\n",
      "Progress 46.75110456553755\n",
      "Progress 47.1281296023564\n",
      "Progress 47.50515463917526\n",
      "Progress 47.88217967599411\n",
      "Progress 48.25920471281296\n",
      "Progress 48.63622974963181\n",
      "Progress 49.01325478645066\n",
      "Progress 49.39027982326951\n",
      "Progress 49.767304860088366\n",
      "Progress 50.144329896907216\n",
      "Progress 50.52135493372607\n",
      "Progress 50.898379970544916\n",
      "Progress 51.27540500736377\n",
      "Progress 51.652430044182616\n",
      "Progress 52.02945508100147\n",
      "Progress 52.40648011782032\n",
      "Progress 52.78350515463918\n",
      "Progress 53.16053019145802\n",
      "Progress 53.53755522827688\n",
      "Progress 53.91458026509572\n",
      "Progress 54.29160530191458\n",
      "Progress 54.66863033873343\n",
      "Progress 55.045655375552286\n",
      "Progress 55.422680412371136\n",
      "Progress 55.799705449189986\n",
      "Progress 56.17673048600884\n",
      "Progress 56.553755522827686\n",
      "Progress 56.93078055964654\n",
      "Progress 57.307805596465386\n",
      "Progress 57.68483063328424\n",
      "Progress 58.06185567010309\n",
      "Progress 58.43888070692195\n",
      "Progress 58.81590574374079\n",
      "Progress 59.19293078055965\n",
      "Progress 59.56995581737849\n",
      "Progress 59.94698085419735\n",
      "Progress 60.3240058910162\n",
      "Progress 60.701030927835056\n",
      "Progress 61.0780559646539\n",
      "Progress 61.455081001472756\n",
      "Progress 61.8321060382916\n",
      "Progress 62.209131075110456\n",
      "Progress 62.586156111929306\n",
      "Progress 62.96318114874816\n",
      "Progress 63.340206185567006\n",
      "Progress 63.71723122238586\n",
      "Progress 64.09425625920471\n",
      "Progress 64.47128129602356\n",
      "Progress 64.84830633284243\n",
      "Progress 65.22533136966126\n",
      "Progress 65.60235640648013\n",
      "Progress 65.97938144329896\n",
      "Progress 66.35640648011783\n",
      "Progress 66.73343151693668\n",
      "Progress 67.11045655375553\n",
      "Progress 67.48748159057438\n",
      "Progress 67.86450662739323\n",
      "Progress 68.24153166421208\n",
      "Progress 68.61855670103093\n",
      "Progress 68.99558173784978\n",
      "Progress 69.37260677466864\n",
      "Progress 69.74963181148748\n",
      "Progress 70.12665684830634\n",
      "Progress 70.50368188512518\n",
      "Progress 70.88070692194404\n",
      "Progress 71.25773195876289\n",
      "Progress 71.63475699558174\n",
      "Progress 72.01178203240059\n",
      "Progress 72.38880706921944\n",
      "Progress 72.76583210603829\n",
      "Progress 73.14285714285714\n",
      "Progress 73.519882179676\n",
      "Progress 73.89690721649484\n",
      "Progress 74.2739322533137\n",
      "Progress 74.65095729013255\n",
      "Progress 75.0279823269514\n",
      "Progress 75.40500736377025\n",
      "Progress 75.7820324005891\n",
      "Progress 76.15905743740795\n",
      "Progress 76.5360824742268\n",
      "Progress 76.91310751104565\n",
      "Progress 77.29013254786452\n",
      "Progress 77.66715758468335\n",
      "Progress 78.04418262150222\n",
      "Progress 78.42120765832105\n",
      "Progress 78.79823269513992\n",
      "Progress 79.17525773195877\n",
      "Progress 79.55228276877762\n",
      "Progress 79.92930780559647\n",
      "Progress 80.30633284241532\n",
      "Progress 80.68335787923417\n",
      "Progress 81.06038291605302\n",
      "Progress 81.43740795287187\n",
      "Progress 81.81443298969072\n",
      "Progress 82.19145802650958\n",
      "Progress 82.56848306332843\n",
      "Progress 82.94550810014728\n",
      "Progress 83.32253313696613\n",
      "Progress 83.69955817378498\n",
      "Progress 84.07658321060383\n",
      "Progress 84.45360824742268\n",
      "Progress 84.83063328424153\n",
      "Progress 85.20765832106039\n",
      "Progress 85.58468335787923\n",
      "Progress 85.96170839469809\n",
      "Progress 86.33873343151693\n",
      "Progress 86.71575846833579\n",
      "Progress 87.09278350515464\n",
      "Progress 87.46980854197349\n",
      "Progress 87.84683357879234\n",
      "Progress 88.22385861561119\n",
      "Progress 88.60088365243004\n",
      "Progress 88.97790868924889\n",
      "Progress 89.35493372606774\n",
      "Progress 89.73195876288659\n",
      "Progress 90.10898379970544\n",
      "Progress 90.4860088365243\n",
      "Progress 90.86303387334314\n",
      "Progress 91.240058910162\n",
      "Progress 91.61708394698086\n",
      "Progress 91.9941089837997\n",
      "Progress 92.37113402061856\n",
      "Progress 92.7481590574374\n",
      "Progress 93.12518409425627\n",
      "Progress 93.5022091310751\n",
      "Progress 93.87923416789397\n",
      "Progress 94.2562592047128\n",
      "Progress 94.63328424153167\n",
      "Progress 95.01030927835052\n",
      "Progress 95.38733431516937\n",
      "Progress 95.76435935198822\n",
      "Progress 96.14138438880707\n",
      "Progress 96.51840942562592\n",
      "Progress 96.89543446244477\n",
      "Progress 97.27245949926362\n",
      "Progress 97.64948453608248\n",
      "Progress 98.02650957290132\n",
      "Progress 98.40353460972018\n",
      "Progress 98.78055964653902\n",
      "Progress 99.15758468335788\n",
      "Progress 99.53460972017673\n",
      "Progress 99.91163475699558\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.2365e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.2349e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.24936e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.25205e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23904e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.15915007 0.15915379        nan        nan\n",
      " 0.19577138 0.19577707        nan        nan 0.20255071        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [59:07, 1182.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Progress 0.0\n",
      "Progress 0.09425625920471281\n",
      "Progress 0.18851251840942562\n",
      "Progress 0.28276877761413843\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.47128129602356406\n",
      "Progress 0.5655375552282769\n",
      "Progress 0.6597938144329897\n",
      "Progress 0.7540500736377025\n",
      "Progress 0.8483063328424153\n",
      "Progress 0.9425625920471281\n",
      "Progress 1.036818851251841\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.2253313696612664\n",
      "Progress 1.3195876288659794\n",
      "Progress 1.4138438880706923\n",
      "Progress 1.508100147275405\n",
      "Progress 1.602356406480118\n",
      "Progress 1.6966126656848306\n",
      "Progress 1.7908689248895433\n",
      "Progress 1.8851251840942562\n",
      "Progress 1.979381443298969\n",
      "Progress 2.073637702503682\n",
      "Progress 2.167893961708395\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.3564064801178204\n",
      "Progress 2.450662739322533\n",
      "Progress 2.544918998527246\n",
      "Progress 2.6391752577319587\n",
      "Progress 2.7334315169366716\n",
      "Progress 2.8276877761413846\n",
      "Progress 2.921944035346097\n",
      "Progress 3.01620029455081\n",
      "Progress 3.110456553755523\n",
      "Progress 3.204712812960236\n",
      "Progress 3.2989690721649487\n",
      "Progress 3.393225331369661\n",
      "Progress 3.487481590574374\n",
      "Progress 3.5817378497790866\n",
      "Progress 3.6759941089837995\n",
      "Progress 3.7702503681885124\n",
      "Progress 3.864506627393225\n",
      "Progress 3.958762886597938\n",
      "Progress 4.053019145802652\n",
      "Progress 4.147275405007364\n",
      "Progress 4.241531664212077\n",
      "Progress 4.33578792341679\n",
      "Progress 4.4300441826215025\n",
      "Progress 4.524300441826215\n",
      "Progress 4.618556701030927\n",
      "Progress 4.712812960235641\n",
      "Progress 4.807069219440353\n",
      "Progress 4.901325478645066\n",
      "Progress 4.995581737849779\n",
      "Progress 5.089837997054492\n",
      "Progress 5.184094256259205\n",
      "Progress 5.278350515463917\n",
      "Progress 5.372606774668631\n",
      "Progress 5.466863033873343\n",
      "Progress 5.561119293078056\n",
      "Progress 5.655375552282769\n",
      "Progress 5.749631811487482\n",
      "Progress 5.843888070692194\n",
      "Progress 5.938144329896907\n",
      "Progress 6.03240058910162\n",
      "Progress 6.126656848306332\n",
      "Progress 6.220913107511046\n",
      "Progress 6.315169366715759\n",
      "Progress 6.409425625920472\n",
      "Progress 6.503681885125184\n",
      "Progress 6.5979381443298974\n",
      "Progress 6.69219440353461\n",
      "Progress 6.786450662739322\n",
      "Progress 6.880706921944036\n",
      "Progress 6.974963181148748\n",
      "Progress 7.069219440353461\n",
      "Progress 7.163475699558173\n",
      "Progress 7.257731958762887\n",
      "Progress 7.351988217967599\n",
      "Progress 7.4462444771723115\n",
      "Progress 7.540500736377025\n",
      "Progress 7.634756995581737\n",
      "Progress 7.72901325478645\n",
      "Progress 7.823269513991163\n",
      "Progress 7.917525773195876\n",
      "Progress 8.011782032400589\n",
      "Progress 8.106038291605303\n",
      "Progress 8.200294550810016\n",
      "Progress 8.294550810014728\n",
      "Progress 8.38880706921944\n",
      "Progress 8.483063328424153\n",
      "Progress 8.577319587628866\n",
      "Progress 8.67157584683358\n",
      "Progress 8.765832106038292\n",
      "Progress 8.860088365243005\n",
      "Progress 8.954344624447717\n",
      "Progress 9.04860088365243\n",
      "Progress 9.142857142857142\n",
      "Progress 9.237113402061855\n",
      "Progress 9.331369661266569\n",
      "Progress 9.425625920471282\n",
      "Progress 9.519882179675994\n",
      "Progress 9.614138438880707\n",
      "Progress 9.708394698085419\n",
      "Progress 9.802650957290131\n",
      "Progress 9.896907216494846\n",
      "Progress 9.991163475699558\n",
      "Progress 10.08541973490427\n",
      "Progress 10.179675994108983\n",
      "Progress 10.273932253313697\n",
      "Progress 10.36818851251841\n",
      "Progress 10.462444771723122\n",
      "Progress 10.556701030927835\n",
      "Progress 10.650957290132549\n",
      "Progress 10.745213549337262\n",
      "Progress 10.839469808541974\n",
      "Progress 10.933726067746687\n",
      "Progress 11.027982326951399\n",
      "Progress 11.122238586156111\n",
      "Progress 11.216494845360824\n",
      "Progress 11.310751104565538\n",
      "Progress 11.40500736377025\n",
      "Progress 11.499263622974963\n",
      "Progress 11.593519882179676\n",
      "Progress 11.687776141384388\n",
      "Progress 11.7820324005891\n",
      "Progress 11.876288659793815\n",
      "Progress 11.970544918998527\n",
      "Progress 12.06480117820324\n",
      "Progress 12.159057437407952\n",
      "Progress 12.253313696612665\n",
      "Progress 12.347569955817377\n",
      "Progress 12.441826215022092\n",
      "Progress 12.536082474226804\n",
      "Progress 12.630338733431518\n",
      "Progress 12.724594992636229\n",
      "Progress 12.818851251840943\n",
      "Progress 12.913107511045654\n",
      "Progress 13.007363770250368\n",
      "Progress 13.10162002945508\n",
      "Progress 13.195876288659795\n",
      "Progress 13.290132547864506\n",
      "Progress 13.38438880706922\n",
      "Progress 13.47864506627393\n",
      "Progress 13.572901325478645\n",
      "Progress 13.667157584683357\n",
      "Progress 13.761413843888072\n",
      "Progress 13.855670103092784\n",
      "Progress 13.949926362297496\n",
      "Progress 14.04418262150221\n",
      "Progress 14.138438880706921\n",
      "Progress 14.232695139911636\n",
      "Progress 14.326951399116346\n",
      "Progress 14.42120765832106\n",
      "Progress 14.515463917525773\n",
      "Progress 14.609720176730487\n",
      "Progress 14.703976435935198\n",
      "Progress 14.798232695139912\n",
      "Progress 14.892488954344623\n",
      "Progress 14.986745213549337\n",
      "Progress 15.08100147275405\n",
      "Progress 15.175257731958764\n",
      "Progress 15.269513991163475\n",
      "Progress 15.363770250368189\n",
      "Progress 15.4580265095729\n",
      "Progress 15.552282768777614\n",
      "Progress 15.646539027982326\n",
      "Progress 15.74079528718704\n",
      "Progress 15.835051546391751\n",
      "Progress 15.929307805596466\n",
      "Progress 16.023564064801178\n",
      "Progress 16.11782032400589\n",
      "Progress 16.212076583210607\n",
      "Progress 16.306332842415316\n",
      "Progress 16.40058910162003\n",
      "Progress 16.49484536082474\n",
      "Progress 16.589101620029457\n",
      "Progress 16.68335787923417\n",
      "Progress 16.77761413843888\n",
      "Progress 16.871870397643594\n",
      "Progress 16.966126656848306\n",
      "Progress 17.06038291605302\n",
      "Progress 17.15463917525773\n",
      "Progress 17.248895434462444\n",
      "Progress 17.34315169366716\n",
      "Progress 17.43740795287187\n",
      "Progress 17.531664212076585\n",
      "Progress 17.625920471281294\n",
      "Progress 17.72017673048601\n",
      "Progress 17.814432989690722\n",
      "Progress 17.908689248895435\n",
      "Progress 18.002945508100147\n",
      "Progress 18.09720176730486\n",
      "Progress 18.191458026509572\n",
      "Progress 18.285714285714285\n",
      "Progress 18.379970544919\n",
      "Progress 18.47422680412371\n",
      "Progress 18.568483063328426\n",
      "Progress 18.662739322533138\n",
      "Progress 18.75699558173785\n",
      "Progress 18.851251840942563\n",
      "Progress 18.945508100147276\n",
      "Progress 19.039764359351988\n",
      "Progress 19.1340206185567\n",
      "Progress 19.228276877761413\n",
      "Progress 19.32253313696613\n",
      "Progress 19.416789396170838\n",
      "Progress 19.511045655375554\n",
      "Progress 19.605301914580263\n",
      "Progress 19.69955817378498\n",
      "Progress 19.79381443298969\n",
      "Progress 19.888070692194404\n",
      "Progress 19.982326951399116\n",
      "Progress 20.07658321060383\n",
      "Progress 20.17083946980854\n",
      "Progress 20.265095729013254\n",
      "Progress 20.359351988217966\n",
      "Progress 20.45360824742268\n",
      "Progress 20.547864506627395\n",
      "Progress 20.642120765832107\n",
      "Progress 20.73637702503682\n",
      "Progress 20.830633284241532\n",
      "Progress 20.924889543446245\n",
      "Progress 21.019145802650957\n",
      "Progress 21.11340206185567\n",
      "Progress 21.207658321060382\n",
      "Progress 21.301914580265098\n",
      "Progress 21.396170839469807\n",
      "Progress 21.490427098674523\n",
      "Progress 21.584683357879232\n",
      "Progress 21.678939617083948\n",
      "Progress 21.77319587628866\n",
      "Progress 21.867452135493373\n",
      "Progress 21.961708394698086\n",
      "Progress 22.055964653902798\n",
      "Progress 22.15022091310751\n",
      "Progress 22.244477172312223\n",
      "Progress 22.338733431516935\n",
      "Progress 22.432989690721648\n",
      "Progress 22.52724594992636\n",
      "Progress 22.621502209131076\n",
      "Progress 22.715758468335785\n",
      "Progress 22.8100147275405\n",
      "Progress 22.904270986745214\n",
      "Progress 22.998527245949926\n",
      "Progress 23.09278350515464\n",
      "Progress 23.18703976435935\n",
      "Progress 23.281296023564067\n",
      "Progress 23.375552282768776\n",
      "Progress 23.469808541973492\n",
      "Progress 23.5640648011782\n",
      "Progress 23.658321060382917\n",
      "Progress 23.75257731958763\n",
      "Progress 23.846833578792342\n",
      "Progress 23.941089837997055\n",
      "Progress 24.035346097201767\n",
      "Progress 24.12960235640648\n",
      "Progress 24.223858615611192\n",
      "Progress 24.318114874815905\n",
      "Progress 24.41237113402062\n",
      "Progress 24.50662739322533\n",
      "Progress 24.600883652430046\n",
      "Progress 24.695139911634755\n",
      "Progress 24.78939617083947\n",
      "Progress 24.883652430044183\n",
      "Progress 24.977908689248896\n",
      "Progress 25.072164948453608\n",
      "Progress 25.166421207658324\n",
      "Progress 25.260677466863036\n",
      "Progress 25.354933726067745\n",
      "Progress 25.449189985272458\n",
      "Progress 25.543446244477174\n",
      "Progress 25.637702503681886\n",
      "Progress 25.7319587628866\n",
      "Progress 25.826215022091308\n",
      "Progress 25.920471281296027\n",
      "Progress 26.014727540500736\n",
      "Progress 26.10898379970545\n",
      "Progress 26.20324005891016\n",
      "Progress 26.297496318114877\n",
      "Progress 26.39175257731959\n",
      "Progress 26.4860088365243\n",
      "Progress 26.58026509572901\n",
      "Progress 26.674521354933727\n",
      "Progress 26.76877761413844\n",
      "Progress 26.863033873343152\n",
      "Progress 26.95729013254786\n",
      "Progress 27.05154639175258\n",
      "Progress 27.14580265095729\n",
      "Progress 27.240058910162002\n",
      "Progress 27.334315169366715\n",
      "Progress 27.42857142857143\n",
      "Progress 27.522827687776143\n",
      "Progress 27.617083946980852\n",
      "Progress 27.711340206185568\n",
      "Progress 27.80559646539028\n",
      "Progress 27.899852724594993\n",
      "Progress 27.994108983799705\n",
      "Progress 28.08836524300442\n",
      "Progress 28.18262150220913\n",
      "Progress 28.276877761413843\n",
      "Progress 28.371134020618555\n",
      "Progress 28.46539027982327\n",
      "Progress 28.559646539027984\n",
      "Progress 28.653902798232693\n",
      "Progress 28.748159057437405\n",
      "Progress 28.84241531664212\n",
      "Progress 28.936671575846834\n",
      "Progress 29.030927835051546\n",
      "Progress 29.125184094256255\n",
      "Progress 29.219440353460975\n",
      "Progress 29.313696612665684\n",
      "Progress 29.407952871870396\n",
      "Progress 29.50220913107511\n",
      "Progress 29.596465390279825\n",
      "Progress 29.690721649484537\n",
      "Progress 29.784977908689246\n",
      "Progress 29.879234167893966\n",
      "Progress 29.973490427098675\n",
      "Progress 30.067746686303387\n",
      "Progress 30.1620029455081\n",
      "Progress 30.256259204712816\n",
      "Progress 30.350515463917528\n",
      "Progress 30.444771723122237\n",
      "Progress 30.53902798232695\n",
      "Progress 30.633284241531666\n",
      "Progress 30.727540500736378\n",
      "Progress 30.82179675994109\n",
      "Progress 30.9160530191458\n",
      "Progress 31.01030927835052\n",
      "Progress 31.104565537555228\n",
      "Progress 31.19882179675994\n",
      "Progress 31.293078055964653\n",
      "Progress 31.38733431516937\n",
      "Progress 31.48159057437408\n",
      "Progress 31.57584683357879\n",
      "Progress 31.670103092783503\n",
      "Progress 31.76435935198822\n",
      "Progress 31.85861561119293\n",
      "Progress 31.952871870397644\n",
      "Progress 32.047128129602356\n",
      "Progress 32.14138438880707\n",
      "Progress 32.23564064801178\n",
      "Progress 32.329896907216494\n",
      "Progress 32.42415316642121\n",
      "Progress 32.51840942562592\n",
      "Progress 32.61266568483063\n",
      "Progress 32.706921944035344\n",
      "Progress 32.80117820324006\n",
      "Progress 32.895434462444776\n",
      "Progress 32.98969072164948\n",
      "Progress 33.08394698085419\n",
      "Progress 33.17820324005891\n",
      "Progress 33.272459499263626\n",
      "Progress 33.36671575846834\n",
      "Progress 33.46097201767304\n",
      "Progress 33.55522827687776\n",
      "Progress 33.649484536082475\n",
      "Progress 33.74374079528719\n",
      "Progress 33.8379970544919\n",
      "Progress 33.93225331369661\n",
      "Progress 34.026509572901325\n",
      "Progress 34.12076583210604\n",
      "Progress 34.21502209131075\n",
      "Progress 34.30927835051546\n",
      "Progress 34.403534609720175\n",
      "Progress 34.49779086892489\n",
      "Progress 34.59204712812961\n",
      "Progress 34.68630338733432\n",
      "Progress 34.780559646539025\n",
      "Progress 34.87481590574374\n",
      "Progress 34.96907216494846\n",
      "Progress 35.06332842415317\n",
      "Progress 35.15758468335788\n",
      "Progress 35.25184094256259\n",
      "Progress 35.34609720176731\n",
      "Progress 35.44035346097202\n",
      "Progress 35.53460972017673\n",
      "Progress 35.628865979381445\n",
      "Progress 35.72312223858616\n",
      "Progress 35.81737849779087\n",
      "Progress 35.91163475699558\n",
      "Progress 36.005891016200295\n",
      "Progress 36.10014727540501\n",
      "Progress 36.19440353460972\n",
      "Progress 36.28865979381443\n",
      "Progress 36.382916053019144\n",
      "Progress 36.47717231222386\n",
      "Progress 36.57142857142857\n",
      "Progress 36.66568483063328\n",
      "Progress 36.759941089838\n",
      "Progress 36.854197349042714\n",
      "Progress 36.94845360824742\n",
      "Progress 37.04270986745213\n",
      "Progress 37.13696612665685\n",
      "Progress 37.231222385861564\n",
      "Progress 37.325478645066276\n",
      "Progress 37.41973490427098\n",
      "Progress 37.5139911634757\n",
      "Progress 37.608247422680414\n",
      "Progress 37.702503681885126\n",
      "Progress 37.79675994108984\n",
      "Progress 37.89101620029455\n",
      "Progress 37.985272459499264\n",
      "Progress 38.079528718703976\n",
      "Progress 38.17378497790869\n",
      "Progress 38.2680412371134\n",
      "Progress 38.362297496318114\n",
      "Progress 38.456553755522826\n",
      "Progress 38.55081001472754\n",
      "Progress 38.64506627393226\n",
      "Progress 38.73932253313696\n",
      "Progress 38.833578792341676\n",
      "Progress 38.927835051546396\n",
      "Progress 39.02209131075111\n",
      "Progress 39.11634756995582\n",
      "Progress 39.210603829160526\n",
      "Progress 39.304860088365245\n",
      "Progress 39.39911634756996\n",
      "Progress 39.49337260677467\n",
      "Progress 39.58762886597938\n",
      "Progress 39.681885125184095\n",
      "Progress 39.77614138438881\n",
      "Progress 39.87039764359352\n",
      "Progress 39.96465390279823\n",
      "Progress 40.058910162002945\n",
      "Progress 40.15316642120766\n",
      "Progress 40.24742268041237\n",
      "Progress 40.34167893961708\n",
      "Progress 40.435935198821795\n",
      "Progress 40.53019145802651\n",
      "Progress 40.62444771723122\n",
      "Progress 40.71870397643593\n",
      "Progress 40.81296023564065\n",
      "Progress 40.90721649484536\n",
      "Progress 41.00147275405007\n",
      "Progress 41.09572901325479\n",
      "Progress 41.1899852724595\n",
      "Progress 41.284241531664215\n",
      "Progress 41.37849779086892\n",
      "Progress 41.47275405007364\n",
      "Progress 41.56701030927835\n",
      "Progress 41.661266568483065\n",
      "Progress 41.75552282768778\n",
      "Progress 41.84977908689249\n",
      "Progress 41.9440353460972\n",
      "Progress 42.038291605301914\n",
      "Progress 42.13254786450663\n",
      "Progress 42.22680412371134\n",
      "Progress 42.32106038291605\n",
      "Progress 42.415316642120764\n",
      "Progress 42.50957290132548\n",
      "Progress 42.603829160530196\n",
      "Progress 42.6980854197349\n",
      "Progress 42.792341678939614\n",
      "Progress 42.88659793814433\n",
      "Progress 42.980854197349046\n",
      "Progress 43.07511045655376\n",
      "Progress 43.169366715758464\n",
      "Progress 43.26362297496318\n",
      "Progress 43.357879234167896\n",
      "Progress 43.45213549337261\n",
      "Progress 43.54639175257732\n",
      "Progress 43.640648011782034\n",
      "Progress 43.734904270986746\n",
      "Progress 43.82916053019146\n",
      "Progress 43.92341678939617\n",
      "Progress 44.017673048600884\n",
      "Progress 44.111929307805596\n",
      "Progress 44.20618556701031\n",
      "Progress 44.30044182621502\n",
      "Progress 44.39469808541973\n",
      "Progress 44.488954344624446\n",
      "Progress 44.58321060382916\n",
      "Progress 44.67746686303387\n",
      "Progress 44.77172312223859\n",
      "Progress 44.865979381443296\n",
      "Progress 44.96023564064801\n",
      "Progress 45.05449189985272\n",
      "Progress 45.14874815905744\n",
      "Progress 45.24300441826215\n",
      "Progress 45.33726067746686\n",
      "Progress 45.43151693667157\n",
      "Progress 45.52577319587629\n",
      "Progress 45.620029455081\n",
      "Progress 45.714285714285715\n",
      "Progress 45.80854197349043\n",
      "Progress 45.90279823269514\n",
      "Progress 45.99705449189985\n",
      "Progress 46.091310751104565\n",
      "Progress 46.18556701030928\n",
      "Progress 46.27982326951399\n",
      "Progress 46.3740795287187\n",
      "Progress 46.468335787923415\n",
      "Progress 46.562592047128135\n",
      "Progress 46.65684830633284\n",
      "Progress 46.75110456553755\n",
      "Progress 46.845360824742265\n",
      "Progress 46.939617083946985\n",
      "Progress 47.0338733431517\n",
      "Progress 47.1281296023564\n",
      "Progress 47.222385861561115\n",
      "Progress 47.316642120765835\n",
      "Progress 47.41089837997055\n",
      "Progress 47.50515463917526\n",
      "Progress 47.599410898379965\n",
      "Progress 47.693667157584684\n",
      "Progress 47.7879234167894\n",
      "Progress 47.88217967599411\n",
      "Progress 47.97643593519882\n",
      "Progress 48.070692194403534\n",
      "Progress 48.16494845360825\n",
      "Progress 48.25920471281296\n",
      "Progress 48.35346097201768\n",
      "Progress 48.447717231222384\n",
      "Progress 48.5419734904271\n",
      "Progress 48.63622974963181\n",
      "Progress 48.73048600883653\n",
      "Progress 48.82474226804124\n",
      "Progress 48.91899852724595\n",
      "Progress 49.01325478645066\n",
      "Progress 49.10751104565538\n",
      "Progress 49.20176730486009\n",
      "Progress 49.296023564064804\n",
      "Progress 49.39027982326951\n",
      "Progress 49.48453608247423\n",
      "Progress 49.57879234167894\n",
      "Progress 49.673048600883654\n",
      "Progress 49.767304860088366\n",
      "Progress 49.86156111929308\n",
      "Progress 49.95581737849779\n",
      "Progress 50.05007363770251\n",
      "Progress 50.144329896907216\n",
      "Progress 50.23858615611193\n",
      "Progress 50.33284241531665\n",
      "Progress 50.42709867452135\n",
      "Progress 50.52135493372607\n",
      "Progress 50.61561119293078\n",
      "Progress 50.70986745213549\n",
      "Progress 50.80412371134021\n",
      "Progress 50.898379970544916\n",
      "Progress 50.992636229749635\n",
      "Progress 51.08689248895435\n",
      "Progress 51.18114874815905\n",
      "Progress 51.27540500736377\n",
      "Progress 51.36966126656848\n",
      "Progress 51.4639175257732\n",
      "Progress 51.55817378497791\n",
      "Progress 51.652430044182616\n",
      "Progress 51.746686303387335\n",
      "Progress 51.840942562592055\n",
      "Progress 51.93519882179676\n",
      "Progress 52.02945508100147\n",
      "Progress 52.12371134020618\n",
      "Progress 52.2179675994109\n",
      "Progress 52.31222385861562\n",
      "Progress 52.40648011782032\n",
      "Progress 52.500736377025035\n",
      "Progress 52.594992636229755\n",
      "Progress 52.68924889543446\n",
      "Progress 52.78350515463918\n",
      "Progress 52.87776141384389\n",
      "Progress 52.9720176730486\n",
      "Progress 53.06627393225332\n",
      "Progress 53.16053019145802\n",
      "Progress 53.25478645066274\n",
      "Progress 53.349042709867454\n",
      "Progress 53.44329896907216\n",
      "Progress 53.53755522827688\n",
      "Progress 53.6318114874816\n",
      "Progress 53.726067746686304\n",
      "Progress 53.82032400589102\n",
      "Progress 53.91458026509572\n",
      "Progress 54.00883652430044\n",
      "Progress 54.10309278350516\n",
      "Progress 54.19734904270987\n",
      "Progress 54.29160530191458\n",
      "Progress 54.3858615611193\n",
      "Progress 54.480117820324004\n",
      "Progress 54.574374079528724\n",
      "Progress 54.66863033873343\n",
      "Progress 54.76288659793814\n",
      "Progress 54.85714285714286\n",
      "Progress 54.95139911634757\n",
      "Progress 55.045655375552286\n",
      "Progress 55.139911634757\n",
      "Progress 55.234167893961704\n",
      "Progress 55.328424153166424\n",
      "Progress 55.422680412371136\n",
      "Progress 55.51693667157585\n",
      "Progress 55.61119293078056\n",
      "Progress 55.705449189985266\n",
      "Progress 55.799705449189986\n",
      "Progress 55.8939617083947\n",
      "Progress 55.98821796759941\n",
      "Progress 56.08247422680412\n",
      "Progress 56.17673048600884\n",
      "Progress 56.27098674521355\n",
      "Progress 56.36524300441826\n",
      "Progress 56.45949926362297\n",
      "Progress 56.553755522827686\n",
      "Progress 56.648011782032405\n",
      "Progress 56.74226804123711\n",
      "Progress 56.83652430044182\n",
      "Progress 56.93078055964654\n",
      "Progress 57.02503681885125\n",
      "Progress 57.11929307805597\n",
      "Progress 57.21354933726068\n",
      "Progress 57.307805596465386\n",
      "Progress 57.402061855670105\n",
      "Progress 57.49631811487481\n",
      "Progress 57.59057437407953\n",
      "Progress 57.68483063328424\n",
      "Progress 57.77908689248895\n",
      "Progress 57.87334315169367\n",
      "Progress 57.96759941089839\n",
      "Progress 58.06185567010309\n",
      "Progress 58.156111929307805\n",
      "Progress 58.25036818851251\n",
      "Progress 58.34462444771723\n",
      "Progress 58.43888070692195\n",
      "Progress 58.533136966126655\n",
      "Progress 58.62739322533137\n",
      "Progress 58.72164948453609\n",
      "Progress 58.81590574374079\n",
      "Progress 58.91016200294551\n",
      "Progress 59.00441826215022\n",
      "Progress 59.09867452135493\n",
      "Progress 59.19293078055965\n",
      "Progress 59.287187039764355\n",
      "Progress 59.381443298969074\n",
      "Progress 59.47569955817379\n",
      "Progress 59.56995581737849\n",
      "Progress 59.66421207658321\n",
      "Progress 59.75846833578793\n",
      "Progress 59.85272459499264\n",
      "Progress 59.94698085419735\n",
      "Progress 60.041237113402055\n",
      "Progress 60.135493372606774\n",
      "Progress 60.229749631811494\n",
      "Progress 60.3240058910162\n",
      "Progress 60.41826215022091\n",
      "Progress 60.51251840942563\n",
      "Progress 60.60677466863034\n",
      "Progress 60.701030927835056\n",
      "Progress 60.79528718703976\n",
      "Progress 60.889543446244474\n",
      "Progress 60.983799705449194\n",
      "Progress 61.0780559646539\n",
      "Progress 61.17231222385862\n",
      "Progress 61.26656848306333\n",
      "Progress 61.360824742268036\n",
      "Progress 61.455081001472756\n",
      "Progress 61.54933726067746\n",
      "Progress 61.64359351988218\n",
      "Progress 61.73784977908689\n",
      "Progress 61.8321060382916\n",
      "Progress 61.92636229749632\n",
      "Progress 62.02061855670104\n",
      "Progress 62.11487481590574\n",
      "Progress 62.209131075110456\n",
      "Progress 62.303387334315175\n",
      "Progress 62.39764359351988\n",
      "Progress 62.4918998527246\n",
      "Progress 62.586156111929306\n",
      "Progress 62.68041237113402\n",
      "Progress 62.77466863033874\n",
      "Progress 62.86892488954344\n",
      "Progress 62.96318114874816\n",
      "Progress 63.057437407952875\n",
      "Progress 63.15169366715758\n",
      "Progress 63.2459499263623\n",
      "Progress 63.340206185567006\n",
      "Progress 63.434462444771725\n",
      "Progress 63.52871870397644\n",
      "Progress 63.62297496318114\n",
      "Progress 63.71723122238586\n",
      "Progress 63.811487481590575\n",
      "Progress 63.90574374079529\n",
      "Progress 64.0\n",
      "Progress 64.09425625920471\n",
      "Progress 64.18851251840942\n",
      "Progress 64.28276877761414\n",
      "Progress 64.37702503681885\n",
      "Progress 64.47128129602356\n",
      "Progress 64.56553755522827\n",
      "Progress 64.65979381443299\n",
      "Progress 64.7540500736377\n",
      "Progress 64.84830633284243\n",
      "Progress 64.94256259204712\n",
      "Progress 65.03681885125184\n",
      "Progress 65.13107511045655\n",
      "Progress 65.22533136966126\n",
      "Progress 65.31958762886599\n",
      "Progress 65.41384388807069\n",
      "Progress 65.5081001472754\n",
      "Progress 65.60235640648013\n",
      "Progress 65.69661266568482\n",
      "Progress 65.79086892488955\n",
      "Progress 65.88512518409425\n",
      "Progress 65.97938144329896\n",
      "Progress 66.07363770250369\n",
      "Progress 66.16789396170839\n",
      "Progress 66.26215022091311\n",
      "Progress 66.35640648011783\n",
      "Progress 66.45066273932252\n",
      "Progress 66.54491899852725\n",
      "Progress 66.63917525773196\n",
      "Progress 66.73343151693668\n",
      "Progress 66.82768777614139\n",
      "Progress 66.92194403534609\n",
      "Progress 67.01620029455081\n",
      "Progress 67.11045655375553\n",
      "Progress 67.20471281296024\n",
      "Progress 67.29896907216495\n",
      "Progress 67.39322533136966\n",
      "Progress 67.48748159057438\n",
      "Progress 67.58173784977909\n",
      "Progress 67.6759941089838\n",
      "Progress 67.77025036818851\n",
      "Progress 67.86450662739323\n",
      "Progress 67.95876288659794\n",
      "Progress 68.05301914580265\n",
      "Progress 68.14727540500736\n",
      "Progress 68.24153166421208\n",
      "Progress 68.33578792341679\n",
      "Progress 68.4300441826215\n",
      "Progress 68.52430044182621\n",
      "Progress 68.61855670103093\n",
      "Progress 68.71281296023564\n",
      "Progress 68.80706921944035\n",
      "Progress 68.90132547864508\n",
      "Progress 68.99558173784978\n",
      "Progress 69.08983799705449\n",
      "Progress 69.18409425625921\n",
      "Progress 69.27835051546391\n",
      "Progress 69.37260677466864\n",
      "Progress 69.46686303387334\n",
      "Progress 69.56111929307805\n",
      "Progress 69.65537555228278\n",
      "Progress 69.74963181148748\n",
      "Progress 69.8438880706922\n",
      "Progress 69.93814432989691\n",
      "Progress 70.03240058910161\n",
      "Progress 70.12665684830634\n",
      "Progress 70.22091310751104\n",
      "Progress 70.31516936671576\n",
      "Progress 70.40942562592048\n",
      "Progress 70.50368188512518\n",
      "Progress 70.5979381443299\n",
      "Progress 70.69219440353461\n",
      "Progress 70.78645066273933\n",
      "Progress 70.88070692194404\n",
      "Progress 70.97496318114875\n",
      "Progress 71.06921944035346\n",
      "Progress 71.16347569955818\n",
      "Progress 71.25773195876289\n",
      "Progress 71.3519882179676\n",
      "Progress 71.44624447717231\n",
      "Progress 71.54050073637703\n",
      "Progress 71.63475699558174\n",
      "Progress 71.72901325478645\n",
      "Progress 71.82326951399116\n",
      "Progress 71.91752577319588\n",
      "Progress 72.01178203240059\n",
      "Progress 72.1060382916053\n",
      "Progress 72.20029455081001\n",
      "Progress 72.29455081001473\n",
      "Progress 72.38880706921944\n",
      "Progress 72.48306332842415\n",
      "Progress 72.57731958762886\n",
      "Progress 72.67157584683358\n",
      "Progress 72.76583210603829\n",
      "Progress 72.860088365243\n",
      "Progress 72.95434462444771\n",
      "Progress 73.04860088365243\n",
      "Progress 73.14285714285714\n",
      "Progress 73.23711340206187\n",
      "Progress 73.33136966126656\n",
      "Progress 73.42562592047128\n",
      "Progress 73.519882179676\n",
      "Progress 73.6141384388807\n",
      "Progress 73.70839469808543\n",
      "Progress 73.80265095729013\n",
      "Progress 73.89690721649484\n",
      "Progress 73.99116347569957\n",
      "Progress 74.08541973490426\n",
      "Progress 74.17967599410899\n",
      "Progress 74.2739322533137\n",
      "Progress 74.3681885125184\n",
      "Progress 74.46244477172313\n",
      "Progress 74.55670103092783\n",
      "Progress 74.65095729013255\n",
      "Progress 74.74521354933727\n",
      "Progress 74.83946980854196\n",
      "Progress 74.93372606774669\n",
      "Progress 75.0279823269514\n",
      "Progress 75.12223858615612\n",
      "Progress 75.21649484536083\n",
      "Progress 75.31075110456553\n",
      "Progress 75.40500736377025\n",
      "Progress 75.49926362297496\n",
      "Progress 75.59351988217968\n",
      "Progress 75.68777614138439\n",
      "Progress 75.7820324005891\n",
      "Progress 75.87628865979381\n",
      "Progress 75.97054491899853\n",
      "Progress 76.06480117820324\n",
      "Progress 76.15905743740795\n",
      "Progress 76.25331369661266\n",
      "Progress 76.34756995581738\n",
      "Progress 76.44182621502209\n",
      "Progress 76.5360824742268\n",
      "Progress 76.63033873343151\n",
      "Progress 76.72459499263623\n",
      "Progress 76.81885125184095\n",
      "Progress 76.91310751104565\n",
      "Progress 77.00736377025036\n",
      "Progress 77.10162002945508\n",
      "Progress 77.19587628865979\n",
      "Progress 77.29013254786452\n",
      "Progress 77.38438880706921\n",
      "Progress 77.47864506627393\n",
      "Progress 77.57290132547865\n",
      "Progress 77.66715758468335\n",
      "Progress 77.76141384388808\n",
      "Progress 77.85567010309279\n",
      "Progress 77.94992636229749\n",
      "Progress 78.04418262150222\n",
      "Progress 78.13843888070691\n",
      "Progress 78.23269513991164\n",
      "Progress 78.32695139911635\n",
      "Progress 78.42120765832105\n",
      "Progress 78.51546391752578\n",
      "Progress 78.60972017673049\n",
      "Progress 78.7039764359352\n",
      "Progress 78.79823269513992\n",
      "Progress 78.89248895434461\n",
      "Progress 78.98674521354934\n",
      "Progress 79.08100147275405\n",
      "Progress 79.17525773195877\n",
      "Progress 79.26951399116348\n",
      "Progress 79.36377025036819\n",
      "Progress 79.4580265095729\n",
      "Progress 79.55228276877762\n",
      "Progress 79.64653902798233\n",
      "Progress 79.74079528718704\n",
      "Progress 79.83505154639175\n",
      "Progress 79.92930780559647\n",
      "Progress 80.02356406480118\n",
      "Progress 80.11782032400589\n",
      "Progress 80.2120765832106\n",
      "Progress 80.30633284241532\n",
      "Progress 80.40058910162003\n",
      "Progress 80.49484536082474\n",
      "Progress 80.58910162002945\n",
      "Progress 80.68335787923417\n",
      "Progress 80.77761413843888\n",
      "Progress 80.87187039764359\n",
      "Progress 80.9661266568483\n",
      "Progress 81.06038291605302\n",
      "Progress 81.15463917525774\n",
      "Progress 81.24889543446244\n",
      "Progress 81.34315169366715\n",
      "Progress 81.43740795287187\n",
      "Progress 81.53166421207658\n",
      "Progress 81.6259204712813\n",
      "Progress 81.720176730486\n",
      "Progress 81.81443298969072\n",
      "Progress 81.90868924889544\n",
      "Progress 82.00294550810014\n",
      "Progress 82.09720176730487\n",
      "Progress 82.19145802650958\n",
      "Progress 82.28571428571428\n",
      "Progress 82.379970544919\n",
      "Progress 82.4742268041237\n",
      "Progress 82.56848306332843\n",
      "Progress 82.66273932253314\n",
      "Progress 82.75699558173784\n",
      "Progress 82.85125184094257\n",
      "Progress 82.94550810014728\n",
      "Progress 83.03976435935199\n",
      "Progress 83.1340206185567\n",
      "Progress 83.2282768777614\n",
      "Progress 83.32253313696613\n",
      "Progress 83.41678939617084\n",
      "Progress 83.51104565537555\n",
      "Progress 83.60530191458027\n",
      "Progress 83.69955817378498\n",
      "Progress 83.79381443298969\n",
      "Progress 83.8880706921944\n",
      "Progress 83.98232695139912\n",
      "Progress 84.07658321060383\n",
      "Progress 84.17083946980854\n",
      "Progress 84.26509572901325\n",
      "Progress 84.35935198821797\n",
      "Progress 84.45360824742268\n",
      "Progress 84.54786450662739\n",
      "Progress 84.6421207658321\n",
      "Progress 84.73637702503683\n",
      "Progress 84.83063328424153\n",
      "Progress 84.92488954344624\n",
      "Progress 85.01914580265095\n",
      "Progress 85.11340206185567\n",
      "Progress 85.20765832106039\n",
      "Progress 85.30191458026509\n",
      "Progress 85.3961708394698\n",
      "Progress 85.49042709867453\n",
      "Progress 85.58468335787923\n",
      "Progress 85.67893961708396\n",
      "Progress 85.77319587628865\n",
      "Progress 85.86745213549337\n",
      "Progress 85.96170839469809\n",
      "Progress 86.05596465390279\n",
      "Progress 86.15022091310752\n",
      "Progress 86.24447717231223\n",
      "Progress 86.33873343151693\n",
      "Progress 86.43298969072166\n",
      "Progress 86.52724594992635\n",
      "Progress 86.62150220913108\n",
      "Progress 86.71575846833579\n",
      "Progress 86.81001472754049\n",
      "Progress 86.90427098674522\n",
      "Progress 86.99852724594993\n",
      "Progress 87.09278350515464\n",
      "Progress 87.18703976435935\n",
      "Progress 87.28129602356407\n",
      "Progress 87.37555228276878\n",
      "Progress 87.46980854197349\n",
      "Progress 87.5640648011782\n",
      "Progress 87.65832106038292\n",
      "Progress 87.75257731958763\n",
      "Progress 87.84683357879234\n",
      "Progress 87.94108983799705\n",
      "Progress 88.03534609720177\n",
      "Progress 88.12960235640648\n",
      "Progress 88.22385861561119\n",
      "Progress 88.3181148748159\n",
      "Progress 88.41237113402062\n",
      "Progress 88.50662739322533\n",
      "Progress 88.60088365243004\n",
      "Progress 88.69513991163475\n",
      "Progress 88.78939617083947\n",
      "Progress 88.88365243004418\n",
      "Progress 88.97790868924889\n",
      "Progress 89.07216494845362\n",
      "Progress 89.16642120765832\n",
      "Progress 89.26067746686303\n",
      "Progress 89.35493372606774\n",
      "Progress 89.44918998527245\n",
      "Progress 89.54344624447718\n",
      "Progress 89.63770250368188\n",
      "Progress 89.73195876288659\n",
      "Progress 89.82621502209132\n",
      "Progress 89.92047128129602\n",
      "Progress 90.01472754050074\n",
      "Progress 90.10898379970544\n",
      "Progress 90.20324005891015\n",
      "Progress 90.29749631811488\n",
      "Progress 90.39175257731958\n",
      "Progress 90.4860088365243\n",
      "Progress 90.58026509572902\n",
      "Progress 90.67452135493372\n",
      "Progress 90.76877761413844\n",
      "Progress 90.86303387334314\n",
      "Progress 90.95729013254787\n",
      "Progress 91.05154639175258\n",
      "Progress 91.14580265095728\n",
      "Progress 91.240058910162\n",
      "Progress 91.33431516936672\n",
      "Progress 91.42857142857143\n",
      "Progress 91.52282768777614\n",
      "Progress 91.61708394698086\n",
      "Progress 91.71134020618557\n",
      "Progress 91.80559646539028\n",
      "Progress 91.899852724595\n",
      "Progress 91.9941089837997\n",
      "Progress 92.08836524300442\n",
      "Progress 92.18262150220913\n",
      "Progress 92.27687776141384\n",
      "Progress 92.37113402061856\n",
      "Progress 92.46539027982327\n",
      "Progress 92.55964653902798\n",
      "Progress 92.65390279823269\n",
      "Progress 92.7481590574374\n",
      "Progress 92.84241531664212\n",
      "Progress 92.93667157584683\n",
      "Progress 93.03092783505154\n",
      "Progress 93.12518409425627\n",
      "Progress 93.21944035346097\n",
      "Progress 93.31369661266568\n",
      "Progress 93.40795287187039\n",
      "Progress 93.5022091310751\n",
      "Progress 93.59646539027983\n",
      "Progress 93.69072164948453\n",
      "Progress 93.78497790868924\n",
      "Progress 93.87923416789397\n",
      "Progress 93.97349042709867\n",
      "Progress 94.0677466863034\n",
      "Progress 94.1620029455081\n",
      "Progress 94.2562592047128\n",
      "Progress 94.35051546391753\n",
      "Progress 94.44477172312223\n",
      "Progress 94.53902798232696\n",
      "Progress 94.63328424153167\n",
      "Progress 94.72754050073637\n",
      "Progress 94.8217967599411\n",
      "Progress 94.9160530191458\n",
      "Progress 95.01030927835052\n",
      "Progress 95.10456553755523\n",
      "Progress 95.19882179675993\n",
      "Progress 95.29307805596466\n",
      "Progress 95.38733431516937\n",
      "Progress 95.48159057437408\n",
      "Progress 95.5758468335788\n",
      "Progress 95.6701030927835\n",
      "Progress 95.76435935198822\n",
      "Progress 95.85861561119293\n",
      "Progress 95.95287187039764\n",
      "Progress 96.04712812960236\n",
      "Progress 96.14138438880707\n",
      "Progress 96.23564064801178\n",
      "Progress 96.3298969072165\n",
      "Progress 96.4241531664212\n",
      "Progress 96.51840942562592\n",
      "Progress 96.61266568483063\n",
      "Progress 96.70692194403536\n",
      "Progress 96.80117820324006\n",
      "Progress 96.89543446244477\n",
      "Progress 96.98969072164948\n",
      "Progress 97.0839469808542\n",
      "Progress 97.17820324005892\n",
      "Progress 97.27245949926362\n",
      "Progress 97.36671575846833\n",
      "Progress 97.46097201767306\n",
      "Progress 97.55522827687776\n",
      "Progress 97.64948453608248\n",
      "Progress 97.74374079528718\n",
      "Progress 97.8379970544919\n",
      "Progress 97.93225331369662\n",
      "Progress 98.02650957290132\n",
      "Progress 98.12076583210604\n",
      "Progress 98.21502209131076\n",
      "Progress 98.30927835051546\n",
      "Progress 98.40353460972018\n",
      "Progress 98.4977908689249\n",
      "Progress 98.59204712812961\n",
      "Progress 98.68630338733432\n",
      "Progress 98.78055964653902\n",
      "Progress 98.87481590574374\n",
      "Progress 98.96907216494846\n",
      "Progress 99.06332842415317\n",
      "Progress 99.15758468335788\n",
      "Progress 99.2518409425626\n",
      "Progress 99.34609720176731\n",
      "Progress 99.44035346097202\n",
      "Progress 99.53460972017673\n",
      "Progress 99.62886597938144\n",
      "Progress 99.72312223858616\n",
      "Progress 99.81737849779087\n",
      "Progress 99.91163475699558\n",
      "Progress 0.0\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.7540500736377025\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.508100147275405\n",
      "Progress 1.8851251840942562\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.6391752577319587\n",
      "Progress 3.01620029455081\n",
      "Progress 3.393225331369661\n",
      "Progress 3.7702503681885124\n",
      "Progress 4.147275405007364\n",
      "Progress 4.524300441826215\n",
      "Progress 4.901325478645066\n",
      "Progress 5.278350515463917\n",
      "Progress 5.655375552282769\n",
      "Progress 6.03240058910162\n",
      "Progress 6.409425625920472\n",
      "Progress 6.786450662739322\n",
      "Progress 7.163475699558173\n",
      "Progress 7.540500736377025\n",
      "Progress 7.917525773195876\n",
      "Progress 8.294550810014728\n",
      "Progress 8.67157584683358\n",
      "Progress 9.04860088365243\n",
      "Progress 9.425625920471282\n",
      "Progress 9.802650957290131\n",
      "Progress 10.179675994108983\n",
      "Progress 10.556701030927835\n",
      "Progress 10.933726067746687\n",
      "Progress 11.310751104565538\n",
      "Progress 11.687776141384388\n",
      "Progress 12.06480117820324\n",
      "Progress 12.441826215022092\n",
      "Progress 12.818851251840943\n",
      "Progress 13.195876288659795\n",
      "Progress 13.572901325478645\n",
      "Progress 13.949926362297496\n",
      "Progress 14.326951399116346\n",
      "Progress 14.703976435935198\n",
      "Progress 15.08100147275405\n",
      "Progress 15.4580265095729\n",
      "Progress 15.835051546391751\n",
      "Progress 16.212076583210607\n",
      "Progress 16.589101620029457\n",
      "Progress 16.966126656848306\n",
      "Progress 17.34315169366716\n",
      "Progress 17.72017673048601\n",
      "Progress 18.09720176730486\n",
      "Progress 18.47422680412371\n",
      "Progress 18.851251840942563\n",
      "Progress 19.228276877761413\n",
      "Progress 19.605301914580263\n",
      "Progress 19.982326951399116\n",
      "Progress 20.359351988217966\n",
      "Progress 20.73637702503682\n",
      "Progress 21.11340206185567\n",
      "Progress 21.490427098674523\n",
      "Progress 21.867452135493373\n",
      "Progress 22.244477172312223\n",
      "Progress 22.621502209131076\n",
      "Progress 22.998527245949926\n",
      "Progress 23.375552282768776\n",
      "Progress 23.75257731958763\n",
      "Progress 24.12960235640648\n",
      "Progress 24.50662739322533\n",
      "Progress 24.883652430044183\n",
      "Progress 25.260677466863036\n",
      "Progress 25.637702503681886\n",
      "Progress 26.014727540500736\n",
      "Progress 26.39175257731959\n",
      "Progress 26.76877761413844\n",
      "Progress 27.14580265095729\n",
      "Progress 27.522827687776143\n",
      "Progress 27.899852724594993\n",
      "Progress 28.276877761413843\n",
      "Progress 28.653902798232693\n",
      "Progress 29.030927835051546\n",
      "Progress 29.407952871870396\n",
      "Progress 29.784977908689246\n",
      "Progress 30.1620029455081\n",
      "Progress 30.53902798232695\n",
      "Progress 30.9160530191458\n",
      "Progress 31.293078055964653\n",
      "Progress 31.670103092783503\n",
      "Progress 32.047128129602356\n",
      "Progress 32.42415316642121\n",
      "Progress 32.80117820324006\n",
      "Progress 33.17820324005891\n",
      "Progress 33.55522827687776\n",
      "Progress 33.93225331369661\n",
      "Progress 34.30927835051546\n",
      "Progress 34.68630338733432\n",
      "Progress 35.06332842415317\n",
      "Progress 35.44035346097202\n",
      "Progress 35.81737849779087\n",
      "Progress 36.19440353460972\n",
      "Progress 36.57142857142857\n",
      "Progress 36.94845360824742\n",
      "Progress 37.325478645066276\n",
      "Progress 37.702503681885126\n",
      "Progress 38.079528718703976\n",
      "Progress 38.456553755522826\n",
      "Progress 38.833578792341676\n",
      "Progress 39.210603829160526\n",
      "Progress 39.58762886597938\n",
      "Progress 39.96465390279823\n",
      "Progress 40.34167893961708\n",
      "Progress 40.71870397643593\n",
      "Progress 41.09572901325479\n",
      "Progress 41.47275405007364\n",
      "Progress 41.84977908689249\n",
      "Progress 42.22680412371134\n",
      "Progress 42.603829160530196\n",
      "Progress 42.980854197349046\n",
      "Progress 43.357879234167896\n",
      "Progress 43.734904270986746\n",
      "Progress 44.111929307805596\n",
      "Progress 44.488954344624446\n",
      "Progress 44.865979381443296\n",
      "Progress 45.24300441826215\n",
      "Progress 45.620029455081\n",
      "Progress 45.99705449189985\n",
      "Progress 46.3740795287187\n",
      "Progress 46.75110456553755\n",
      "Progress 47.1281296023564\n",
      "Progress 47.50515463917526\n",
      "Progress 47.88217967599411\n",
      "Progress 48.25920471281296\n",
      "Progress 48.63622974963181\n",
      "Progress 49.01325478645066\n",
      "Progress 49.39027982326951\n",
      "Progress 49.767304860088366\n",
      "Progress 50.144329896907216\n",
      "Progress 50.52135493372607\n",
      "Progress 50.898379970544916\n",
      "Progress 51.27540500736377\n",
      "Progress 51.652430044182616\n",
      "Progress 52.02945508100147\n",
      "Progress 52.40648011782032\n",
      "Progress 52.78350515463918\n",
      "Progress 53.16053019145802\n",
      "Progress 53.53755522827688\n",
      "Progress 53.91458026509572\n",
      "Progress 54.29160530191458\n",
      "Progress 54.66863033873343\n",
      "Progress 55.045655375552286\n",
      "Progress 55.422680412371136\n",
      "Progress 55.799705449189986\n",
      "Progress 56.17673048600884\n",
      "Progress 56.553755522827686\n",
      "Progress 56.93078055964654\n",
      "Progress 57.307805596465386\n",
      "Progress 57.68483063328424\n",
      "Progress 58.06185567010309\n",
      "Progress 58.43888070692195\n",
      "Progress 58.81590574374079\n",
      "Progress 59.19293078055965\n",
      "Progress 59.56995581737849\n",
      "Progress 59.94698085419735\n",
      "Progress 60.3240058910162\n",
      "Progress 60.701030927835056\n",
      "Progress 61.0780559646539\n",
      "Progress 61.455081001472756\n",
      "Progress 61.8321060382916\n",
      "Progress 62.209131075110456\n",
      "Progress 62.586156111929306\n",
      "Progress 62.96318114874816\n",
      "Progress 63.340206185567006\n",
      "Progress 63.71723122238586\n",
      "Progress 64.09425625920471\n",
      "Progress 64.47128129602356\n",
      "Progress 64.84830633284243\n",
      "Progress 65.22533136966126\n",
      "Progress 65.60235640648013\n",
      "Progress 65.97938144329896\n",
      "Progress 66.35640648011783\n",
      "Progress 66.73343151693668\n",
      "Progress 67.11045655375553\n",
      "Progress 67.48748159057438\n",
      "Progress 67.86450662739323\n",
      "Progress 68.24153166421208\n",
      "Progress 68.61855670103093\n",
      "Progress 68.99558173784978\n",
      "Progress 69.37260677466864\n",
      "Progress 69.74963181148748\n",
      "Progress 70.12665684830634\n",
      "Progress 70.50368188512518\n",
      "Progress 70.88070692194404\n",
      "Progress 71.25773195876289\n",
      "Progress 71.63475699558174\n",
      "Progress 72.01178203240059\n",
      "Progress 72.38880706921944\n",
      "Progress 72.76583210603829\n",
      "Progress 73.14285714285714\n",
      "Progress 73.519882179676\n",
      "Progress 73.89690721649484\n",
      "Progress 74.2739322533137\n",
      "Progress 74.65095729013255\n",
      "Progress 75.0279823269514\n",
      "Progress 75.40500736377025\n",
      "Progress 75.7820324005891\n",
      "Progress 76.15905743740795\n",
      "Progress 76.5360824742268\n",
      "Progress 76.91310751104565\n",
      "Progress 77.29013254786452\n",
      "Progress 77.66715758468335\n",
      "Progress 78.04418262150222\n",
      "Progress 78.42120765832105\n",
      "Progress 78.79823269513992\n",
      "Progress 79.17525773195877\n",
      "Progress 79.55228276877762\n",
      "Progress 79.92930780559647\n",
      "Progress 80.30633284241532\n",
      "Progress 80.68335787923417\n",
      "Progress 81.06038291605302\n",
      "Progress 81.43740795287187\n",
      "Progress 81.81443298969072\n",
      "Progress 82.19145802650958\n",
      "Progress 82.56848306332843\n",
      "Progress 82.94550810014728\n",
      "Progress 83.32253313696613\n",
      "Progress 83.69955817378498\n",
      "Progress 84.07658321060383\n",
      "Progress 84.45360824742268\n",
      "Progress 84.83063328424153\n",
      "Progress 85.20765832106039\n",
      "Progress 85.58468335787923\n",
      "Progress 85.96170839469809\n",
      "Progress 86.33873343151693\n",
      "Progress 86.71575846833579\n",
      "Progress 87.09278350515464\n",
      "Progress 87.46980854197349\n",
      "Progress 87.84683357879234\n",
      "Progress 88.22385861561119\n",
      "Progress 88.60088365243004\n",
      "Progress 88.97790868924889\n",
      "Progress 89.35493372606774\n",
      "Progress 89.73195876288659\n",
      "Progress 90.10898379970544\n",
      "Progress 90.4860088365243\n",
      "Progress 90.86303387334314\n",
      "Progress 91.240058910162\n",
      "Progress 91.61708394698086\n",
      "Progress 91.9941089837997\n",
      "Progress 92.37113402061856\n",
      "Progress 92.7481590574374\n",
      "Progress 93.12518409425627\n",
      "Progress 93.5022091310751\n",
      "Progress 93.87923416789397\n",
      "Progress 94.2562592047128\n",
      "Progress 94.63328424153167\n",
      "Progress 95.01030927835052\n",
      "Progress 95.38733431516937\n",
      "Progress 95.76435935198822\n",
      "Progress 96.14138438880707\n",
      "Progress 96.51840942562592\n",
      "Progress 96.89543446244477\n",
      "Progress 97.27245949926362\n",
      "Progress 97.64948453608248\n",
      "Progress 98.02650957290132\n",
      "Progress 98.40353460972018\n",
      "Progress 98.78055964653902\n",
      "Progress 99.15758468335788\n",
      "Progress 99.53460972017673\n",
      "Progress 99.91163475699558\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49184e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48775e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50802e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48367e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.4883e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.1601421  0.16014139        nan        nan\n",
      " 0.20269508 0.20264671        nan        nan 0.20831677        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:18:12, 1167.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Progress 0.0\n",
      "Progress 0.09425625920471281\n",
      "Progress 0.18851251840942562\n",
      "Progress 0.28276877761413843\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.47128129602356406\n",
      "Progress 0.5655375552282769\n",
      "Progress 0.6597938144329897\n",
      "Progress 0.7540500736377025\n",
      "Progress 0.8483063328424153\n",
      "Progress 0.9425625920471281\n",
      "Progress 1.036818851251841\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.2253313696612664\n",
      "Progress 1.3195876288659794\n",
      "Progress 1.4138438880706923\n",
      "Progress 1.508100147275405\n",
      "Progress 1.602356406480118\n",
      "Progress 1.6966126656848306\n",
      "Progress 1.7908689248895433\n",
      "Progress 1.8851251840942562\n",
      "Progress 1.979381443298969\n",
      "Progress 2.073637702503682\n",
      "Progress 2.167893961708395\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.3564064801178204\n",
      "Progress 2.450662739322533\n",
      "Progress 2.544918998527246\n",
      "Progress 2.6391752577319587\n",
      "Progress 2.7334315169366716\n",
      "Progress 2.8276877761413846\n",
      "Progress 2.921944035346097\n",
      "Progress 3.01620029455081\n",
      "Progress 3.110456553755523\n",
      "Progress 3.204712812960236\n",
      "Progress 3.2989690721649487\n",
      "Progress 3.393225331369661\n",
      "Progress 3.487481590574374\n",
      "Progress 3.5817378497790866\n",
      "Progress 3.6759941089837995\n",
      "Progress 3.7702503681885124\n",
      "Progress 3.864506627393225\n",
      "Progress 3.958762886597938\n",
      "Progress 4.053019145802652\n",
      "Progress 4.147275405007364\n",
      "Progress 4.241531664212077\n",
      "Progress 4.33578792341679\n",
      "Progress 4.4300441826215025\n",
      "Progress 4.524300441826215\n",
      "Progress 4.618556701030927\n",
      "Progress 4.712812960235641\n",
      "Progress 4.807069219440353\n",
      "Progress 4.901325478645066\n",
      "Progress 4.995581737849779\n",
      "Progress 5.089837997054492\n",
      "Progress 5.184094256259205\n",
      "Progress 5.278350515463917\n",
      "Progress 5.372606774668631\n",
      "Progress 5.466863033873343\n",
      "Progress 5.561119293078056\n",
      "Progress 5.655375552282769\n",
      "Progress 5.749631811487482\n",
      "Progress 5.843888070692194\n",
      "Progress 5.938144329896907\n",
      "Progress 6.03240058910162\n",
      "Progress 6.126656848306332\n",
      "Progress 6.220913107511046\n",
      "Progress 6.315169366715759\n",
      "Progress 6.409425625920472\n",
      "Progress 6.503681885125184\n",
      "Progress 6.5979381443298974\n",
      "Progress 6.69219440353461\n",
      "Progress 6.786450662739322\n",
      "Progress 6.880706921944036\n",
      "Progress 6.974963181148748\n",
      "Progress 7.069219440353461\n",
      "Progress 7.163475699558173\n",
      "Progress 7.257731958762887\n",
      "Progress 7.351988217967599\n",
      "Progress 7.4462444771723115\n",
      "Progress 7.540500736377025\n",
      "Progress 7.634756995581737\n",
      "Progress 7.72901325478645\n",
      "Progress 7.823269513991163\n",
      "Progress 7.917525773195876\n",
      "Progress 8.011782032400589\n",
      "Progress 8.106038291605303\n",
      "Progress 8.200294550810016\n",
      "Progress 8.294550810014728\n",
      "Progress 8.38880706921944\n",
      "Progress 8.483063328424153\n",
      "Progress 8.577319587628866\n",
      "Progress 8.67157584683358\n",
      "Progress 8.765832106038292\n",
      "Progress 8.860088365243005\n",
      "Progress 8.954344624447717\n",
      "Progress 9.04860088365243\n",
      "Progress 9.142857142857142\n",
      "Progress 9.237113402061855\n",
      "Progress 9.331369661266569\n",
      "Progress 9.425625920471282\n",
      "Progress 9.519882179675994\n",
      "Progress 9.614138438880707\n",
      "Progress 9.708394698085419\n",
      "Progress 9.802650957290131\n",
      "Progress 9.896907216494846\n",
      "Progress 9.991163475699558\n",
      "Progress 10.08541973490427\n",
      "Progress 10.179675994108983\n",
      "Progress 10.273932253313697\n",
      "Progress 10.36818851251841\n",
      "Progress 10.462444771723122\n",
      "Progress 10.556701030927835\n",
      "Progress 10.650957290132549\n",
      "Progress 10.745213549337262\n",
      "Progress 10.839469808541974\n",
      "Progress 10.933726067746687\n",
      "Progress 11.027982326951399\n",
      "Progress 11.122238586156111\n",
      "Progress 11.216494845360824\n",
      "Progress 11.310751104565538\n",
      "Progress 11.40500736377025\n",
      "Progress 11.499263622974963\n",
      "Progress 11.593519882179676\n",
      "Progress 11.687776141384388\n",
      "Progress 11.7820324005891\n",
      "Progress 11.876288659793815\n",
      "Progress 11.970544918998527\n",
      "Progress 12.06480117820324\n",
      "Progress 12.159057437407952\n",
      "Progress 12.253313696612665\n",
      "Progress 12.347569955817377\n",
      "Progress 12.441826215022092\n",
      "Progress 12.536082474226804\n",
      "Progress 12.630338733431518\n",
      "Progress 12.724594992636229\n",
      "Progress 12.818851251840943\n",
      "Progress 12.913107511045654\n",
      "Progress 13.007363770250368\n",
      "Progress 13.10162002945508\n",
      "Progress 13.195876288659795\n",
      "Progress 13.290132547864506\n",
      "Progress 13.38438880706922\n",
      "Progress 13.47864506627393\n",
      "Progress 13.572901325478645\n",
      "Progress 13.667157584683357\n",
      "Progress 13.761413843888072\n",
      "Progress 13.855670103092784\n",
      "Progress 13.949926362297496\n",
      "Progress 14.04418262150221\n",
      "Progress 14.138438880706921\n",
      "Progress 14.232695139911636\n",
      "Progress 14.326951399116346\n",
      "Progress 14.42120765832106\n",
      "Progress 14.515463917525773\n",
      "Progress 14.609720176730487\n",
      "Progress 14.703976435935198\n",
      "Progress 14.798232695139912\n",
      "Progress 14.892488954344623\n",
      "Progress 14.986745213549337\n",
      "Progress 15.08100147275405\n",
      "Progress 15.175257731958764\n",
      "Progress 15.269513991163475\n",
      "Progress 15.363770250368189\n",
      "Progress 15.4580265095729\n",
      "Progress 15.552282768777614\n",
      "Progress 15.646539027982326\n",
      "Progress 15.74079528718704\n",
      "Progress 15.835051546391751\n",
      "Progress 15.929307805596466\n",
      "Progress 16.023564064801178\n",
      "Progress 16.11782032400589\n",
      "Progress 16.212076583210607\n",
      "Progress 16.306332842415316\n",
      "Progress 16.40058910162003\n",
      "Progress 16.49484536082474\n",
      "Progress 16.589101620029457\n",
      "Progress 16.68335787923417\n",
      "Progress 16.77761413843888\n",
      "Progress 16.871870397643594\n",
      "Progress 16.966126656848306\n",
      "Progress 17.06038291605302\n",
      "Progress 17.15463917525773\n",
      "Progress 17.248895434462444\n",
      "Progress 17.34315169366716\n",
      "Progress 17.43740795287187\n",
      "Progress 17.531664212076585\n",
      "Progress 17.625920471281294\n",
      "Progress 17.72017673048601\n",
      "Progress 17.814432989690722\n",
      "Progress 17.908689248895435\n",
      "Progress 18.002945508100147\n",
      "Progress 18.09720176730486\n",
      "Progress 18.191458026509572\n",
      "Progress 18.285714285714285\n",
      "Progress 18.379970544919\n",
      "Progress 18.47422680412371\n",
      "Progress 18.568483063328426\n",
      "Progress 18.662739322533138\n",
      "Progress 18.75699558173785\n",
      "Progress 18.851251840942563\n",
      "Progress 18.945508100147276\n",
      "Progress 19.039764359351988\n",
      "Progress 19.1340206185567\n",
      "Progress 19.228276877761413\n",
      "Progress 19.32253313696613\n",
      "Progress 19.416789396170838\n",
      "Progress 19.511045655375554\n",
      "Progress 19.605301914580263\n",
      "Progress 19.69955817378498\n",
      "Progress 19.79381443298969\n",
      "Progress 19.888070692194404\n",
      "Progress 19.982326951399116\n",
      "Progress 20.07658321060383\n",
      "Progress 20.17083946980854\n",
      "Progress 20.265095729013254\n",
      "Progress 20.359351988217966\n",
      "Progress 20.45360824742268\n",
      "Progress 20.547864506627395\n",
      "Progress 20.642120765832107\n",
      "Progress 20.73637702503682\n",
      "Progress 20.830633284241532\n",
      "Progress 20.924889543446245\n",
      "Progress 21.019145802650957\n",
      "Progress 21.11340206185567\n",
      "Progress 21.207658321060382\n",
      "Progress 21.301914580265098\n",
      "Progress 21.396170839469807\n",
      "Progress 21.490427098674523\n",
      "Progress 21.584683357879232\n",
      "Progress 21.678939617083948\n",
      "Progress 21.77319587628866\n",
      "Progress 21.867452135493373\n",
      "Progress 21.961708394698086\n",
      "Progress 22.055964653902798\n",
      "Progress 22.15022091310751\n",
      "Progress 22.244477172312223\n",
      "Progress 22.338733431516935\n",
      "Progress 22.432989690721648\n",
      "Progress 22.52724594992636\n",
      "Progress 22.621502209131076\n",
      "Progress 22.715758468335785\n",
      "Progress 22.8100147275405\n",
      "Progress 22.904270986745214\n",
      "Progress 22.998527245949926\n",
      "Progress 23.09278350515464\n",
      "Progress 23.18703976435935\n",
      "Progress 23.281296023564067\n",
      "Progress 23.375552282768776\n",
      "Progress 23.469808541973492\n",
      "Progress 23.5640648011782\n",
      "Progress 23.658321060382917\n",
      "Progress 23.75257731958763\n",
      "Progress 23.846833578792342\n",
      "Progress 23.941089837997055\n",
      "Progress 24.035346097201767\n",
      "Progress 24.12960235640648\n",
      "Progress 24.223858615611192\n",
      "Progress 24.318114874815905\n",
      "Progress 24.41237113402062\n",
      "Progress 24.50662739322533\n",
      "Progress 24.600883652430046\n",
      "Progress 24.695139911634755\n",
      "Progress 24.78939617083947\n",
      "Progress 24.883652430044183\n",
      "Progress 24.977908689248896\n",
      "Progress 25.072164948453608\n",
      "Progress 25.166421207658324\n",
      "Progress 25.260677466863036\n",
      "Progress 25.354933726067745\n",
      "Progress 25.449189985272458\n",
      "Progress 25.543446244477174\n",
      "Progress 25.637702503681886\n",
      "Progress 25.7319587628866\n",
      "Progress 25.826215022091308\n",
      "Progress 25.920471281296027\n",
      "Progress 26.014727540500736\n",
      "Progress 26.10898379970545\n",
      "Progress 26.20324005891016\n",
      "Progress 26.297496318114877\n",
      "Progress 26.39175257731959\n",
      "Progress 26.4860088365243\n",
      "Progress 26.58026509572901\n",
      "Progress 26.674521354933727\n",
      "Progress 26.76877761413844\n",
      "Progress 26.863033873343152\n",
      "Progress 26.95729013254786\n",
      "Progress 27.05154639175258\n",
      "Progress 27.14580265095729\n",
      "Progress 27.240058910162002\n",
      "Progress 27.334315169366715\n",
      "Progress 27.42857142857143\n",
      "Progress 27.522827687776143\n",
      "Progress 27.617083946980852\n",
      "Progress 27.711340206185568\n",
      "Progress 27.80559646539028\n",
      "Progress 27.899852724594993\n",
      "Progress 27.994108983799705\n",
      "Progress 28.08836524300442\n",
      "Progress 28.18262150220913\n",
      "Progress 28.276877761413843\n",
      "Progress 28.371134020618555\n",
      "Progress 28.46539027982327\n",
      "Progress 28.559646539027984\n",
      "Progress 28.653902798232693\n",
      "Progress 28.748159057437405\n",
      "Progress 28.84241531664212\n",
      "Progress 28.936671575846834\n",
      "Progress 29.030927835051546\n",
      "Progress 29.125184094256255\n",
      "Progress 29.219440353460975\n",
      "Progress 29.313696612665684\n",
      "Progress 29.407952871870396\n",
      "Progress 29.50220913107511\n",
      "Progress 29.596465390279825\n",
      "Progress 29.690721649484537\n",
      "Progress 29.784977908689246\n",
      "Progress 29.879234167893966\n",
      "Progress 29.973490427098675\n",
      "Progress 30.067746686303387\n",
      "Progress 30.1620029455081\n",
      "Progress 30.256259204712816\n",
      "Progress 30.350515463917528\n",
      "Progress 30.444771723122237\n",
      "Progress 30.53902798232695\n",
      "Progress 30.633284241531666\n",
      "Progress 30.727540500736378\n",
      "Progress 30.82179675994109\n",
      "Progress 30.9160530191458\n",
      "Progress 31.01030927835052\n",
      "Progress 31.104565537555228\n",
      "Progress 31.19882179675994\n",
      "Progress 31.293078055964653\n",
      "Progress 31.38733431516937\n",
      "Progress 31.48159057437408\n",
      "Progress 31.57584683357879\n",
      "Progress 31.670103092783503\n",
      "Progress 31.76435935198822\n",
      "Progress 31.85861561119293\n",
      "Progress 31.952871870397644\n",
      "Progress 32.047128129602356\n",
      "Progress 32.14138438880707\n",
      "Progress 32.23564064801178\n",
      "Progress 32.329896907216494\n",
      "Progress 32.42415316642121\n",
      "Progress 32.51840942562592\n",
      "Progress 32.61266568483063\n",
      "Progress 32.706921944035344\n",
      "Progress 32.80117820324006\n",
      "Progress 32.895434462444776\n",
      "Progress 32.98969072164948\n",
      "Progress 33.08394698085419\n",
      "Progress 33.17820324005891\n",
      "Progress 33.272459499263626\n",
      "Progress 33.36671575846834\n",
      "Progress 33.46097201767304\n",
      "Progress 33.55522827687776\n",
      "Progress 33.649484536082475\n",
      "Progress 33.74374079528719\n",
      "Progress 33.8379970544919\n",
      "Progress 33.93225331369661\n",
      "Progress 34.026509572901325\n",
      "Progress 34.12076583210604\n",
      "Progress 34.21502209131075\n",
      "Progress 34.30927835051546\n",
      "Progress 34.403534609720175\n",
      "Progress 34.49779086892489\n",
      "Progress 34.59204712812961\n",
      "Progress 34.68630338733432\n",
      "Progress 34.780559646539025\n",
      "Progress 34.87481590574374\n",
      "Progress 34.96907216494846\n",
      "Progress 35.06332842415317\n",
      "Progress 35.15758468335788\n",
      "Progress 35.25184094256259\n",
      "Progress 35.34609720176731\n",
      "Progress 35.44035346097202\n",
      "Progress 35.53460972017673\n",
      "Progress 35.628865979381445\n",
      "Progress 35.72312223858616\n",
      "Progress 35.81737849779087\n",
      "Progress 35.91163475699558\n",
      "Progress 36.005891016200295\n",
      "Progress 36.10014727540501\n",
      "Progress 36.19440353460972\n",
      "Progress 36.28865979381443\n",
      "Progress 36.382916053019144\n",
      "Progress 36.47717231222386\n",
      "Progress 36.57142857142857\n",
      "Progress 36.66568483063328\n",
      "Progress 36.759941089838\n",
      "Progress 36.854197349042714\n",
      "Progress 36.94845360824742\n",
      "Progress 37.04270986745213\n",
      "Progress 37.13696612665685\n",
      "Progress 37.231222385861564\n",
      "Progress 37.325478645066276\n",
      "Progress 37.41973490427098\n",
      "Progress 37.5139911634757\n",
      "Progress 37.608247422680414\n",
      "Progress 37.702503681885126\n",
      "Progress 37.79675994108984\n",
      "Progress 37.89101620029455\n",
      "Progress 37.985272459499264\n",
      "Progress 38.079528718703976\n",
      "Progress 38.17378497790869\n",
      "Progress 38.2680412371134\n",
      "Progress 38.362297496318114\n",
      "Progress 38.456553755522826\n",
      "Progress 38.55081001472754\n",
      "Progress 38.64506627393226\n",
      "Progress 38.73932253313696\n",
      "Progress 38.833578792341676\n",
      "Progress 38.927835051546396\n",
      "Progress 39.02209131075111\n",
      "Progress 39.11634756995582\n",
      "Progress 39.210603829160526\n",
      "Progress 39.304860088365245\n",
      "Progress 39.39911634756996\n",
      "Progress 39.49337260677467\n",
      "Progress 39.58762886597938\n",
      "Progress 39.681885125184095\n",
      "Progress 39.77614138438881\n",
      "Progress 39.87039764359352\n",
      "Progress 39.96465390279823\n",
      "Progress 40.058910162002945\n",
      "Progress 40.15316642120766\n",
      "Progress 40.24742268041237\n",
      "Progress 40.34167893961708\n",
      "Progress 40.435935198821795\n",
      "Progress 40.53019145802651\n",
      "Progress 40.62444771723122\n",
      "Progress 40.71870397643593\n",
      "Progress 40.81296023564065\n",
      "Progress 40.90721649484536\n",
      "Progress 41.00147275405007\n",
      "Progress 41.09572901325479\n",
      "Progress 41.1899852724595\n",
      "Progress 41.284241531664215\n",
      "Progress 41.37849779086892\n",
      "Progress 41.47275405007364\n",
      "Progress 41.56701030927835\n",
      "Progress 41.661266568483065\n",
      "Progress 41.75552282768778\n",
      "Progress 41.84977908689249\n",
      "Progress 41.9440353460972\n",
      "Progress 42.038291605301914\n",
      "Progress 42.13254786450663\n",
      "Progress 42.22680412371134\n",
      "Progress 42.32106038291605\n",
      "Progress 42.415316642120764\n",
      "Progress 42.50957290132548\n",
      "Progress 42.603829160530196\n",
      "Progress 42.6980854197349\n",
      "Progress 42.792341678939614\n",
      "Progress 42.88659793814433\n",
      "Progress 42.980854197349046\n",
      "Progress 43.07511045655376\n",
      "Progress 43.169366715758464\n",
      "Progress 43.26362297496318\n",
      "Progress 43.357879234167896\n",
      "Progress 43.45213549337261\n",
      "Progress 43.54639175257732\n",
      "Progress 43.640648011782034\n",
      "Progress 43.734904270986746\n",
      "Progress 43.82916053019146\n",
      "Progress 43.92341678939617\n",
      "Progress 44.017673048600884\n",
      "Progress 44.111929307805596\n",
      "Progress 44.20618556701031\n",
      "Progress 44.30044182621502\n",
      "Progress 44.39469808541973\n",
      "Progress 44.488954344624446\n",
      "Progress 44.58321060382916\n",
      "Progress 44.67746686303387\n",
      "Progress 44.77172312223859\n",
      "Progress 44.865979381443296\n",
      "Progress 44.96023564064801\n",
      "Progress 45.05449189985272\n",
      "Progress 45.14874815905744\n",
      "Progress 45.24300441826215\n",
      "Progress 45.33726067746686\n",
      "Progress 45.43151693667157\n",
      "Progress 45.52577319587629\n",
      "Progress 45.620029455081\n",
      "Progress 45.714285714285715\n",
      "Progress 45.80854197349043\n",
      "Progress 45.90279823269514\n",
      "Progress 45.99705449189985\n",
      "Progress 46.091310751104565\n",
      "Progress 46.18556701030928\n",
      "Progress 46.27982326951399\n",
      "Progress 46.3740795287187\n",
      "Progress 46.468335787923415\n",
      "Progress 46.562592047128135\n",
      "Progress 46.65684830633284\n",
      "Progress 46.75110456553755\n",
      "Progress 46.845360824742265\n",
      "Progress 46.939617083946985\n",
      "Progress 47.0338733431517\n",
      "Progress 47.1281296023564\n",
      "Progress 47.222385861561115\n",
      "Progress 47.316642120765835\n",
      "Progress 47.41089837997055\n",
      "Progress 47.50515463917526\n",
      "Progress 47.599410898379965\n",
      "Progress 47.693667157584684\n",
      "Progress 47.7879234167894\n",
      "Progress 47.88217967599411\n",
      "Progress 47.97643593519882\n",
      "Progress 48.070692194403534\n",
      "Progress 48.16494845360825\n",
      "Progress 48.25920471281296\n",
      "Progress 48.35346097201768\n",
      "Progress 48.447717231222384\n",
      "Progress 48.5419734904271\n",
      "Progress 48.63622974963181\n",
      "Progress 48.73048600883653\n",
      "Progress 48.82474226804124\n",
      "Progress 48.91899852724595\n",
      "Progress 49.01325478645066\n",
      "Progress 49.10751104565538\n",
      "Progress 49.20176730486009\n",
      "Progress 49.296023564064804\n",
      "Progress 49.39027982326951\n",
      "Progress 49.48453608247423\n",
      "Progress 49.57879234167894\n",
      "Progress 49.673048600883654\n",
      "Progress 49.767304860088366\n",
      "Progress 49.86156111929308\n",
      "Progress 49.95581737849779\n",
      "Progress 50.05007363770251\n",
      "Progress 50.144329896907216\n",
      "Progress 50.23858615611193\n",
      "Progress 50.33284241531665\n",
      "Progress 50.42709867452135\n",
      "Progress 50.52135493372607\n",
      "Progress 50.61561119293078\n",
      "Progress 50.70986745213549\n",
      "Progress 50.80412371134021\n",
      "Progress 50.898379970544916\n",
      "Progress 50.992636229749635\n",
      "Progress 51.08689248895435\n",
      "Progress 51.18114874815905\n",
      "Progress 51.27540500736377\n",
      "Progress 51.36966126656848\n",
      "Progress 51.4639175257732\n",
      "Progress 51.55817378497791\n",
      "Progress 51.652430044182616\n",
      "Progress 51.746686303387335\n",
      "Progress 51.840942562592055\n",
      "Progress 51.93519882179676\n",
      "Progress 52.02945508100147\n",
      "Progress 52.12371134020618\n",
      "Progress 52.2179675994109\n",
      "Progress 52.31222385861562\n",
      "Progress 52.40648011782032\n",
      "Progress 52.500736377025035\n",
      "Progress 52.594992636229755\n",
      "Progress 52.68924889543446\n",
      "Progress 52.78350515463918\n",
      "Progress 52.87776141384389\n",
      "Progress 52.9720176730486\n",
      "Progress 53.06627393225332\n",
      "Progress 53.16053019145802\n",
      "Progress 53.25478645066274\n",
      "Progress 53.349042709867454\n",
      "Progress 53.44329896907216\n",
      "Progress 53.53755522827688\n",
      "Progress 53.6318114874816\n",
      "Progress 53.726067746686304\n",
      "Progress 53.82032400589102\n",
      "Progress 53.91458026509572\n",
      "Progress 54.00883652430044\n",
      "Progress 54.10309278350516\n",
      "Progress 54.19734904270987\n",
      "Progress 54.29160530191458\n",
      "Progress 54.3858615611193\n",
      "Progress 54.480117820324004\n",
      "Progress 54.574374079528724\n",
      "Progress 54.66863033873343\n",
      "Progress 54.76288659793814\n",
      "Progress 54.85714285714286\n",
      "Progress 54.95139911634757\n",
      "Progress 55.045655375552286\n",
      "Progress 55.139911634757\n",
      "Progress 55.234167893961704\n",
      "Progress 55.328424153166424\n",
      "Progress 55.422680412371136\n",
      "Progress 55.51693667157585\n",
      "Progress 55.61119293078056\n",
      "Progress 55.705449189985266\n",
      "Progress 55.799705449189986\n",
      "Progress 55.8939617083947\n",
      "Progress 55.98821796759941\n",
      "Progress 56.08247422680412\n",
      "Progress 56.17673048600884\n",
      "Progress 56.27098674521355\n",
      "Progress 56.36524300441826\n",
      "Progress 56.45949926362297\n",
      "Progress 56.553755522827686\n",
      "Progress 56.648011782032405\n",
      "Progress 56.74226804123711\n",
      "Progress 56.83652430044182\n",
      "Progress 56.93078055964654\n",
      "Progress 57.02503681885125\n",
      "Progress 57.11929307805597\n",
      "Progress 57.21354933726068\n",
      "Progress 57.307805596465386\n",
      "Progress 57.402061855670105\n",
      "Progress 57.49631811487481\n",
      "Progress 57.59057437407953\n",
      "Progress 57.68483063328424\n",
      "Progress 57.77908689248895\n",
      "Progress 57.87334315169367\n",
      "Progress 57.96759941089839\n",
      "Progress 58.06185567010309\n",
      "Progress 58.156111929307805\n",
      "Progress 58.25036818851251\n",
      "Progress 58.34462444771723\n",
      "Progress 58.43888070692195\n",
      "Progress 58.533136966126655\n",
      "Progress 58.62739322533137\n",
      "Progress 58.72164948453609\n",
      "Progress 58.81590574374079\n",
      "Progress 58.91016200294551\n",
      "Progress 59.00441826215022\n",
      "Progress 59.09867452135493\n",
      "Progress 59.19293078055965\n",
      "Progress 59.287187039764355\n",
      "Progress 59.381443298969074\n",
      "Progress 59.47569955817379\n",
      "Progress 59.56995581737849\n",
      "Progress 59.66421207658321\n",
      "Progress 59.75846833578793\n",
      "Progress 59.85272459499264\n",
      "Progress 59.94698085419735\n",
      "Progress 60.041237113402055\n",
      "Progress 60.135493372606774\n",
      "Progress 60.229749631811494\n",
      "Progress 60.3240058910162\n",
      "Progress 60.41826215022091\n",
      "Progress 60.51251840942563\n",
      "Progress 60.60677466863034\n",
      "Progress 60.701030927835056\n",
      "Progress 60.79528718703976\n",
      "Progress 60.889543446244474\n",
      "Progress 60.983799705449194\n",
      "Progress 61.0780559646539\n",
      "Progress 61.17231222385862\n",
      "Progress 61.26656848306333\n",
      "Progress 61.360824742268036\n",
      "Progress 61.455081001472756\n",
      "Progress 61.54933726067746\n",
      "Progress 61.64359351988218\n",
      "Progress 61.73784977908689\n",
      "Progress 61.8321060382916\n",
      "Progress 61.92636229749632\n",
      "Progress 62.02061855670104\n",
      "Progress 62.11487481590574\n",
      "Progress 62.209131075110456\n",
      "Progress 62.303387334315175\n",
      "Progress 62.39764359351988\n",
      "Progress 62.4918998527246\n",
      "Progress 62.586156111929306\n",
      "Progress 62.68041237113402\n",
      "Progress 62.77466863033874\n",
      "Progress 62.86892488954344\n",
      "Progress 62.96318114874816\n",
      "Progress 63.057437407952875\n",
      "Progress 63.15169366715758\n",
      "Progress 63.2459499263623\n",
      "Progress 63.340206185567006\n",
      "Progress 63.434462444771725\n",
      "Progress 63.52871870397644\n",
      "Progress 63.62297496318114\n",
      "Progress 63.71723122238586\n",
      "Progress 63.811487481590575\n",
      "Progress 63.90574374079529\n",
      "Progress 64.0\n",
      "Progress 64.09425625920471\n",
      "Progress 64.18851251840942\n",
      "Progress 64.28276877761414\n",
      "Progress 64.37702503681885\n",
      "Progress 64.47128129602356\n",
      "Progress 64.56553755522827\n",
      "Progress 64.65979381443299\n",
      "Progress 64.7540500736377\n",
      "Progress 64.84830633284243\n",
      "Progress 64.94256259204712\n",
      "Progress 65.03681885125184\n",
      "Progress 65.13107511045655\n",
      "Progress 65.22533136966126\n",
      "Progress 65.31958762886599\n",
      "Progress 65.41384388807069\n",
      "Progress 65.5081001472754\n",
      "Progress 65.60235640648013\n",
      "Progress 65.69661266568482\n",
      "Progress 65.79086892488955\n",
      "Progress 65.88512518409425\n",
      "Progress 65.97938144329896\n",
      "Progress 66.07363770250369\n",
      "Progress 66.16789396170839\n",
      "Progress 66.26215022091311\n",
      "Progress 66.35640648011783\n",
      "Progress 66.45066273932252\n",
      "Progress 66.54491899852725\n",
      "Progress 66.63917525773196\n",
      "Progress 66.73343151693668\n",
      "Progress 66.82768777614139\n",
      "Progress 66.92194403534609\n",
      "Progress 67.01620029455081\n",
      "Progress 67.11045655375553\n",
      "Progress 67.20471281296024\n",
      "Progress 67.29896907216495\n",
      "Progress 67.39322533136966\n",
      "Progress 67.48748159057438\n",
      "Progress 67.58173784977909\n",
      "Progress 67.6759941089838\n",
      "Progress 67.77025036818851\n",
      "Progress 67.86450662739323\n",
      "Progress 67.95876288659794\n",
      "Progress 68.05301914580265\n",
      "Progress 68.14727540500736\n",
      "Progress 68.24153166421208\n",
      "Progress 68.33578792341679\n",
      "Progress 68.4300441826215\n",
      "Progress 68.52430044182621\n",
      "Progress 68.61855670103093\n",
      "Progress 68.71281296023564\n",
      "Progress 68.80706921944035\n",
      "Progress 68.90132547864508\n",
      "Progress 68.99558173784978\n",
      "Progress 69.08983799705449\n",
      "Progress 69.18409425625921\n",
      "Progress 69.27835051546391\n",
      "Progress 69.37260677466864\n",
      "Progress 69.46686303387334\n",
      "Progress 69.56111929307805\n",
      "Progress 69.65537555228278\n",
      "Progress 69.74963181148748\n",
      "Progress 69.8438880706922\n",
      "Progress 69.93814432989691\n",
      "Progress 70.03240058910161\n",
      "Progress 70.12665684830634\n",
      "Progress 70.22091310751104\n",
      "Progress 70.31516936671576\n",
      "Progress 70.40942562592048\n",
      "Progress 70.50368188512518\n",
      "Progress 70.5979381443299\n",
      "Progress 70.69219440353461\n",
      "Progress 70.78645066273933\n",
      "Progress 70.88070692194404\n",
      "Progress 70.97496318114875\n",
      "Progress 71.06921944035346\n",
      "Progress 71.16347569955818\n",
      "Progress 71.25773195876289\n",
      "Progress 71.3519882179676\n",
      "Progress 71.44624447717231\n",
      "Progress 71.54050073637703\n",
      "Progress 71.63475699558174\n",
      "Progress 71.72901325478645\n",
      "Progress 71.82326951399116\n",
      "Progress 71.91752577319588\n",
      "Progress 72.01178203240059\n",
      "Progress 72.1060382916053\n",
      "Progress 72.20029455081001\n",
      "Progress 72.29455081001473\n",
      "Progress 72.38880706921944\n",
      "Progress 72.48306332842415\n",
      "Progress 72.57731958762886\n",
      "Progress 72.67157584683358\n",
      "Progress 72.76583210603829\n",
      "Progress 72.860088365243\n",
      "Progress 72.95434462444771\n",
      "Progress 73.04860088365243\n",
      "Progress 73.14285714285714\n",
      "Progress 73.23711340206187\n",
      "Progress 73.33136966126656\n",
      "Progress 73.42562592047128\n",
      "Progress 73.519882179676\n",
      "Progress 73.6141384388807\n",
      "Progress 73.70839469808543\n",
      "Progress 73.80265095729013\n",
      "Progress 73.89690721649484\n",
      "Progress 73.99116347569957\n",
      "Progress 74.08541973490426\n",
      "Progress 74.17967599410899\n",
      "Progress 74.2739322533137\n",
      "Progress 74.3681885125184\n",
      "Progress 74.46244477172313\n",
      "Progress 74.55670103092783\n",
      "Progress 74.65095729013255\n",
      "Progress 74.74521354933727\n",
      "Progress 74.83946980854196\n",
      "Progress 74.93372606774669\n",
      "Progress 75.0279823269514\n",
      "Progress 75.12223858615612\n",
      "Progress 75.21649484536083\n",
      "Progress 75.31075110456553\n",
      "Progress 75.40500736377025\n",
      "Progress 75.49926362297496\n",
      "Progress 75.59351988217968\n",
      "Progress 75.68777614138439\n",
      "Progress 75.7820324005891\n",
      "Progress 75.87628865979381\n",
      "Progress 75.97054491899853\n",
      "Progress 76.06480117820324\n",
      "Progress 76.15905743740795\n",
      "Progress 76.25331369661266\n",
      "Progress 76.34756995581738\n",
      "Progress 76.44182621502209\n",
      "Progress 76.5360824742268\n",
      "Progress 76.63033873343151\n",
      "Progress 76.72459499263623\n",
      "Progress 76.81885125184095\n",
      "Progress 76.91310751104565\n",
      "Progress 77.00736377025036\n",
      "Progress 77.10162002945508\n",
      "Progress 77.19587628865979\n",
      "Progress 77.29013254786452\n",
      "Progress 77.38438880706921\n",
      "Progress 77.47864506627393\n",
      "Progress 77.57290132547865\n",
      "Progress 77.66715758468335\n",
      "Progress 77.76141384388808\n",
      "Progress 77.85567010309279\n",
      "Progress 77.94992636229749\n",
      "Progress 78.04418262150222\n",
      "Progress 78.13843888070691\n",
      "Progress 78.23269513991164\n",
      "Progress 78.32695139911635\n",
      "Progress 78.42120765832105\n",
      "Progress 78.51546391752578\n",
      "Progress 78.60972017673049\n",
      "Progress 78.7039764359352\n",
      "Progress 78.79823269513992\n",
      "Progress 78.89248895434461\n",
      "Progress 78.98674521354934\n",
      "Progress 79.08100147275405\n",
      "Progress 79.17525773195877\n",
      "Progress 79.26951399116348\n",
      "Progress 79.36377025036819\n",
      "Progress 79.4580265095729\n",
      "Progress 79.55228276877762\n",
      "Progress 79.64653902798233\n",
      "Progress 79.74079528718704\n",
      "Progress 79.83505154639175\n",
      "Progress 79.92930780559647\n",
      "Progress 80.02356406480118\n",
      "Progress 80.11782032400589\n",
      "Progress 80.2120765832106\n",
      "Progress 80.30633284241532\n",
      "Progress 80.40058910162003\n",
      "Progress 80.49484536082474\n",
      "Progress 80.58910162002945\n",
      "Progress 80.68335787923417\n",
      "Progress 80.77761413843888\n",
      "Progress 80.87187039764359\n",
      "Progress 80.9661266568483\n",
      "Progress 81.06038291605302\n",
      "Progress 81.15463917525774\n",
      "Progress 81.24889543446244\n",
      "Progress 81.34315169366715\n",
      "Progress 81.43740795287187\n",
      "Progress 81.53166421207658\n",
      "Progress 81.6259204712813\n",
      "Progress 81.720176730486\n",
      "Progress 81.81443298969072\n",
      "Progress 81.90868924889544\n",
      "Progress 82.00294550810014\n",
      "Progress 82.09720176730487\n",
      "Progress 82.19145802650958\n",
      "Progress 82.28571428571428\n",
      "Progress 82.379970544919\n",
      "Progress 82.4742268041237\n",
      "Progress 82.56848306332843\n",
      "Progress 82.66273932253314\n",
      "Progress 82.75699558173784\n",
      "Progress 82.85125184094257\n",
      "Progress 82.94550810014728\n",
      "Progress 83.03976435935199\n",
      "Progress 83.1340206185567\n",
      "Progress 83.2282768777614\n",
      "Progress 83.32253313696613\n",
      "Progress 83.41678939617084\n",
      "Progress 83.51104565537555\n",
      "Progress 83.60530191458027\n",
      "Progress 83.69955817378498\n",
      "Progress 83.79381443298969\n",
      "Progress 83.8880706921944\n",
      "Progress 83.98232695139912\n",
      "Progress 84.07658321060383\n",
      "Progress 84.17083946980854\n",
      "Progress 84.26509572901325\n",
      "Progress 84.35935198821797\n",
      "Progress 84.45360824742268\n",
      "Progress 84.54786450662739\n",
      "Progress 84.6421207658321\n",
      "Progress 84.73637702503683\n",
      "Progress 84.83063328424153\n",
      "Progress 84.92488954344624\n",
      "Progress 85.01914580265095\n",
      "Progress 85.11340206185567\n",
      "Progress 85.20765832106039\n",
      "Progress 85.30191458026509\n",
      "Progress 85.3961708394698\n",
      "Progress 85.49042709867453\n",
      "Progress 85.58468335787923\n",
      "Progress 85.67893961708396\n",
      "Progress 85.77319587628865\n",
      "Progress 85.86745213549337\n",
      "Progress 85.96170839469809\n",
      "Progress 86.05596465390279\n",
      "Progress 86.15022091310752\n",
      "Progress 86.24447717231223\n",
      "Progress 86.33873343151693\n",
      "Progress 86.43298969072166\n",
      "Progress 86.52724594992635\n",
      "Progress 86.62150220913108\n",
      "Progress 86.71575846833579\n",
      "Progress 86.81001472754049\n",
      "Progress 86.90427098674522\n",
      "Progress 86.99852724594993\n",
      "Progress 87.09278350515464\n",
      "Progress 87.18703976435935\n",
      "Progress 87.28129602356407\n",
      "Progress 87.37555228276878\n",
      "Progress 87.46980854197349\n",
      "Progress 87.5640648011782\n",
      "Progress 87.65832106038292\n",
      "Progress 87.75257731958763\n",
      "Progress 87.84683357879234\n",
      "Progress 87.94108983799705\n",
      "Progress 88.03534609720177\n",
      "Progress 88.12960235640648\n",
      "Progress 88.22385861561119\n",
      "Progress 88.3181148748159\n",
      "Progress 88.41237113402062\n",
      "Progress 88.50662739322533\n",
      "Progress 88.60088365243004\n",
      "Progress 88.69513991163475\n",
      "Progress 88.78939617083947\n",
      "Progress 88.88365243004418\n",
      "Progress 88.97790868924889\n",
      "Progress 89.07216494845362\n",
      "Progress 89.16642120765832\n",
      "Progress 89.26067746686303\n",
      "Progress 89.35493372606774\n",
      "Progress 89.44918998527245\n",
      "Progress 89.54344624447718\n",
      "Progress 89.63770250368188\n",
      "Progress 89.73195876288659\n",
      "Progress 89.82621502209132\n",
      "Progress 89.92047128129602\n",
      "Progress 90.01472754050074\n",
      "Progress 90.10898379970544\n",
      "Progress 90.20324005891015\n",
      "Progress 90.29749631811488\n",
      "Progress 90.39175257731958\n",
      "Progress 90.4860088365243\n",
      "Progress 90.58026509572902\n",
      "Progress 90.67452135493372\n",
      "Progress 90.76877761413844\n",
      "Progress 90.86303387334314\n",
      "Progress 90.95729013254787\n",
      "Progress 91.05154639175258\n",
      "Progress 91.14580265095728\n",
      "Progress 91.240058910162\n",
      "Progress 91.33431516936672\n",
      "Progress 91.42857142857143\n",
      "Progress 91.52282768777614\n",
      "Progress 91.61708394698086\n",
      "Progress 91.71134020618557\n",
      "Progress 91.80559646539028\n",
      "Progress 91.899852724595\n",
      "Progress 91.9941089837997\n",
      "Progress 92.08836524300442\n",
      "Progress 92.18262150220913\n",
      "Progress 92.27687776141384\n",
      "Progress 92.37113402061856\n",
      "Progress 92.46539027982327\n",
      "Progress 92.55964653902798\n",
      "Progress 92.65390279823269\n",
      "Progress 92.7481590574374\n",
      "Progress 92.84241531664212\n",
      "Progress 92.93667157584683\n",
      "Progress 93.03092783505154\n",
      "Progress 93.12518409425627\n",
      "Progress 93.21944035346097\n",
      "Progress 93.31369661266568\n",
      "Progress 93.40795287187039\n",
      "Progress 93.5022091310751\n",
      "Progress 93.59646539027983\n",
      "Progress 93.69072164948453\n",
      "Progress 93.78497790868924\n",
      "Progress 93.87923416789397\n",
      "Progress 93.97349042709867\n",
      "Progress 94.0677466863034\n",
      "Progress 94.1620029455081\n",
      "Progress 94.2562592047128\n",
      "Progress 94.35051546391753\n",
      "Progress 94.44477172312223\n",
      "Progress 94.53902798232696\n",
      "Progress 94.63328424153167\n",
      "Progress 94.72754050073637\n",
      "Progress 94.8217967599411\n",
      "Progress 94.9160530191458\n",
      "Progress 95.01030927835052\n",
      "Progress 95.10456553755523\n",
      "Progress 95.19882179675993\n",
      "Progress 95.29307805596466\n",
      "Progress 95.38733431516937\n",
      "Progress 95.48159057437408\n",
      "Progress 95.5758468335788\n",
      "Progress 95.6701030927835\n",
      "Progress 95.76435935198822\n",
      "Progress 95.85861561119293\n",
      "Progress 95.95287187039764\n",
      "Progress 96.04712812960236\n",
      "Progress 96.14138438880707\n",
      "Progress 96.23564064801178\n",
      "Progress 96.3298969072165\n",
      "Progress 96.4241531664212\n",
      "Progress 96.51840942562592\n",
      "Progress 96.61266568483063\n",
      "Progress 96.70692194403536\n",
      "Progress 96.80117820324006\n",
      "Progress 96.89543446244477\n",
      "Progress 96.98969072164948\n",
      "Progress 97.0839469808542\n",
      "Progress 97.17820324005892\n",
      "Progress 97.27245949926362\n",
      "Progress 97.36671575846833\n",
      "Progress 97.46097201767306\n",
      "Progress 97.55522827687776\n",
      "Progress 97.64948453608248\n",
      "Progress 97.74374079528718\n",
      "Progress 97.8379970544919\n",
      "Progress 97.93225331369662\n",
      "Progress 98.02650957290132\n",
      "Progress 98.12076583210604\n",
      "Progress 98.21502209131076\n",
      "Progress 98.30927835051546\n",
      "Progress 98.40353460972018\n",
      "Progress 98.4977908689249\n",
      "Progress 98.59204712812961\n",
      "Progress 98.68630338733432\n",
      "Progress 98.78055964653902\n",
      "Progress 98.87481590574374\n",
      "Progress 98.96907216494846\n",
      "Progress 99.06332842415317\n",
      "Progress 99.15758468335788\n",
      "Progress 99.2518409425626\n",
      "Progress 99.34609720176731\n",
      "Progress 99.44035346097202\n",
      "Progress 99.53460972017673\n",
      "Progress 99.62886597938144\n",
      "Progress 99.72312223858616\n",
      "Progress 99.81737849779087\n",
      "Progress 99.91163475699558\n",
      "Progress 0.0\n",
      "Progress 0.37702503681885124\n",
      "Progress 0.7540500736377025\n",
      "Progress 1.1310751104565537\n",
      "Progress 1.508100147275405\n",
      "Progress 1.8851251840942562\n",
      "Progress 2.2621502209131075\n",
      "Progress 2.6391752577319587\n",
      "Progress 3.01620029455081\n",
      "Progress 3.393225331369661\n",
      "Progress 3.7702503681885124\n",
      "Progress 4.147275405007364\n",
      "Progress 4.524300441826215\n",
      "Progress 4.901325478645066\n",
      "Progress 5.278350515463917\n",
      "Progress 5.655375552282769\n",
      "Progress 6.03240058910162\n",
      "Progress 6.409425625920472\n",
      "Progress 6.786450662739322\n",
      "Progress 7.163475699558173\n",
      "Progress 7.540500736377025\n",
      "Progress 7.917525773195876\n",
      "Progress 8.294550810014728\n",
      "Progress 8.67157584683358\n",
      "Progress 9.04860088365243\n",
      "Progress 9.425625920471282\n",
      "Progress 9.802650957290131\n",
      "Progress 10.179675994108983\n",
      "Progress 10.556701030927835\n",
      "Progress 10.933726067746687\n",
      "Progress 11.310751104565538\n",
      "Progress 11.687776141384388\n",
      "Progress 12.06480117820324\n",
      "Progress 12.441826215022092\n",
      "Progress 12.818851251840943\n",
      "Progress 13.195876288659795\n",
      "Progress 13.572901325478645\n",
      "Progress 13.949926362297496\n",
      "Progress 14.326951399116346\n",
      "Progress 14.703976435935198\n",
      "Progress 15.08100147275405\n",
      "Progress 15.4580265095729\n",
      "Progress 15.835051546391751\n",
      "Progress 16.212076583210607\n",
      "Progress 16.589101620029457\n",
      "Progress 16.966126656848306\n",
      "Progress 17.34315169366716\n",
      "Progress 17.72017673048601\n",
      "Progress 18.09720176730486\n",
      "Progress 18.47422680412371\n",
      "Progress 18.851251840942563\n",
      "Progress 19.228276877761413\n",
      "Progress 19.605301914580263\n",
      "Progress 19.982326951399116\n",
      "Progress 20.359351988217966\n",
      "Progress 20.73637702503682\n",
      "Progress 21.11340206185567\n",
      "Progress 21.490427098674523\n",
      "Progress 21.867452135493373\n",
      "Progress 22.244477172312223\n",
      "Progress 22.621502209131076\n",
      "Progress 22.998527245949926\n",
      "Progress 23.375552282768776\n",
      "Progress 23.75257731958763\n",
      "Progress 24.12960235640648\n",
      "Progress 24.50662739322533\n",
      "Progress 24.883652430044183\n",
      "Progress 25.260677466863036\n",
      "Progress 25.637702503681886\n",
      "Progress 26.014727540500736\n",
      "Progress 26.39175257731959\n",
      "Progress 26.76877761413844\n",
      "Progress 27.14580265095729\n",
      "Progress 27.522827687776143\n",
      "Progress 27.899852724594993\n",
      "Progress 28.276877761413843\n",
      "Progress 28.653902798232693\n",
      "Progress 29.030927835051546\n",
      "Progress 29.407952871870396\n",
      "Progress 29.784977908689246\n",
      "Progress 30.1620029455081\n",
      "Progress 30.53902798232695\n",
      "Progress 30.9160530191458\n",
      "Progress 31.293078055964653\n",
      "Progress 31.670103092783503\n",
      "Progress 32.047128129602356\n",
      "Progress 32.42415316642121\n",
      "Progress 32.80117820324006\n",
      "Progress 33.17820324005891\n",
      "Progress 33.55522827687776\n",
      "Progress 33.93225331369661\n",
      "Progress 34.30927835051546\n",
      "Progress 34.68630338733432\n",
      "Progress 35.06332842415317\n",
      "Progress 35.44035346097202\n",
      "Progress 35.81737849779087\n",
      "Progress 36.19440353460972\n",
      "Progress 36.57142857142857\n",
      "Progress 36.94845360824742\n",
      "Progress 37.325478645066276\n",
      "Progress 37.702503681885126\n",
      "Progress 38.079528718703976\n",
      "Progress 38.456553755522826\n",
      "Progress 38.833578792341676\n",
      "Progress 39.210603829160526\n",
      "Progress 39.58762886597938\n",
      "Progress 39.96465390279823\n",
      "Progress 40.34167893961708\n",
      "Progress 40.71870397643593\n",
      "Progress 41.09572901325479\n",
      "Progress 41.47275405007364\n",
      "Progress 41.84977908689249\n",
      "Progress 42.22680412371134\n",
      "Progress 42.603829160530196\n",
      "Progress 42.980854197349046\n",
      "Progress 43.357879234167896\n",
      "Progress 43.734904270986746\n",
      "Progress 44.111929307805596\n",
      "Progress 44.488954344624446\n",
      "Progress 44.865979381443296\n",
      "Progress 45.24300441826215\n",
      "Progress 45.620029455081\n",
      "Progress 45.99705449189985\n",
      "Progress 46.3740795287187\n",
      "Progress 46.75110456553755\n",
      "Progress 47.1281296023564\n",
      "Progress 47.50515463917526\n",
      "Progress 47.88217967599411\n",
      "Progress 48.25920471281296\n",
      "Progress 48.63622974963181\n",
      "Progress 49.01325478645066\n",
      "Progress 49.39027982326951\n",
      "Progress 49.767304860088366\n",
      "Progress 50.144329896907216\n",
      "Progress 50.52135493372607\n",
      "Progress 50.898379970544916\n",
      "Progress 51.27540500736377\n",
      "Progress 51.652430044182616\n",
      "Progress 52.02945508100147\n",
      "Progress 52.40648011782032\n",
      "Progress 52.78350515463918\n",
      "Progress 53.16053019145802\n",
      "Progress 53.53755522827688\n",
      "Progress 53.91458026509572\n",
      "Progress 54.29160530191458\n",
      "Progress 54.66863033873343\n",
      "Progress 55.045655375552286\n",
      "Progress 55.422680412371136\n",
      "Progress 55.799705449189986\n",
      "Progress 56.17673048600884\n",
      "Progress 56.553755522827686\n",
      "Progress 56.93078055964654\n",
      "Progress 57.307805596465386\n",
      "Progress 57.68483063328424\n",
      "Progress 58.06185567010309\n",
      "Progress 58.43888070692195\n",
      "Progress 58.81590574374079\n",
      "Progress 59.19293078055965\n",
      "Progress 59.56995581737849\n",
      "Progress 59.94698085419735\n",
      "Progress 60.3240058910162\n",
      "Progress 60.701030927835056\n",
      "Progress 61.0780559646539\n",
      "Progress 61.455081001472756\n",
      "Progress 61.8321060382916\n",
      "Progress 62.209131075110456\n",
      "Progress 62.586156111929306\n",
      "Progress 62.96318114874816\n",
      "Progress 63.340206185567006\n",
      "Progress 63.71723122238586\n",
      "Progress 64.09425625920471\n",
      "Progress 64.47128129602356\n",
      "Progress 64.84830633284243\n",
      "Progress 65.22533136966126\n",
      "Progress 65.60235640648013\n",
      "Progress 65.97938144329896\n",
      "Progress 66.35640648011783\n",
      "Progress 66.73343151693668\n",
      "Progress 67.11045655375553\n",
      "Progress 67.48748159057438\n",
      "Progress 67.86450662739323\n",
      "Progress 68.24153166421208\n",
      "Progress 68.61855670103093\n",
      "Progress 68.99558173784978\n",
      "Progress 69.37260677466864\n",
      "Progress 69.74963181148748\n",
      "Progress 70.12665684830634\n",
      "Progress 70.50368188512518\n",
      "Progress 70.88070692194404\n",
      "Progress 71.25773195876289\n",
      "Progress 71.63475699558174\n",
      "Progress 72.01178203240059\n",
      "Progress 72.38880706921944\n",
      "Progress 72.76583210603829\n",
      "Progress 73.14285714285714\n",
      "Progress 73.519882179676\n",
      "Progress 73.89690721649484\n",
      "Progress 74.2739322533137\n",
      "Progress 74.65095729013255\n",
      "Progress 75.0279823269514\n",
      "Progress 75.40500736377025\n",
      "Progress 75.7820324005891\n",
      "Progress 76.15905743740795\n",
      "Progress 76.5360824742268\n",
      "Progress 76.91310751104565\n",
      "Progress 77.29013254786452\n",
      "Progress 77.66715758468335\n",
      "Progress 78.04418262150222\n",
      "Progress 78.42120765832105\n",
      "Progress 78.79823269513992\n",
      "Progress 79.17525773195877\n",
      "Progress 79.55228276877762\n",
      "Progress 79.92930780559647\n",
      "Progress 80.30633284241532\n",
      "Progress 80.68335787923417\n",
      "Progress 81.06038291605302\n",
      "Progress 81.43740795287187\n",
      "Progress 81.81443298969072\n",
      "Progress 82.19145802650958\n",
      "Progress 82.56848306332843\n",
      "Progress 82.94550810014728\n",
      "Progress 83.32253313696613\n",
      "Progress 83.69955817378498\n",
      "Progress 84.07658321060383\n",
      "Progress 84.45360824742268\n",
      "Progress 84.83063328424153\n",
      "Progress 85.20765832106039\n",
      "Progress 85.58468335787923\n",
      "Progress 85.96170839469809\n",
      "Progress 86.33873343151693\n",
      "Progress 86.71575846833579\n",
      "Progress 87.09278350515464\n",
      "Progress 87.46980854197349\n",
      "Progress 87.84683357879234\n",
      "Progress 88.22385861561119\n",
      "Progress 88.60088365243004\n",
      "Progress 88.97790868924889\n",
      "Progress 89.35493372606774\n",
      "Progress 89.73195876288659\n",
      "Progress 90.10898379970544\n",
      "Progress 90.4860088365243\n",
      "Progress 90.86303387334314\n",
      "Progress 91.240058910162\n",
      "Progress 91.61708394698086\n",
      "Progress 91.9941089837997\n",
      "Progress 92.37113402061856\n",
      "Progress 92.7481590574374\n",
      "Progress 93.12518409425627\n",
      "Progress 93.5022091310751\n",
      "Progress 93.87923416789397\n",
      "Progress 94.2562592047128\n",
      "Progress 94.63328424153167\n",
      "Progress 95.01030927835052\n",
      "Progress 95.38733431516937\n",
      "Progress 95.76435935198822\n",
      "Progress 96.14138438880707\n",
      "Progress 96.51840942562592\n",
      "Progress 96.89543446244477\n",
      "Progress 97.27245949926362\n",
      "Progress 97.64948453608248\n",
      "Progress 98.02650957290132\n",
      "Progress 98.40353460972018\n",
      "Progress 98.78055964653902\n",
      "Progress 99.15758468335788\n",
      "Progress 99.53460972017673\n",
      "Progress 99.91163475699558\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   6.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12567e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12724e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.1378e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12779e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12196e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.15210174 0.1520792         nan        nan\n",
      " 0.18882719 0.1888764         nan        nan 0.19630349        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:38:49, 1185.84s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"death_in_30\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 7.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 7.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:36:40, 5800.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [3:05:43, 5531.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 8.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 8.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [4:45:24, 5736.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [6:17:25, 5651.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"death_in_30\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: DVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "1it [04:59, 299.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2it [09:55, 297.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "3it [14:51, 296.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "4it [19:46, 296.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "5it [24:45, 297.12s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"DVT\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06581e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06222e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06049e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06986e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06929e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.03905753 0.03905747        nan        nan\n",
      " 0.04077556 0.04076183        nan        nan 0.03944856        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:59, 59.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50406e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.494e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50576e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49524e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.4997e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.04265677 0.0426567         nan        nan\n",
      " 0.04120583 0.04121218        nan        nan 0.03780071        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:59, 59.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23676e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23474e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.24935e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.25191e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23914e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.03300807 0.03300719        nan        nan\n",
      " 0.03558678 0.03556761        nan        nan 0.03195117        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:58, 59.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49309e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48588e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50954e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48235e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48895e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.03592279 0.03592221        nan        nan\n",
      " 0.03595142 0.03594554        nan        nan 0.03924556        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:59, 60.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12549e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12765e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.13646e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12942e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12147e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.03603518 0.03603515        nan        nan\n",
      " 0.03663718 0.03662819        nan        nan 0.03656385        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:53, 58.64s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"DVT\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:34:54, 5694.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [3:18:57, 6017.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 5.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 5.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 5.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [5:06:43, 6222.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [6:46:13, 6122.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time= 1.2min\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time= 1.2min\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time= 1.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 9.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 8.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 9.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [8:42:07, 6265.42s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"DVT\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "1it [04:48, 288.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2it [09:36, 287.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "3it [14:22, 287.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [19:09, 287.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "5it [23:57, 287.55s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"PE\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06579e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06207e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06032e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.0702e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.0693e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.01561954 0.01561946        nan        nan\n",
      " 0.01891555 0.01892085        nan        nan 0.01683586        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:57, 57.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50415e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49316e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50602e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49569e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50005e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.014439   0.01443896        nan        nan\n",
      " 0.01854739 0.018533          nan        nan 0.02005445        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:56, 58.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23672e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23518e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.24863e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.25217e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23913e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.01433047 0.01433037        nan        nan\n",
      " 0.01458411 0.01457572        nan        nan 0.02560457        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:52, 57.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.2s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49313e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48567e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50935e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48313e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48856e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.01731072 0.01730932        nan        nan\n",
      " 0.0174528  0.01743286        nan        nan 0.02506333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:51, 58.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   2.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.1254e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12746e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.1367e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12915e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12169e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.01497505 0.01497505        nan        nan\n",
      " 0.02720907 0.02723204        nan        nan 0.02214275        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:48, 57.79s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"PE\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:38:01, 5881.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [3:08:05, 5600.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [4:45:00, 5698.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.7s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 5.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 8.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 8.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [6:23:08, 5773.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [7:47:31, 5610.38s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"PE\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: PNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "1it [04:57, 297.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2it [09:55, 297.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "3it [14:52, 297.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "4it [19:50, 297.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "5it [24:47, 297.47s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"PNA\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06579e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06206e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06119e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.0693e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06934e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.05762018 0.05762059        nan        nan\n",
      " 0.0655857  0.06563227        nan        nan 0.06360186        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:50, 50.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.5048e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49313e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50587e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.4958e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.4998e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.05840556 0.05840553        nan        nan\n",
      " 0.06244236 0.06245697        nan        nan 0.06008872        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:41, 50.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.9s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23672e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23454e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.24928e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.25205e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23899e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.05834957 0.05834956        nan        nan\n",
      " 0.06188    0.06185115        nan        nan 0.06287416        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:34, 51.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49305e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48616e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50982e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48292e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48841e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.04973978 0.04973977        nan        nan\n",
      " 0.05453141 0.05451064        nan        nan 0.05185826        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:25, 51.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.8s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.7s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   4.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12555e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.1277e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.13642e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12937e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12162e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.05404971 0.05404761        nan        nan\n",
      " 0.05950649 0.0595305         nan        nan 0.06064143        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:17, 51.58s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"PNA\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.6s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:39:31, 5971.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [3:17:07, 5903.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [4:59:34, 6014.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [6:35:03, 5901.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  37.8s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  38.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 5.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [8:19:47, 5997.53s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"PNA\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: AKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [06:10, 370.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [12:18, 369.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [18:28, 369.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [24:35, 368.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   2.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   2.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   2.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   2.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   2.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   2.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.8s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   2.7s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   2.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   1.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   2.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   1.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   2.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   2.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [30:42, 368.59s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"post_aki_status\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  12.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06576e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06193e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06053e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06967e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.06946e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.46778284 0.46777717        nan        nan\n",
      " 0.51276171 0.51276649        nan        nan 0.51817947        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:50, 110.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50381e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49351e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50659e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49459e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50064e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.47382374 0.47381365        nan        nan\n",
      " 0.51568267 0.51566296        nan        nan 0.51775138        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:40, 110.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.5s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.7s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23653e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23423e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.24982e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.2526e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.23939e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.47924975 0.47925748        nan        nan\n",
      " 0.52082602 0.52081275        nan        nan 0.5238256         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:28, 109.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.4s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.6s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.49254e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48632e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.50931e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.4834e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.48862e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.47410423 0.4740946         nan        nan\n",
      " 0.51231848 0.5122777         nan        nan 0.51737731        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [07:15, 108.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   1.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.9s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.6s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   4.5s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   1.4s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   9.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  10.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   9.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   9.4s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12641e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12645e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.13664e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12886e-08): result may not be accurate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=4.12147e-08): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "35 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 484, in _logistic_regression_path\n",
      "    w0 = sol.solve(X=X, y=target, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 418, in solve\n",
      "    self.fallback_lbfgs_solve(X=X, y=y, sample_weight=sample_weight)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_glm/_newton_solver.py\", line 181, in fallback_lbfgs_solve\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 305, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 332, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 278, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 257, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "  File \"sklearn/_loss/_loss.pyx\", line 1654, in sklearn._loss._loss.CyHalfBinomialLoss.loss_gradient\n",
      "ValueError: Buffer dtype mismatch, expected 'npy_float32' but got 'double'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.47498994 0.47497046        nan        nan\n",
      " 0.51790299 0.51788772        nan        nan 0.52199354        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [09:01, 108.37s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"post_aki_status\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  35.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  35.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  35.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  35.9s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.0min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:10:01, 4201.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [2:21:49, 4263.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [3:35:05, 4324.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [4:48:46, 4362.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.2s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=  36.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.1min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time= 3.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [6:01:29, 4337.87s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"post_aki_status\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: delirium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:02, 182.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [06:05, 182.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [09:07, 182.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [12:10, 182.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.1, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   1.0s\n",
      "[CV] END .learning_rate=0.1, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.7s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=2; total time=   1.5s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END .learning_rate=0.1, max_depth=8, min_child_weight=4; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.1s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=2; total time=   1.0s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.6s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=1; total time=   1.5s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.3s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=2; total time=   1.4s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END learning_rate=0.15, max_depth=8, min_child_weight=4; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=1; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=2; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=4, min_child_weight=4; total time=   0.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=1; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=2; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=5, min_child_weight=4; total time=   0.5s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=1; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=2; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.7s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=6, min_child_weight=4; total time=   0.6s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.0s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=1; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=2; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.9s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=7, min_child_weight=4; total time=   0.8s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.3s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=1; total time=   1.4s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=2; total time=   1.2s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n",
      "[CV] END .learning_rate=0.3, max_depth=8, min_child_weight=4; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [15:10, 182.20s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val(\"postop_del\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70092016 0.70089745        nan        nan\n",
      " 0.73205919 0.73206006        nan        nan 0.73889987 0.73890649]\n",
      "  warnings.warn(\n",
      "1it [00:06,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70761939 0.70762405        nan        nan\n",
      " 0.73106615 0.73105224        nan        nan 0.74092897 0.74094064]\n",
      "  warnings.warn(\n",
      "2it [00:13,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.72363852 0.72363212        nan        nan\n",
      " 0.74036153 0.7404047         nan        nan 0.74723642 0.74724211]\n",
      "  warnings.warn(\n",
      "3it [00:21,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70416673 0.70417601        nan        nan\n",
      " 0.72674958 0.72675424        nan        nan 0.73632034 0.73633142]\n",
      "  warnings.warn(\n",
      "4it [00:28,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.1s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END .........C=0.01, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.3s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.2s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/charles/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/charles/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70138167 0.70139334        nan        nan\n",
      " 0.73159913 0.73161203        nan        nan 0.73838777 0.73834013]\n",
      "  warnings.warn(\n",
      "5it [00:34,  6.94s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_log_reg(\"postop_del\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  12.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [05:43, 343.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [11:29, 345.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [17:18, 346.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [23:04, 346.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=2; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=4, min_samples_leaf=3, min_samples_split=5; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  13.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  13.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=5; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [28:48, 345.78s/it]\n"
     ]
    }
   ],
   "source": [
    "results=K_fold_val_rf(\"postop_del\", df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
